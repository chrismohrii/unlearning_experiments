{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_nns_regular_mnist.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45d6e3c69c7b4041b54c3b3f4a76f04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cf7f586894345fc8de451f494c1451d",
              "IPY_MODEL_04c1d2acbcd847b89e17d5c1e9e31f0b",
              "IPY_MODEL_b3ad2a69d105450cb07386d7d899aa1d"
            ],
            "layout": "IPY_MODEL_2210e5083bd542899813c0960b510195"
          }
        },
        "2cf7f586894345fc8de451f494c1451d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a76f4da8b924986b2ac45689a60e6ce",
            "placeholder": "​",
            "style": "IPY_MODEL_1fc6d7d7c24f40708f75c6a8480e7fe9",
            "value": ""
          }
        },
        "04c1d2acbcd847b89e17d5c1e9e31f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948e991f952b4945895296bd6c6d5320",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e2a2fd492484bf08d2786270d33aec8",
            "value": 9912422
          }
        },
        "b3ad2a69d105450cb07386d7d899aa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf60655da23432eb701b241179e2621",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c26449c63a4be79245c34f7b7b25c1",
            "value": " 9913344/? [00:00&lt;00:00, 21742016.14it/s]"
          }
        },
        "2210e5083bd542899813c0960b510195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a76f4da8b924986b2ac45689a60e6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc6d7d7c24f40708f75c6a8480e7fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "948e991f952b4945895296bd6c6d5320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e2a2fd492484bf08d2786270d33aec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bf60655da23432eb701b241179e2621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c26449c63a4be79245c34f7b7b25c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de230257dbaf453caaaabb0bb2887737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4648fec873d4e15be7b2b3981de348f",
              "IPY_MODEL_9073fbb73ce344d3b5dc80e1d79320a6",
              "IPY_MODEL_783749e6205044d78591f96284596789"
            ],
            "layout": "IPY_MODEL_98fe0170ee3f4c5aa9f008bac68da633"
          }
        },
        "b4648fec873d4e15be7b2b3981de348f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78aa8c13b3e14557b4faaa1cd8dfd6a0",
            "placeholder": "​",
            "style": "IPY_MODEL_958d1614deaa4a6eac7b386655be8ada",
            "value": ""
          }
        },
        "9073fbb73ce344d3b5dc80e1d79320a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c93ea03ee37444983d3d249d7e7316d",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da5b9d09316e42b4960f8207a8f5ca6b",
            "value": 28881
          }
        },
        "783749e6205044d78591f96284596789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_523ec5e3583b4b57a6cd2e99e1808a49",
            "placeholder": "​",
            "style": "IPY_MODEL_9fcc40638b704feaa014ef50a073cc3d",
            "value": " 29696/? [00:00&lt;00:00, 8827.95it/s]"
          }
        },
        "98fe0170ee3f4c5aa9f008bac68da633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78aa8c13b3e14557b4faaa1cd8dfd6a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958d1614deaa4a6eac7b386655be8ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c93ea03ee37444983d3d249d7e7316d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5b9d09316e42b4960f8207a8f5ca6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "523ec5e3583b4b57a6cd2e99e1808a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fcc40638b704feaa014ef50a073cc3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a811373516e4c52b07484feb795dfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_100d739b9b264e658fd4ddb25ab36861",
              "IPY_MODEL_d8c9713cf85a4e598e10a6c28bcbbadd",
              "IPY_MODEL_381548012fe44d148f95850478caeb4a"
            ],
            "layout": "IPY_MODEL_2147b191addb4c64a89e419db3e76184"
          }
        },
        "100d739b9b264e658fd4ddb25ab36861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61194a9ded77494dab95798e3708709f",
            "placeholder": "​",
            "style": "IPY_MODEL_fc4c275688c94b9983f7c09e3d5b2213",
            "value": ""
          }
        },
        "d8c9713cf85a4e598e10a6c28bcbbadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1935842e5cdf42e0939eb104bb5942ba",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa9ad88ac0e6462392f913ffe0c687d4",
            "value": 1648877
          }
        },
        "381548012fe44d148f95850478caeb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1180419a59d54abe83222cdfd4912a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_26b609553f724fb28d8246daeb836f96",
            "value": " 1649664/? [00:00&lt;00:00, 4432857.37it/s]"
          }
        },
        "2147b191addb4c64a89e419db3e76184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61194a9ded77494dab95798e3708709f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4c275688c94b9983f7c09e3d5b2213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1935842e5cdf42e0939eb104bb5942ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa9ad88ac0e6462392f913ffe0c687d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1180419a59d54abe83222cdfd4912a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b609553f724fb28d8246daeb836f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f57c804f7140a496b4074733db2bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73661c14593249e0a1f9c608a4d4471d",
              "IPY_MODEL_6dbe83c72da14ebcb9a6bfad9c745cac",
              "IPY_MODEL_d66c817f0f384e5498a6abd053ed3400"
            ],
            "layout": "IPY_MODEL_e0a1508e131547f69e99d40e90984839"
          }
        },
        "73661c14593249e0a1f9c608a4d4471d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01860c3274de4ac5b625547ab331d916",
            "placeholder": "​",
            "style": "IPY_MODEL_1d0e19a860e5446393cf61e8392101dc",
            "value": ""
          }
        },
        "6dbe83c72da14ebcb9a6bfad9c745cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75c797764ad445d86e9c27434a71725",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfa72f6bbab840849fe95be2d4af0e40",
            "value": 4542
          }
        },
        "d66c817f0f384e5498a6abd053ed3400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab883b9fba5944a69f40b23006c748c6",
            "placeholder": "​",
            "style": "IPY_MODEL_70d9b127d80e48fa89467390f2b2f0b2",
            "value": " 5120/? [00:00&lt;00:00, 6163.69it/s]"
          }
        },
        "e0a1508e131547f69e99d40e90984839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01860c3274de4ac5b625547ab331d916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0e19a860e5446393cf61e8392101dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b75c797764ad445d86e9c27434a71725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa72f6bbab840849fe95be2d4af0e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab883b9fba5944a69f40b23006c748c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d9b127d80e48fa89467390f2b2f0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unlearning Experiments ([steps](https://www.overleaf.com/project/623aa8d6b133433e9006bc8a))"
      ],
      "metadata": {
        "id": "xUlA6pKW1QLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install pyvacy\n",
        "from pyvacy import optim, analysis"
      ],
      "metadata": {
        "id": "RYZxqbFWbv-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get MNIST data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "K9Fk8NcGb2in",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "45d6e3c69c7b4041b54c3b3f4a76f04f",
            "2cf7f586894345fc8de451f494c1451d",
            "04c1d2acbcd847b89e17d5c1e9e31f0b",
            "b3ad2a69d105450cb07386d7d899aa1d",
            "2210e5083bd542899813c0960b510195",
            "5a76f4da8b924986b2ac45689a60e6ce",
            "1fc6d7d7c24f40708f75c6a8480e7fe9",
            "948e991f952b4945895296bd6c6d5320",
            "9e2a2fd492484bf08d2786270d33aec8",
            "9bf60655da23432eb701b241179e2621",
            "b2c26449c63a4be79245c34f7b7b25c1",
            "de230257dbaf453caaaabb0bb2887737",
            "b4648fec873d4e15be7b2b3981de348f",
            "9073fbb73ce344d3b5dc80e1d79320a6",
            "783749e6205044d78591f96284596789",
            "98fe0170ee3f4c5aa9f008bac68da633",
            "78aa8c13b3e14557b4faaa1cd8dfd6a0",
            "958d1614deaa4a6eac7b386655be8ada",
            "5c93ea03ee37444983d3d249d7e7316d",
            "da5b9d09316e42b4960f8207a8f5ca6b",
            "523ec5e3583b4b57a6cd2e99e1808a49",
            "9fcc40638b704feaa014ef50a073cc3d",
            "4a811373516e4c52b07484feb795dfc0",
            "100d739b9b264e658fd4ddb25ab36861",
            "d8c9713cf85a4e598e10a6c28bcbbadd",
            "381548012fe44d148f95850478caeb4a",
            "2147b191addb4c64a89e419db3e76184",
            "61194a9ded77494dab95798e3708709f",
            "fc4c275688c94b9983f7c09e3d5b2213",
            "1935842e5cdf42e0939eb104bb5942ba",
            "aa9ad88ac0e6462392f913ffe0c687d4",
            "1180419a59d54abe83222cdfd4912a5d",
            "26b609553f724fb28d8246daeb836f96",
            "25f57c804f7140a496b4074733db2bf8",
            "73661c14593249e0a1f9c608a4d4471d",
            "6dbe83c72da14ebcb9a6bfad9c745cac",
            "d66c817f0f384e5498a6abd053ed3400",
            "e0a1508e131547f69e99d40e90984839",
            "01860c3274de4ac5b625547ab331d916",
            "1d0e19a860e5446393cf61e8392101dc",
            "b75c797764ad445d86e9c27434a71725",
            "dfa72f6bbab840849fe95be2d4af0e40",
            "ab883b9fba5944a69f40b23006c748c6",
            "70d9b127d80e48fa89467390f2b2f0b2"
          ]
        },
        "outputId": "b9ce81b9-49c2-4b3e-eec2-4f5b2aaa6294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45d6e3c69c7b4041b54c3b3f4a76f04f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de230257dbaf453caaaabb0bb2887737"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a811373516e4c52b07484feb795dfc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25f57c804f7140a496b4074733db2bf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size\n",
        "batch_size = 50\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "LpXjed2xcWMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get CPU or GPU device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define 3-layer fully connected neural network\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PqdU3l2cctc",
        "outputId": "181b4acd-b224-49c4-94d2-f19a65301ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains for one epoch.\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Discard element if it was marked as the removed one (y == -1)\n",
        "        if -1 in y:\n",
        "            index_removed = int((y == -1).nonzero(as_tuple=True)[0][0])\n",
        "            y = torch.cat((y[:index_removed], y[index_removed + 1:]))\n",
        "            X = torch.cat((X[:index_removed, :], X[index_removed + 1:, :]))\n",
        "\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "XXIvVlT1Hugk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the accuracy and average loss for the test set.\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return correct"
      ],
      "metadata": {
        "id": "zkXutjo_Hvt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and hyperparameters.\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lr = 1e-2\n",
        "num_epochs = 30\n",
        "delta = 0.1"
      ],
      "metadata": {
        "id": "M8JgtV-R1M1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample U (one element) from specified label and get dataset without U.\n",
        "def get_modified_training_dataloader(label, batch_size):\n",
        "    # Create copy of dataset to modify\n",
        "    modified_dataset = datasets.MNIST(\n",
        "        root=\"data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=ToTensor(),\n",
        "    )\n",
        "\n",
        "    # Find index of first element from class i (the single element in set of \n",
        "    # delete requests U). It does not matter that it is the first because we\n",
        "    # are randomly shuffling\n",
        "    indicies_from_class = modified_dataset.targets == label\n",
        "    index_of_u = int((indicies_from_class == True).nonzero()[0][0]) # Doesn't matter which one we pick because of shuffling\n",
        "\n",
        "    # Mark the removed element with \"-1\" class to discard while training.\n",
        "    modified_dataset.targets[index_of_u] = -1\n",
        "    \n",
        "    return DataLoader(modified_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "a = get_modified_training_dataloader(0, 100)\n",
        "\n",
        "\n",
        "# Trains a neural network for a given number of epochs.\n",
        "def train_model(model, train_dataloader, optimizer, test_dataloader = test_dataloader, loss_fn = loss_fn, num_epochs = 100):\n",
        "    for t in range(num_epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train(train_dataloader, model, loss_fn, optimizer)\n",
        "        test(test_dataloader, model, loss_fn)\n",
        "    print(\"Done!\")"
      ],
      "metadata": {
        "id": "gOzLiN7r1yex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize list of models\n",
        "models = []\n",
        "num_classes_to_delete_point_from = 10\n",
        "\n",
        "# Compute w and noisy ws for each random seed. For loop in the form i, i+1 to \n",
        "# avoid problems with runtime disconnecting (each iteration takes approx 2 hrs).\n",
        "for seed in range(0, 1):\n",
        "    seed_models = []\n",
        "\n",
        "    # Set seed for training on regular dataset\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Get new dataloader appropriate for seed (shuffling has an effect)\n",
        "    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Train for w(S)\n",
        "    model_regular = NeuralNetwork().to(device)\n",
        "    optimizer = torch.optim.SGD(model_regular.parameters(), lr=lr)\n",
        "    train_model(model_regular, train_dataloader, optimizer, num_epochs = num_epochs)\n",
        "\n",
        "    seed_models.append(model_regular)\n",
        "\n",
        "    # Train for each of the w(S\\U) \n",
        "    models_modified = []\n",
        "    for label in range(num_classes_to_delete_point_from):\n",
        "        print(\"Removing an element from class: \" + str(label))\n",
        "\n",
        "        # Set the same seed to start each training iteration\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # Remove an element from the training dataset\n",
        "        modified_train_dataloader = get_modified_training_dataloader(label, batch_size)\n",
        "\n",
        "        # Create and train model for the modified dataset\n",
        "        model_modified = NeuralNetwork().to(device)\n",
        "        optimizer = torch.optim.SGD(model_modified.parameters(), lr=lr)\n",
        "        train_model(model_modified, modified_train_dataloader, optimizer, num_epochs = num_epochs)\n",
        "\n",
        "        models_modified.append(model_modified)\n",
        "\n",
        "    seed_models.append(models_modified)\n",
        "    models.append(seed_models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWLJwQQzwrLA",
        "outputId": "fba4d537-6dfc-4bb9-a5b2-636fc8a2e32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193841  [    0/60000]\n",
            "loss: 0.192506  [ 5000/60000]\n",
            "loss: 0.210706  [10000/60000]\n",
            "loss: 0.199433  [15000/60000]\n",
            "loss: 0.217013  [20000/60000]\n",
            "loss: 0.075574  [25000/60000]\n",
            "loss: 0.383400  [30000/60000]\n",
            "loss: 0.177394  [35000/60000]\n",
            "loss: 0.272902  [40000/60000]\n",
            "loss: 0.152705  [45000/60000]\n",
            "loss: 0.227820  [50000/60000]\n",
            "loss: 0.141011  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216086 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.174327  [    0/60000]\n",
            "loss: 0.115843  [ 5000/60000]\n",
            "loss: 0.235159  [10000/60000]\n",
            "loss: 0.418990  [15000/60000]\n",
            "loss: 0.156088  [20000/60000]\n",
            "loss: 0.165416  [25000/60000]\n",
            "loss: 0.192230  [30000/60000]\n",
            "loss: 0.146998  [35000/60000]\n",
            "loss: 0.062790  [40000/60000]\n",
            "loss: 0.185229  [45000/60000]\n",
            "loss: 0.236429  [50000/60000]\n",
            "loss: 0.172271  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202150 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200249  [    0/60000]\n",
            "loss: 0.343548  [ 5000/60000]\n",
            "loss: 0.238172  [10000/60000]\n",
            "loss: 0.152462  [15000/60000]\n",
            "loss: 0.101133  [20000/60000]\n",
            "loss: 0.146568  [25000/60000]\n",
            "loss: 0.241678  [30000/60000]\n",
            "loss: 0.243830  [35000/60000]\n",
            "loss: 0.270969  [40000/60000]\n",
            "loss: 0.158014  [45000/60000]\n",
            "loss: 0.331414  [50000/60000]\n",
            "loss: 0.060541  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186882 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069614  [    0/60000]\n",
            "loss: 0.128131  [ 5000/60000]\n",
            "loss: 0.211799  [10000/60000]\n",
            "loss: 0.302221  [15000/60000]\n",
            "loss: 0.314297  [20000/60000]\n",
            "loss: 0.097226  [25000/60000]\n",
            "loss: 0.200177  [30000/60000]\n",
            "loss: 0.084449  [35000/60000]\n",
            "loss: 0.281616  [40000/60000]\n",
            "loss: 0.207063  [45000/60000]\n",
            "loss: 0.139450  [50000/60000]\n",
            "loss: 0.410525  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175079 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128170  [    0/60000]\n",
            "loss: 0.284237  [ 5000/60000]\n",
            "loss: 0.232228  [10000/60000]\n",
            "loss: 0.202441  [15000/60000]\n",
            "loss: 0.132390  [20000/60000]\n",
            "loss: 0.164488  [25000/60000]\n",
            "loss: 0.166013  [30000/60000]\n",
            "loss: 0.201361  [35000/60000]\n",
            "loss: 0.061946  [40000/60000]\n",
            "loss: 0.070824  [45000/60000]\n",
            "loss: 0.175675  [50000/60000]\n",
            "loss: 0.326741  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.170625 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.241867  [    0/60000]\n",
            "loss: 0.194055  [ 5000/60000]\n",
            "loss: 0.182888  [10000/60000]\n",
            "loss: 0.290710  [15000/60000]\n",
            "loss: 0.084433  [20000/60000]\n",
            "loss: 0.158270  [25000/60000]\n",
            "loss: 0.195731  [30000/60000]\n",
            "loss: 0.161916  [35000/60000]\n",
            "loss: 0.220858  [40000/60000]\n",
            "loss: 0.044334  [45000/60000]\n",
            "loss: 0.055688  [50000/60000]\n",
            "loss: 0.108552  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159432 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.181111  [    0/60000]\n",
            "loss: 0.092809  [ 5000/60000]\n",
            "loss: 0.069553  [10000/60000]\n",
            "loss: 0.157887  [15000/60000]\n",
            "loss: 0.181291  [20000/60000]\n",
            "loss: 0.188715  [25000/60000]\n",
            "loss: 0.042288  [30000/60000]\n",
            "loss: 0.142287  [35000/60000]\n",
            "loss: 0.150014  [40000/60000]\n",
            "loss: 0.250734  [45000/60000]\n",
            "loss: 0.124975  [50000/60000]\n",
            "loss: 0.067470  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153609 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040696  [    0/60000]\n",
            "loss: 0.066443  [ 5000/60000]\n",
            "loss: 0.117037  [10000/60000]\n",
            "loss: 0.156858  [15000/60000]\n",
            "loss: 0.104682  [20000/60000]\n",
            "loss: 0.172367  [25000/60000]\n",
            "loss: 0.140945  [30000/60000]\n",
            "loss: 0.096479  [35000/60000]\n",
            "loss: 0.060588  [40000/60000]\n",
            "loss: 0.149650  [45000/60000]\n",
            "loss: 0.320611  [50000/60000]\n",
            "loss: 0.102112  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146002 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.376336  [    0/60000]\n",
            "loss: 0.174597  [ 5000/60000]\n",
            "loss: 0.189817  [10000/60000]\n",
            "loss: 0.221565  [15000/60000]\n",
            "loss: 0.167206  [20000/60000]\n",
            "loss: 0.038227  [25000/60000]\n",
            "loss: 0.093003  [30000/60000]\n",
            "loss: 0.203449  [35000/60000]\n",
            "loss: 0.057447  [40000/60000]\n",
            "loss: 0.067734  [45000/60000]\n",
            "loss: 0.043572  [50000/60000]\n",
            "loss: 0.126015  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141948 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.131014  [    0/60000]\n",
            "loss: 0.071245  [ 5000/60000]\n",
            "loss: 0.117336  [10000/60000]\n",
            "loss: 0.114351  [15000/60000]\n",
            "loss: 0.112244  [20000/60000]\n",
            "loss: 0.067706  [25000/60000]\n",
            "loss: 0.050049  [30000/60000]\n",
            "loss: 0.160949  [35000/60000]\n",
            "loss: 0.247589  [40000/60000]\n",
            "loss: 0.096104  [45000/60000]\n",
            "loss: 0.047715  [50000/60000]\n",
            "loss: 0.240362  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134774 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.473936  [    0/60000]\n",
            "loss: 0.048773  [ 5000/60000]\n",
            "loss: 0.253546  [10000/60000]\n",
            "loss: 0.251420  [15000/60000]\n",
            "loss: 0.067695  [20000/60000]\n",
            "loss: 0.077868  [25000/60000]\n",
            "loss: 0.273561  [30000/60000]\n",
            "loss: 0.109024  [35000/60000]\n",
            "loss: 0.245458  [40000/60000]\n",
            "loss: 0.079938  [45000/60000]\n",
            "loss: 0.080478  [50000/60000]\n",
            "loss: 0.166215  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133116 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149895  [    0/60000]\n",
            "loss: 0.047197  [ 5000/60000]\n",
            "loss: 0.113799  [10000/60000]\n",
            "loss: 0.010363  [15000/60000]\n",
            "loss: 0.158764  [20000/60000]\n",
            "loss: 0.084210  [25000/60000]\n",
            "loss: 0.071696  [30000/60000]\n",
            "loss: 0.052809  [35000/60000]\n",
            "loss: 0.077254  [40000/60000]\n",
            "loss: 0.164780  [45000/60000]\n",
            "loss: 0.056365  [50000/60000]\n",
            "loss: 0.210016  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.125785 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.047816  [    0/60000]\n",
            "loss: 0.063220  [ 5000/60000]\n",
            "loss: 0.247820  [10000/60000]\n",
            "loss: 0.114276  [15000/60000]\n",
            "loss: 0.102827  [20000/60000]\n",
            "loss: 0.088109  [25000/60000]\n",
            "loss: 0.081103  [30000/60000]\n",
            "loss: 0.047415  [35000/60000]\n",
            "loss: 0.123083  [40000/60000]\n",
            "loss: 0.116286  [45000/60000]\n",
            "loss: 0.447084  [50000/60000]\n",
            "loss: 0.123069  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126438 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048081  [    0/60000]\n",
            "loss: 0.140016  [ 5000/60000]\n",
            "loss: 0.066169  [10000/60000]\n",
            "loss: 0.040220  [15000/60000]\n",
            "loss: 0.098510  [20000/60000]\n",
            "loss: 0.084969  [25000/60000]\n",
            "loss: 0.175651  [30000/60000]\n",
            "loss: 0.270968  [35000/60000]\n",
            "loss: 0.042808  [40000/60000]\n",
            "loss: 0.138914  [45000/60000]\n",
            "loss: 0.138954  [50000/60000]\n",
            "loss: 0.069108  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118154 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.102053  [    0/60000]\n",
            "loss: 0.049291  [ 5000/60000]\n",
            "loss: 0.159410  [10000/60000]\n",
            "loss: 0.084010  [15000/60000]\n",
            "loss: 0.064411  [20000/60000]\n",
            "loss: 0.036478  [25000/60000]\n",
            "loss: 0.089241  [30000/60000]\n",
            "loss: 0.118804  [35000/60000]\n",
            "loss: 0.111045  [40000/60000]\n",
            "loss: 0.117352  [45000/60000]\n",
            "loss: 0.041009  [50000/60000]\n",
            "loss: 0.182341  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.116436 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.026343  [    0/60000]\n",
            "loss: 0.060650  [ 5000/60000]\n",
            "loss: 0.080159  [10000/60000]\n",
            "loss: 0.049218  [15000/60000]\n",
            "loss: 0.076638  [20000/60000]\n",
            "loss: 0.014040  [25000/60000]\n",
            "loss: 0.239765  [30000/60000]\n",
            "loss: 0.062915  [35000/60000]\n",
            "loss: 0.060115  [40000/60000]\n",
            "loss: 0.158180  [45000/60000]\n",
            "loss: 0.060644  [50000/60000]\n",
            "loss: 0.039374  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117137 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.158456  [    0/60000]\n",
            "loss: 0.128763  [ 5000/60000]\n",
            "loss: 0.084637  [10000/60000]\n",
            "loss: 0.093640  [15000/60000]\n",
            "loss: 0.316531  [20000/60000]\n",
            "loss: 0.076358  [25000/60000]\n",
            "loss: 0.084071  [30000/60000]\n",
            "loss: 0.089063  [35000/60000]\n",
            "loss: 0.143812  [40000/60000]\n",
            "loss: 0.042755  [45000/60000]\n",
            "loss: 0.089546  [50000/60000]\n",
            "loss: 0.039712  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113340 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.119683  [    0/60000]\n",
            "loss: 0.082017  [ 5000/60000]\n",
            "loss: 0.175764  [10000/60000]\n",
            "loss: 0.098159  [15000/60000]\n",
            "loss: 0.061973  [20000/60000]\n",
            "loss: 0.072210  [25000/60000]\n",
            "loss: 0.029197  [30000/60000]\n",
            "loss: 0.010616  [35000/60000]\n",
            "loss: 0.093625  [40000/60000]\n",
            "loss: 0.100483  [45000/60000]\n",
            "loss: 0.056550  [50000/60000]\n",
            "loss: 0.169033  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.107991 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.231868  [    0/60000]\n",
            "loss: 0.156677  [ 5000/60000]\n",
            "loss: 0.046382  [10000/60000]\n",
            "loss: 0.032986  [15000/60000]\n",
            "loss: 0.025647  [20000/60000]\n",
            "loss: 0.178137  [25000/60000]\n",
            "loss: 0.102927  [30000/60000]\n",
            "loss: 0.165276  [35000/60000]\n",
            "loss: 0.095308  [40000/60000]\n",
            "loss: 0.050816  [45000/60000]\n",
            "loss: 0.089232  [50000/60000]\n",
            "loss: 0.157240  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107308 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050348  [    0/60000]\n",
            "loss: 0.136231  [ 5000/60000]\n",
            "loss: 0.105044  [10000/60000]\n",
            "loss: 0.235595  [15000/60000]\n",
            "loss: 0.048804  [20000/60000]\n",
            "loss: 0.086098  [25000/60000]\n",
            "loss: 0.041038  [30000/60000]\n",
            "loss: 0.211495  [35000/60000]\n",
            "loss: 0.039901  [40000/60000]\n",
            "loss: 0.010614  [45000/60000]\n",
            "loss: 0.242241  [50000/60000]\n",
            "loss: 0.168750  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.103868 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034555  [    0/60000]\n",
            "loss: 0.224387  [ 5000/60000]\n",
            "loss: 0.040488  [10000/60000]\n",
            "loss: 0.060645  [15000/60000]\n",
            "loss: 0.015722  [20000/60000]\n",
            "loss: 0.031568  [25000/60000]\n",
            "loss: 0.155628  [30000/60000]\n",
            "loss: 0.066334  [35000/60000]\n",
            "loss: 0.171373  [40000/60000]\n",
            "loss: 0.011922  [45000/60000]\n",
            "loss: 0.066464  [50000/60000]\n",
            "loss: 0.073297  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.100957 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.138964  [    0/60000]\n",
            "loss: 0.021089  [ 5000/60000]\n",
            "loss: 0.039010  [10000/60000]\n",
            "loss: 0.118053  [15000/60000]\n",
            "loss: 0.066985  [20000/60000]\n",
            "loss: 0.139476  [25000/60000]\n",
            "loss: 0.049827  [30000/60000]\n",
            "loss: 0.033588  [35000/60000]\n",
            "loss: 0.162773  [40000/60000]\n",
            "loss: 0.097764  [45000/60000]\n",
            "loss: 0.044194  [50000/60000]\n",
            "loss: 0.030096  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098980 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048598  [    0/60000]\n",
            "loss: 0.054576  [ 5000/60000]\n",
            "loss: 0.069792  [10000/60000]\n",
            "loss: 0.031864  [15000/60000]\n",
            "loss: 0.024533  [20000/60000]\n",
            "loss: 0.080419  [25000/60000]\n",
            "loss: 0.067997  [30000/60000]\n",
            "loss: 0.158219  [35000/60000]\n",
            "loss: 0.042596  [40000/60000]\n",
            "loss: 0.090974  [45000/60000]\n",
            "loss: 0.059100  [50000/60000]\n",
            "loss: 0.103787  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099510 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 1\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314301  [30000/60000]\n",
            "loss: 1.119912  [35000/60000]\n",
            "loss: 1.104669  [40000/60000]\n",
            "loss: 1.037258  [45000/60000]\n",
            "loss: 0.860640  [50000/60000]\n",
            "loss: 0.646582  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590782 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629870  [    0/60000]\n",
            "loss: 0.527618  [ 5000/60000]\n",
            "loss: 0.491029  [10000/60000]\n",
            "loss: 0.540440  [15000/60000]\n",
            "loss: 0.418385  [20000/60000]\n",
            "loss: 0.493025  [25000/60000]\n",
            "loss: 0.458751  [30000/60000]\n",
            "loss: 0.487822  [35000/60000]\n",
            "loss: 0.718841  [40000/60000]\n",
            "loss: 0.727034  [45000/60000]\n",
            "loss: 0.260493  [50000/60000]\n",
            "loss: 0.347200  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379056 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231745  [    0/60000]\n",
            "loss: 0.206718  [ 5000/60000]\n",
            "loss: 0.527511  [10000/60000]\n",
            "loss: 0.144636  [15000/60000]\n",
            "loss: 0.355160  [20000/60000]\n",
            "loss: 0.215272  [25000/60000]\n",
            "loss: 0.446777  [30000/60000]\n",
            "loss: 0.289294  [35000/60000]\n",
            "loss: 0.366922  [40000/60000]\n",
            "loss: 0.569209  [45000/60000]\n",
            "loss: 0.331889  [50000/60000]\n",
            "loss: 0.502977  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325592 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397439  [    0/60000]\n",
            "loss: 0.817256  [ 5000/60000]\n",
            "loss: 0.415086  [10000/60000]\n",
            "loss: 0.300880  [15000/60000]\n",
            "loss: 0.449597  [20000/60000]\n",
            "loss: 0.402234  [25000/60000]\n",
            "loss: 0.228471  [30000/60000]\n",
            "loss: 0.368608  [35000/60000]\n",
            "loss: 0.498273  [40000/60000]\n",
            "loss: 0.470889  [45000/60000]\n",
            "loss: 0.396883  [50000/60000]\n",
            "loss: 0.217862  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290560 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231091  [    0/60000]\n",
            "loss: 0.209327  [ 5000/60000]\n",
            "loss: 0.142446  [10000/60000]\n",
            "loss: 0.434467  [15000/60000]\n",
            "loss: 0.322938  [20000/60000]\n",
            "loss: 0.134304  [25000/60000]\n",
            "loss: 0.122899  [30000/60000]\n",
            "loss: 0.419494  [35000/60000]\n",
            "loss: 0.286975  [40000/60000]\n",
            "loss: 0.309961  [45000/60000]\n",
            "loss: 0.223168  [50000/60000]\n",
            "loss: 0.534863  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268326 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166894  [    0/60000]\n",
            "loss: 0.177031  [ 5000/60000]\n",
            "loss: 0.144233  [10000/60000]\n",
            "loss: 0.474966  [15000/60000]\n",
            "loss: 0.372302  [20000/60000]\n",
            "loss: 0.264066  [25000/60000]\n",
            "loss: 0.279748  [30000/60000]\n",
            "loss: 0.195895  [35000/60000]\n",
            "loss: 0.163337  [40000/60000]\n",
            "loss: 0.166332  [45000/60000]\n",
            "loss: 0.294977  [50000/60000]\n",
            "loss: 0.314473  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.247337 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146523  [    0/60000]\n",
            "loss: 0.337818  [ 5000/60000]\n",
            "loss: 0.349787  [10000/60000]\n",
            "loss: 0.121992  [15000/60000]\n",
            "loss: 0.176776  [20000/60000]\n",
            "loss: 0.189409  [25000/60000]\n",
            "loss: 0.255434  [30000/60000]\n",
            "loss: 0.112715  [35000/60000]\n",
            "loss: 0.263365  [40000/60000]\n",
            "loss: 0.385932  [45000/60000]\n",
            "loss: 0.374054  [50000/60000]\n",
            "loss: 0.067688  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228131 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193396  [    0/60000]\n",
            "loss: 0.192626  [ 5000/60000]\n",
            "loss: 0.210625  [10000/60000]\n",
            "loss: 0.199396  [15000/60000]\n",
            "loss: 0.216860  [20000/60000]\n",
            "loss: 0.075664  [25000/60000]\n",
            "loss: 0.383157  [30000/60000]\n",
            "loss: 0.177330  [35000/60000]\n",
            "loss: 0.272900  [40000/60000]\n",
            "loss: 0.152641  [45000/60000]\n",
            "loss: 0.227610  [50000/60000]\n",
            "loss: 0.141011  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216047 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.173968  [    0/60000]\n",
            "loss: 0.115864  [ 5000/60000]\n",
            "loss: 0.235022  [10000/60000]\n",
            "loss: 0.418947  [15000/60000]\n",
            "loss: 0.156097  [20000/60000]\n",
            "loss: 0.165275  [25000/60000]\n",
            "loss: 0.192202  [30000/60000]\n",
            "loss: 0.146865  [35000/60000]\n",
            "loss: 0.062845  [40000/60000]\n",
            "loss: 0.184957  [45000/60000]\n",
            "loss: 0.236699  [50000/60000]\n",
            "loss: 0.172332  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202123 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200578  [    0/60000]\n",
            "loss: 0.343323  [ 5000/60000]\n",
            "loss: 0.237987  [10000/60000]\n",
            "loss: 0.152491  [15000/60000]\n",
            "loss: 0.101157  [20000/60000]\n",
            "loss: 0.146499  [25000/60000]\n",
            "loss: 0.241788  [30000/60000]\n",
            "loss: 0.243499  [35000/60000]\n",
            "loss: 0.270920  [40000/60000]\n",
            "loss: 0.158051  [45000/60000]\n",
            "loss: 0.331599  [50000/60000]\n",
            "loss: 0.060594  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186849 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069365  [    0/60000]\n",
            "loss: 0.128137  [ 5000/60000]\n",
            "loss: 0.212010  [10000/60000]\n",
            "loss: 0.301579  [15000/60000]\n",
            "loss: 0.314120  [20000/60000]\n",
            "loss: 0.097056  [25000/60000]\n",
            "loss: 0.200265  [30000/60000]\n",
            "loss: 0.084614  [35000/60000]\n",
            "loss: 0.281740  [40000/60000]\n",
            "loss: 0.206960  [45000/60000]\n",
            "loss: 0.139700  [50000/60000]\n",
            "loss: 0.410063  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175098 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128751  [    0/60000]\n",
            "loss: 0.284269  [ 5000/60000]\n",
            "loss: 0.232431  [10000/60000]\n",
            "loss: 0.202156  [15000/60000]\n",
            "loss: 0.132609  [20000/60000]\n",
            "loss: 0.164306  [25000/60000]\n",
            "loss: 0.166152  [30000/60000]\n",
            "loss: 0.201405  [35000/60000]\n",
            "loss: 0.061973  [40000/60000]\n",
            "loss: 0.070828  [45000/60000]\n",
            "loss: 0.175281  [50000/60000]\n",
            "loss: 0.326891  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.170638 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.241645  [    0/60000]\n",
            "loss: 0.193890  [ 5000/60000]\n",
            "loss: 0.182463  [10000/60000]\n",
            "loss: 0.290879  [15000/60000]\n",
            "loss: 0.084603  [20000/60000]\n",
            "loss: 0.158758  [25000/60000]\n",
            "loss: 0.195921  [30000/60000]\n",
            "loss: 0.161697  [35000/60000]\n",
            "loss: 0.220629  [40000/60000]\n",
            "loss: 0.044356  [45000/60000]\n",
            "loss: 0.055725  [50000/60000]\n",
            "loss: 0.108658  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159484 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.181032  [    0/60000]\n",
            "loss: 0.092717  [ 5000/60000]\n",
            "loss: 0.069615  [10000/60000]\n",
            "loss: 0.158181  [15000/60000]\n",
            "loss: 0.180891  [20000/60000]\n",
            "loss: 0.188375  [25000/60000]\n",
            "loss: 0.042358  [30000/60000]\n",
            "loss: 0.142074  [35000/60000]\n",
            "loss: 0.149950  [40000/60000]\n",
            "loss: 0.250810  [45000/60000]\n",
            "loss: 0.125395  [50000/60000]\n",
            "loss: 0.067302  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153614 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040453  [    0/60000]\n",
            "loss: 0.066427  [ 5000/60000]\n",
            "loss: 0.116861  [10000/60000]\n",
            "loss: 0.157395  [15000/60000]\n",
            "loss: 0.104721  [20000/60000]\n",
            "loss: 0.172182  [25000/60000]\n",
            "loss: 0.141000  [30000/60000]\n",
            "loss: 0.096618  [35000/60000]\n",
            "loss: 0.060637  [40000/60000]\n",
            "loss: 0.149507  [45000/60000]\n",
            "loss: 0.321694  [50000/60000]\n",
            "loss: 0.102360  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146064 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.376903  [    0/60000]\n",
            "loss: 0.174515  [ 5000/60000]\n",
            "loss: 0.189931  [10000/60000]\n",
            "loss: 0.222109  [15000/60000]\n",
            "loss: 0.167054  [20000/60000]\n",
            "loss: 0.038262  [25000/60000]\n",
            "loss: 0.092932  [30000/60000]\n",
            "loss: 0.204300  [35000/60000]\n",
            "loss: 0.057396  [40000/60000]\n",
            "loss: 0.067996  [45000/60000]\n",
            "loss: 0.043446  [50000/60000]\n",
            "loss: 0.125754  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141970 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.130915  [    0/60000]\n",
            "loss: 0.071221  [ 5000/60000]\n",
            "loss: 0.117283  [10000/60000]\n",
            "loss: 0.114694  [15000/60000]\n",
            "loss: 0.111807  [20000/60000]\n",
            "loss: 0.068000  [25000/60000]\n",
            "loss: 0.050104  [30000/60000]\n",
            "loss: 0.160240  [35000/60000]\n",
            "loss: 0.247225  [40000/60000]\n",
            "loss: 0.096264  [45000/60000]\n",
            "loss: 0.047665  [50000/60000]\n",
            "loss: 0.240368  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134753 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.473175  [    0/60000]\n",
            "loss: 0.048604  [ 5000/60000]\n",
            "loss: 0.253192  [10000/60000]\n",
            "loss: 0.251264  [15000/60000]\n",
            "loss: 0.067826  [20000/60000]\n",
            "loss: 0.077995  [25000/60000]\n",
            "loss: 0.273355  [30000/60000]\n",
            "loss: 0.108524  [35000/60000]\n",
            "loss: 0.245708  [40000/60000]\n",
            "loss: 0.080232  [45000/60000]\n",
            "loss: 0.080320  [50000/60000]\n",
            "loss: 0.167017  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133103 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149917  [    0/60000]\n",
            "loss: 0.046955  [ 5000/60000]\n",
            "loss: 0.113944  [10000/60000]\n",
            "loss: 0.010364  [15000/60000]\n",
            "loss: 0.159273  [20000/60000]\n",
            "loss: 0.084235  [25000/60000]\n",
            "loss: 0.071607  [30000/60000]\n",
            "loss: 0.052678  [35000/60000]\n",
            "loss: 0.077169  [40000/60000]\n",
            "loss: 0.163955  [45000/60000]\n",
            "loss: 0.056205  [50000/60000]\n",
            "loss: 0.210510  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.125748 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.048006  [    0/60000]\n",
            "loss: 0.063013  [ 5000/60000]\n",
            "loss: 0.246081  [10000/60000]\n",
            "loss: 0.115170  [15000/60000]\n",
            "loss: 0.102661  [20000/60000]\n",
            "loss: 0.088026  [25000/60000]\n",
            "loss: 0.080510  [30000/60000]\n",
            "loss: 0.047425  [35000/60000]\n",
            "loss: 0.123769  [40000/60000]\n",
            "loss: 0.116660  [45000/60000]\n",
            "loss: 0.447344  [50000/60000]\n",
            "loss: 0.123706  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126473 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048020  [    0/60000]\n",
            "loss: 0.140331  [ 5000/60000]\n",
            "loss: 0.066576  [10000/60000]\n",
            "loss: 0.039780  [15000/60000]\n",
            "loss: 0.098822  [20000/60000]\n",
            "loss: 0.084830  [25000/60000]\n",
            "loss: 0.175255  [30000/60000]\n",
            "loss: 0.270742  [35000/60000]\n",
            "loss: 0.042803  [40000/60000]\n",
            "loss: 0.138309  [45000/60000]\n",
            "loss: 0.139486  [50000/60000]\n",
            "loss: 0.068933  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118177 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.101956  [    0/60000]\n",
            "loss: 0.049398  [ 5000/60000]\n",
            "loss: 0.159581  [10000/60000]\n",
            "loss: 0.083281  [15000/60000]\n",
            "loss: 0.064650  [20000/60000]\n",
            "loss: 0.036469  [25000/60000]\n",
            "loss: 0.089885  [30000/60000]\n",
            "loss: 0.119322  [35000/60000]\n",
            "loss: 0.111575  [40000/60000]\n",
            "loss: 0.117120  [45000/60000]\n",
            "loss: 0.041390  [50000/60000]\n",
            "loss: 0.182508  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.116342 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.026039  [    0/60000]\n",
            "loss: 0.060299  [ 5000/60000]\n",
            "loss: 0.080013  [10000/60000]\n",
            "loss: 0.049276  [15000/60000]\n",
            "loss: 0.077087  [20000/60000]\n",
            "loss: 0.013978  [25000/60000]\n",
            "loss: 0.239563  [30000/60000]\n",
            "loss: 0.062593  [35000/60000]\n",
            "loss: 0.060063  [40000/60000]\n",
            "loss: 0.158399  [45000/60000]\n",
            "loss: 0.061179  [50000/60000]\n",
            "loss: 0.039328  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117274 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.159093  [    0/60000]\n",
            "loss: 0.129075  [ 5000/60000]\n",
            "loss: 0.084540  [10000/60000]\n",
            "loss: 0.093300  [15000/60000]\n",
            "loss: 0.315196  [20000/60000]\n",
            "loss: 0.075742  [25000/60000]\n",
            "loss: 0.083341  [30000/60000]\n",
            "loss: 0.089176  [35000/60000]\n",
            "loss: 0.144019  [40000/60000]\n",
            "loss: 0.042658  [45000/60000]\n",
            "loss: 0.090172  [50000/60000]\n",
            "loss: 0.040304  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113273 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.119356  [    0/60000]\n",
            "loss: 0.081854  [ 5000/60000]\n",
            "loss: 0.175055  [10000/60000]\n",
            "loss: 0.098215  [15000/60000]\n",
            "loss: 0.061633  [20000/60000]\n",
            "loss: 0.071112  [25000/60000]\n",
            "loss: 0.029171  [30000/60000]\n",
            "loss: 0.010608  [35000/60000]\n",
            "loss: 0.094842  [40000/60000]\n",
            "loss: 0.101679  [45000/60000]\n",
            "loss: 0.056409  [50000/60000]\n",
            "loss: 0.169183  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107982 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.233445  [    0/60000]\n",
            "loss: 0.155846  [ 5000/60000]\n",
            "loss: 0.046152  [10000/60000]\n",
            "loss: 0.033175  [15000/60000]\n",
            "loss: 0.025623  [20000/60000]\n",
            "loss: 0.177257  [25000/60000]\n",
            "loss: 0.102562  [30000/60000]\n",
            "loss: 0.164145  [35000/60000]\n",
            "loss: 0.095199  [40000/60000]\n",
            "loss: 0.050368  [45000/60000]\n",
            "loss: 0.088643  [50000/60000]\n",
            "loss: 0.157141  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107315 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050420  [    0/60000]\n",
            "loss: 0.137369  [ 5000/60000]\n",
            "loss: 0.105132  [10000/60000]\n",
            "loss: 0.234378  [15000/60000]\n",
            "loss: 0.048644  [20000/60000]\n",
            "loss: 0.085352  [25000/60000]\n",
            "loss: 0.041565  [30000/60000]\n",
            "loss: 0.212540  [35000/60000]\n",
            "loss: 0.039778  [40000/60000]\n",
            "loss: 0.010675  [45000/60000]\n",
            "loss: 0.242117  [50000/60000]\n",
            "loss: 0.168630  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103808 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034158  [    0/60000]\n",
            "loss: 0.224229  [ 5000/60000]\n",
            "loss: 0.040405  [10000/60000]\n",
            "loss: 0.060100  [15000/60000]\n",
            "loss: 0.015584  [20000/60000]\n",
            "loss: 0.031545  [25000/60000]\n",
            "loss: 0.155369  [30000/60000]\n",
            "loss: 0.067840  [35000/60000]\n",
            "loss: 0.170431  [40000/60000]\n",
            "loss: 0.012051  [45000/60000]\n",
            "loss: 0.066014  [50000/60000]\n",
            "loss: 0.073203  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.101001 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.137468  [    0/60000]\n",
            "loss: 0.021332  [ 5000/60000]\n",
            "loss: 0.038790  [10000/60000]\n",
            "loss: 0.117144  [15000/60000]\n",
            "loss: 0.066639  [20000/60000]\n",
            "loss: 0.139300  [25000/60000]\n",
            "loss: 0.049306  [30000/60000]\n",
            "loss: 0.033541  [35000/60000]\n",
            "loss: 0.163180  [40000/60000]\n",
            "loss: 0.097214  [45000/60000]\n",
            "loss: 0.044569  [50000/60000]\n",
            "loss: 0.030463  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098897 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.047906  [    0/60000]\n",
            "loss: 0.054461  [ 5000/60000]\n",
            "loss: 0.070114  [10000/60000]\n",
            "loss: 0.032005  [15000/60000]\n",
            "loss: 0.024259  [20000/60000]\n",
            "loss: 0.080399  [25000/60000]\n",
            "loss: 0.068356  [30000/60000]\n",
            "loss: 0.157689  [35000/60000]\n",
            "loss: 0.043285  [40000/60000]\n",
            "loss: 0.089743  [45000/60000]\n",
            "loss: 0.059149  [50000/60000]\n",
            "loss: 0.103621  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099558 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 2\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314122  [30000/60000]\n",
            "loss: 1.119836  [35000/60000]\n",
            "loss: 1.104734  [40000/60000]\n",
            "loss: 1.037225  [45000/60000]\n",
            "loss: 0.860640  [50000/60000]\n",
            "loss: 0.646573  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590774 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629868  [    0/60000]\n",
            "loss: 0.527590  [ 5000/60000]\n",
            "loss: 0.491023  [10000/60000]\n",
            "loss: 0.540455  [15000/60000]\n",
            "loss: 0.418389  [20000/60000]\n",
            "loss: 0.492998  [25000/60000]\n",
            "loss: 0.458780  [30000/60000]\n",
            "loss: 0.487742  [35000/60000]\n",
            "loss: 0.718825  [40000/60000]\n",
            "loss: 0.726961  [45000/60000]\n",
            "loss: 0.260495  [50000/60000]\n",
            "loss: 0.347363  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379048 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231745  [    0/60000]\n",
            "loss: 0.206686  [ 5000/60000]\n",
            "loss: 0.527713  [10000/60000]\n",
            "loss: 0.144540  [15000/60000]\n",
            "loss: 0.355196  [20000/60000]\n",
            "loss: 0.215274  [25000/60000]\n",
            "loss: 0.446829  [30000/60000]\n",
            "loss: 0.289326  [35000/60000]\n",
            "loss: 0.366740  [40000/60000]\n",
            "loss: 0.569225  [45000/60000]\n",
            "loss: 0.331867  [50000/60000]\n",
            "loss: 0.502949  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325592 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397488  [    0/60000]\n",
            "loss: 0.817433  [ 5000/60000]\n",
            "loss: 0.415160  [10000/60000]\n",
            "loss: 0.300833  [15000/60000]\n",
            "loss: 0.449546  [20000/60000]\n",
            "loss: 0.402323  [25000/60000]\n",
            "loss: 0.228604  [30000/60000]\n",
            "loss: 0.368727  [35000/60000]\n",
            "loss: 0.498603  [40000/60000]\n",
            "loss: 0.470921  [45000/60000]\n",
            "loss: 0.396889  [50000/60000]\n",
            "loss: 0.217797  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290578 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231019  [    0/60000]\n",
            "loss: 0.209499  [ 5000/60000]\n",
            "loss: 0.142238  [10000/60000]\n",
            "loss: 0.434307  [15000/60000]\n",
            "loss: 0.323190  [20000/60000]\n",
            "loss: 0.134340  [25000/60000]\n",
            "loss: 0.122821  [30000/60000]\n",
            "loss: 0.419329  [35000/60000]\n",
            "loss: 0.286757  [40000/60000]\n",
            "loss: 0.310054  [45000/60000]\n",
            "loss: 0.223136  [50000/60000]\n",
            "loss: 0.534865  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268357 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166968  [    0/60000]\n",
            "loss: 0.176748  [ 5000/60000]\n",
            "loss: 0.144342  [10000/60000]\n",
            "loss: 0.475091  [15000/60000]\n",
            "loss: 0.372427  [20000/60000]\n",
            "loss: 0.263976  [25000/60000]\n",
            "loss: 0.279563  [30000/60000]\n",
            "loss: 0.195781  [35000/60000]\n",
            "loss: 0.163322  [40000/60000]\n",
            "loss: 0.166238  [45000/60000]\n",
            "loss: 0.294766  [50000/60000]\n",
            "loss: 0.314458  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.247366 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146404  [    0/60000]\n",
            "loss: 0.337894  [ 5000/60000]\n",
            "loss: 0.350042  [10000/60000]\n",
            "loss: 0.121764  [15000/60000]\n",
            "loss: 0.175374  [20000/60000]\n",
            "loss: 0.189517  [25000/60000]\n",
            "loss: 0.255865  [30000/60000]\n",
            "loss: 0.112821  [35000/60000]\n",
            "loss: 0.263733  [40000/60000]\n",
            "loss: 0.385698  [45000/60000]\n",
            "loss: 0.374780  [50000/60000]\n",
            "loss: 0.067890  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228229 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193418  [    0/60000]\n",
            "loss: 0.192295  [ 5000/60000]\n",
            "loss: 0.210870  [10000/60000]\n",
            "loss: 0.199284  [15000/60000]\n",
            "loss: 0.217012  [20000/60000]\n",
            "loss: 0.075705  [25000/60000]\n",
            "loss: 0.382478  [30000/60000]\n",
            "loss: 0.177565  [35000/60000]\n",
            "loss: 0.272612  [40000/60000]\n",
            "loss: 0.152944  [45000/60000]\n",
            "loss: 0.227764  [50000/60000]\n",
            "loss: 0.141199  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216143 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.174460  [    0/60000]\n",
            "loss: 0.115911  [ 5000/60000]\n",
            "loss: 0.235358  [10000/60000]\n",
            "loss: 0.418504  [15000/60000]\n",
            "loss: 0.155969  [20000/60000]\n",
            "loss: 0.164821  [25000/60000]\n",
            "loss: 0.191667  [30000/60000]\n",
            "loss: 0.146716  [35000/60000]\n",
            "loss: 0.062731  [40000/60000]\n",
            "loss: 0.184844  [45000/60000]\n",
            "loss: 0.236722  [50000/60000]\n",
            "loss: 0.172311  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202190 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200211  [    0/60000]\n",
            "loss: 0.343634  [ 5000/60000]\n",
            "loss: 0.237895  [10000/60000]\n",
            "loss: 0.152317  [15000/60000]\n",
            "loss: 0.101202  [20000/60000]\n",
            "loss: 0.146408  [25000/60000]\n",
            "loss: 0.242149  [30000/60000]\n",
            "loss: 0.243791  [35000/60000]\n",
            "loss: 0.270947  [40000/60000]\n",
            "loss: 0.157993  [45000/60000]\n",
            "loss: 0.332043  [50000/60000]\n",
            "loss: 0.060467  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186906 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069665  [    0/60000]\n",
            "loss: 0.128087  [ 5000/60000]\n",
            "loss: 0.211903  [10000/60000]\n",
            "loss: 0.301494  [15000/60000]\n",
            "loss: 0.313510  [20000/60000]\n",
            "loss: 0.097238  [25000/60000]\n",
            "loss: 0.199897  [30000/60000]\n",
            "loss: 0.084719  [35000/60000]\n",
            "loss: 0.281413  [40000/60000]\n",
            "loss: 0.206916  [45000/60000]\n",
            "loss: 0.139597  [50000/60000]\n",
            "loss: 0.410346  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175119 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128565  [    0/60000]\n",
            "loss: 0.284170  [ 5000/60000]\n",
            "loss: 0.232188  [10000/60000]\n",
            "loss: 0.202049  [15000/60000]\n",
            "loss: 0.133007  [20000/60000]\n",
            "loss: 0.164834  [25000/60000]\n",
            "loss: 0.166063  [30000/60000]\n",
            "loss: 0.200964  [35000/60000]\n",
            "loss: 0.061890  [40000/60000]\n",
            "loss: 0.070721  [45000/60000]\n",
            "loss: 0.175294  [50000/60000]\n",
            "loss: 0.326853  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.170664 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.242479  [    0/60000]\n",
            "loss: 0.193730  [ 5000/60000]\n",
            "loss: 0.182462  [10000/60000]\n",
            "loss: 0.291041  [15000/60000]\n",
            "loss: 0.084561  [20000/60000]\n",
            "loss: 0.158649  [25000/60000]\n",
            "loss: 0.195774  [30000/60000]\n",
            "loss: 0.161351  [35000/60000]\n",
            "loss: 0.220623  [40000/60000]\n",
            "loss: 0.044613  [45000/60000]\n",
            "loss: 0.055700  [50000/60000]\n",
            "loss: 0.108778  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159490 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.181186  [    0/60000]\n",
            "loss: 0.092684  [ 5000/60000]\n",
            "loss: 0.069336  [10000/60000]\n",
            "loss: 0.158137  [15000/60000]\n",
            "loss: 0.181367  [20000/60000]\n",
            "loss: 0.187979  [25000/60000]\n",
            "loss: 0.042217  [30000/60000]\n",
            "loss: 0.142176  [35000/60000]\n",
            "loss: 0.149856  [40000/60000]\n",
            "loss: 0.250822  [45000/60000]\n",
            "loss: 0.125476  [50000/60000]\n",
            "loss: 0.067290  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153691 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040561  [    0/60000]\n",
            "loss: 0.066524  [ 5000/60000]\n",
            "loss: 0.116791  [10000/60000]\n",
            "loss: 0.156668  [15000/60000]\n",
            "loss: 0.104713  [20000/60000]\n",
            "loss: 0.171124  [25000/60000]\n",
            "loss: 0.142400  [30000/60000]\n",
            "loss: 0.096004  [35000/60000]\n",
            "loss: 0.060600  [40000/60000]\n",
            "loss: 0.149341  [45000/60000]\n",
            "loss: 0.323102  [50000/60000]\n",
            "loss: 0.101780  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146114 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.376925  [    0/60000]\n",
            "loss: 0.175427  [ 5000/60000]\n",
            "loss: 0.189227  [10000/60000]\n",
            "loss: 0.220950  [15000/60000]\n",
            "loss: 0.167762  [20000/60000]\n",
            "loss: 0.038304  [25000/60000]\n",
            "loss: 0.092671  [30000/60000]\n",
            "loss: 0.204123  [35000/60000]\n",
            "loss: 0.057389  [40000/60000]\n",
            "loss: 0.067994  [45000/60000]\n",
            "loss: 0.043291  [50000/60000]\n",
            "loss: 0.125093  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.142028 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.130888  [    0/60000]\n",
            "loss: 0.071333  [ 5000/60000]\n",
            "loss: 0.116641  [10000/60000]\n",
            "loss: 0.115037  [15000/60000]\n",
            "loss: 0.111929  [20000/60000]\n",
            "loss: 0.067604  [25000/60000]\n",
            "loss: 0.050230  [30000/60000]\n",
            "loss: 0.161016  [35000/60000]\n",
            "loss: 0.250125  [40000/60000]\n",
            "loss: 0.096313  [45000/60000]\n",
            "loss: 0.047578  [50000/60000]\n",
            "loss: 0.240936  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134854 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.473503  [    0/60000]\n",
            "loss: 0.049080  [ 5000/60000]\n",
            "loss: 0.253408  [10000/60000]\n",
            "loss: 0.251665  [15000/60000]\n",
            "loss: 0.068195  [20000/60000]\n",
            "loss: 0.077708  [25000/60000]\n",
            "loss: 0.273488  [30000/60000]\n",
            "loss: 0.109594  [35000/60000]\n",
            "loss: 0.246466  [40000/60000]\n",
            "loss: 0.080191  [45000/60000]\n",
            "loss: 0.080745  [50000/60000]\n",
            "loss: 0.166258  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133216 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149791  [    0/60000]\n",
            "loss: 0.046802  [ 5000/60000]\n",
            "loss: 0.114378  [10000/60000]\n",
            "loss: 0.010350  [15000/60000]\n",
            "loss: 0.159788  [20000/60000]\n",
            "loss: 0.084168  [25000/60000]\n",
            "loss: 0.071590  [30000/60000]\n",
            "loss: 0.052376  [35000/60000]\n",
            "loss: 0.077276  [40000/60000]\n",
            "loss: 0.162432  [45000/60000]\n",
            "loss: 0.056504  [50000/60000]\n",
            "loss: 0.212610  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.125933 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.048463  [    0/60000]\n",
            "loss: 0.063818  [ 5000/60000]\n",
            "loss: 0.246524  [10000/60000]\n",
            "loss: 0.114164  [15000/60000]\n",
            "loss: 0.102988  [20000/60000]\n",
            "loss: 0.087738  [25000/60000]\n",
            "loss: 0.081190  [30000/60000]\n",
            "loss: 0.047671  [35000/60000]\n",
            "loss: 0.124588  [40000/60000]\n",
            "loss: 0.116597  [45000/60000]\n",
            "loss: 0.446821  [50000/60000]\n",
            "loss: 0.123679  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126566 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048211  [    0/60000]\n",
            "loss: 0.141490  [ 5000/60000]\n",
            "loss: 0.066558  [10000/60000]\n",
            "loss: 0.039399  [15000/60000]\n",
            "loss: 0.098815  [20000/60000]\n",
            "loss: 0.085174  [25000/60000]\n",
            "loss: 0.174586  [30000/60000]\n",
            "loss: 0.271127  [35000/60000]\n",
            "loss: 0.043096  [40000/60000]\n",
            "loss: 0.139855  [45000/60000]\n",
            "loss: 0.138292  [50000/60000]\n",
            "loss: 0.070119  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118254 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.101509  [    0/60000]\n",
            "loss: 0.049669  [ 5000/60000]\n",
            "loss: 0.159837  [10000/60000]\n",
            "loss: 0.083155  [15000/60000]\n",
            "loss: 0.064504  [20000/60000]\n",
            "loss: 0.036654  [25000/60000]\n",
            "loss: 0.088662  [30000/60000]\n",
            "loss: 0.119747  [35000/60000]\n",
            "loss: 0.111348  [40000/60000]\n",
            "loss: 0.117204  [45000/60000]\n",
            "loss: 0.041189  [50000/60000]\n",
            "loss: 0.183606  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.116473 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.026238  [    0/60000]\n",
            "loss: 0.060312  [ 5000/60000]\n",
            "loss: 0.079563  [10000/60000]\n",
            "loss: 0.049467  [15000/60000]\n",
            "loss: 0.076498  [20000/60000]\n",
            "loss: 0.013959  [25000/60000]\n",
            "loss: 0.239085  [30000/60000]\n",
            "loss: 0.063229  [35000/60000]\n",
            "loss: 0.060779  [40000/60000]\n",
            "loss: 0.159308  [45000/60000]\n",
            "loss: 0.061176  [50000/60000]\n",
            "loss: 0.039590  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117276 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.159944  [    0/60000]\n",
            "loss: 0.128471  [ 5000/60000]\n",
            "loss: 0.083973  [10000/60000]\n",
            "loss: 0.092732  [15000/60000]\n",
            "loss: 0.316406  [20000/60000]\n",
            "loss: 0.076347  [25000/60000]\n",
            "loss: 0.083912  [30000/60000]\n",
            "loss: 0.089193  [35000/60000]\n",
            "loss: 0.144343  [40000/60000]\n",
            "loss: 0.042400  [45000/60000]\n",
            "loss: 0.089989  [50000/60000]\n",
            "loss: 0.040074  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113451 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.120661  [    0/60000]\n",
            "loss: 0.082635  [ 5000/60000]\n",
            "loss: 0.176039  [10000/60000]\n",
            "loss: 0.097907  [15000/60000]\n",
            "loss: 0.062559  [20000/60000]\n",
            "loss: 0.071305  [25000/60000]\n",
            "loss: 0.029174  [30000/60000]\n",
            "loss: 0.010479  [35000/60000]\n",
            "loss: 0.092974  [40000/60000]\n",
            "loss: 0.101352  [45000/60000]\n",
            "loss: 0.055450  [50000/60000]\n",
            "loss: 0.166816  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.108047 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.232970  [    0/60000]\n",
            "loss: 0.156704  [ 5000/60000]\n",
            "loss: 0.045503  [10000/60000]\n",
            "loss: 0.035105  [15000/60000]\n",
            "loss: 0.025852  [20000/60000]\n",
            "loss: 0.181530  [25000/60000]\n",
            "loss: 0.103604  [30000/60000]\n",
            "loss: 0.163769  [35000/60000]\n",
            "loss: 0.097872  [40000/60000]\n",
            "loss: 0.050828  [45000/60000]\n",
            "loss: 0.086947  [50000/60000]\n",
            "loss: 0.157945  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.107346 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050774  [    0/60000]\n",
            "loss: 0.135995  [ 5000/60000]\n",
            "loss: 0.106842  [10000/60000]\n",
            "loss: 0.233084  [15000/60000]\n",
            "loss: 0.049044  [20000/60000]\n",
            "loss: 0.086927  [25000/60000]\n",
            "loss: 0.040883  [30000/60000]\n",
            "loss: 0.211684  [35000/60000]\n",
            "loss: 0.039356  [40000/60000]\n",
            "loss: 0.010602  [45000/60000]\n",
            "loss: 0.242092  [50000/60000]\n",
            "loss: 0.161213  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103906 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034754  [    0/60000]\n",
            "loss: 0.226368  [ 5000/60000]\n",
            "loss: 0.040073  [10000/60000]\n",
            "loss: 0.060643  [15000/60000]\n",
            "loss: 0.015126  [20000/60000]\n",
            "loss: 0.031619  [25000/60000]\n",
            "loss: 0.155717  [30000/60000]\n",
            "loss: 0.066974  [35000/60000]\n",
            "loss: 0.171013  [40000/60000]\n",
            "loss: 0.012315  [45000/60000]\n",
            "loss: 0.067058  [50000/60000]\n",
            "loss: 0.073109  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.100978 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.140399  [    0/60000]\n",
            "loss: 0.020664  [ 5000/60000]\n",
            "loss: 0.039140  [10000/60000]\n",
            "loss: 0.118636  [15000/60000]\n",
            "loss: 0.067139  [20000/60000]\n",
            "loss: 0.140496  [25000/60000]\n",
            "loss: 0.052051  [30000/60000]\n",
            "loss: 0.033332  [35000/60000]\n",
            "loss: 0.159005  [40000/60000]\n",
            "loss: 0.096905  [45000/60000]\n",
            "loss: 0.043854  [50000/60000]\n",
            "loss: 0.030147  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098742 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048644  [    0/60000]\n",
            "loss: 0.054880  [ 5000/60000]\n",
            "loss: 0.069222  [10000/60000]\n",
            "loss: 0.032543  [15000/60000]\n",
            "loss: 0.024562  [20000/60000]\n",
            "loss: 0.081067  [25000/60000]\n",
            "loss: 0.067981  [30000/60000]\n",
            "loss: 0.158190  [35000/60000]\n",
            "loss: 0.043145  [40000/60000]\n",
            "loss: 0.089862  [45000/60000]\n",
            "loss: 0.058893  [50000/60000]\n",
            "loss: 0.103464  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099445 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 3\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314301  [30000/60000]\n",
            "loss: 1.119928  [35000/60000]\n",
            "loss: 1.104700  [40000/60000]\n",
            "loss: 1.037244  [45000/60000]\n",
            "loss: 0.860642  [50000/60000]\n",
            "loss: 0.646582  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590788 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629849  [    0/60000]\n",
            "loss: 0.527575  [ 5000/60000]\n",
            "loss: 0.491064  [10000/60000]\n",
            "loss: 0.540453  [15000/60000]\n",
            "loss: 0.418391  [20000/60000]\n",
            "loss: 0.493021  [25000/60000]\n",
            "loss: 0.458724  [30000/60000]\n",
            "loss: 0.487828  [35000/60000]\n",
            "loss: 0.718830  [40000/60000]\n",
            "loss: 0.727090  [45000/60000]\n",
            "loss: 0.260512  [50000/60000]\n",
            "loss: 0.347246  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379044 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231739  [    0/60000]\n",
            "loss: 0.206699  [ 5000/60000]\n",
            "loss: 0.527673  [10000/60000]\n",
            "loss: 0.144556  [15000/60000]\n",
            "loss: 0.355152  [20000/60000]\n",
            "loss: 0.215305  [25000/60000]\n",
            "loss: 0.446810  [30000/60000]\n",
            "loss: 0.289245  [35000/60000]\n",
            "loss: 0.366853  [40000/60000]\n",
            "loss: 0.569258  [45000/60000]\n",
            "loss: 0.331925  [50000/60000]\n",
            "loss: 0.502970  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325590 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397436  [    0/60000]\n",
            "loss: 0.817553  [ 5000/60000]\n",
            "loss: 0.415101  [10000/60000]\n",
            "loss: 0.300955  [15000/60000]\n",
            "loss: 0.449619  [20000/60000]\n",
            "loss: 0.402326  [25000/60000]\n",
            "loss: 0.228509  [30000/60000]\n",
            "loss: 0.368577  [35000/60000]\n",
            "loss: 0.498512  [40000/60000]\n",
            "loss: 0.471035  [45000/60000]\n",
            "loss: 0.397034  [50000/60000]\n",
            "loss: 0.218171  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290560 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231173  [    0/60000]\n",
            "loss: 0.209318  [ 5000/60000]\n",
            "loss: 0.142513  [10000/60000]\n",
            "loss: 0.434309  [15000/60000]\n",
            "loss: 0.322936  [20000/60000]\n",
            "loss: 0.134322  [25000/60000]\n",
            "loss: 0.122870  [30000/60000]\n",
            "loss: 0.419564  [35000/60000]\n",
            "loss: 0.286750  [40000/60000]\n",
            "loss: 0.309875  [45000/60000]\n",
            "loss: 0.223064  [50000/60000]\n",
            "loss: 0.535065  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268346 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166736  [    0/60000]\n",
            "loss: 0.176873  [ 5000/60000]\n",
            "loss: 0.144301  [10000/60000]\n",
            "loss: 0.474903  [15000/60000]\n",
            "loss: 0.372195  [20000/60000]\n",
            "loss: 0.264231  [25000/60000]\n",
            "loss: 0.279669  [30000/60000]\n",
            "loss: 0.195913  [35000/60000]\n",
            "loss: 0.163575  [40000/60000]\n",
            "loss: 0.166295  [45000/60000]\n",
            "loss: 0.294647  [50000/60000]\n",
            "loss: 0.314489  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.247350 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146433  [    0/60000]\n",
            "loss: 0.337667  [ 5000/60000]\n",
            "loss: 0.349866  [10000/60000]\n",
            "loss: 0.121978  [15000/60000]\n",
            "loss: 0.176421  [20000/60000]\n",
            "loss: 0.189412  [25000/60000]\n",
            "loss: 0.255168  [30000/60000]\n",
            "loss: 0.112668  [35000/60000]\n",
            "loss: 0.263199  [40000/60000]\n",
            "loss: 0.385581  [45000/60000]\n",
            "loss: 0.373615  [50000/60000]\n",
            "loss: 0.067801  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228145 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193717  [    0/60000]\n",
            "loss: 0.192640  [ 5000/60000]\n",
            "loss: 0.210636  [10000/60000]\n",
            "loss: 0.199531  [15000/60000]\n",
            "loss: 0.216874  [20000/60000]\n",
            "loss: 0.075614  [25000/60000]\n",
            "loss: 0.383341  [30000/60000]\n",
            "loss: 0.177189  [35000/60000]\n",
            "loss: 0.273228  [40000/60000]\n",
            "loss: 0.152729  [45000/60000]\n",
            "loss: 0.227986  [50000/60000]\n",
            "loss: 0.140787  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216101 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.173852  [    0/60000]\n",
            "loss: 0.116069  [ 5000/60000]\n",
            "loss: 0.235072  [10000/60000]\n",
            "loss: 0.418817  [15000/60000]\n",
            "loss: 0.156074  [20000/60000]\n",
            "loss: 0.164732  [25000/60000]\n",
            "loss: 0.192087  [30000/60000]\n",
            "loss: 0.147133  [35000/60000]\n",
            "loss: 0.062782  [40000/60000]\n",
            "loss: 0.185128  [45000/60000]\n",
            "loss: 0.236605  [50000/60000]\n",
            "loss: 0.172404  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202152 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200711  [    0/60000]\n",
            "loss: 0.343299  [ 5000/60000]\n",
            "loss: 0.237735  [10000/60000]\n",
            "loss: 0.152479  [15000/60000]\n",
            "loss: 0.101356  [20000/60000]\n",
            "loss: 0.146522  [25000/60000]\n",
            "loss: 0.241915  [30000/60000]\n",
            "loss: 0.243811  [35000/60000]\n",
            "loss: 0.270978  [40000/60000]\n",
            "loss: 0.158106  [45000/60000]\n",
            "loss: 0.331798  [50000/60000]\n",
            "loss: 0.060407  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186862 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069490  [    0/60000]\n",
            "loss: 0.127940  [ 5000/60000]\n",
            "loss: 0.211805  [10000/60000]\n",
            "loss: 0.301644  [15000/60000]\n",
            "loss: 0.314112  [20000/60000]\n",
            "loss: 0.097179  [25000/60000]\n",
            "loss: 0.200069  [30000/60000]\n",
            "loss: 0.084415  [35000/60000]\n",
            "loss: 0.281266  [40000/60000]\n",
            "loss: 0.206764  [45000/60000]\n",
            "loss: 0.139277  [50000/60000]\n",
            "loss: 0.409842  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175097 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128528  [    0/60000]\n",
            "loss: 0.284699  [ 5000/60000]\n",
            "loss: 0.232075  [10000/60000]\n",
            "loss: 0.202186  [15000/60000]\n",
            "loss: 0.132786  [20000/60000]\n",
            "loss: 0.164016  [25000/60000]\n",
            "loss: 0.166333  [30000/60000]\n",
            "loss: 0.201386  [35000/60000]\n",
            "loss: 0.062017  [40000/60000]\n",
            "loss: 0.070844  [45000/60000]\n",
            "loss: 0.175556  [50000/60000]\n",
            "loss: 0.326906  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.170597 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.241692  [    0/60000]\n",
            "loss: 0.193589  [ 5000/60000]\n",
            "loss: 0.182776  [10000/60000]\n",
            "loss: 0.290730  [15000/60000]\n",
            "loss: 0.084881  [20000/60000]\n",
            "loss: 0.158369  [25000/60000]\n",
            "loss: 0.195654  [30000/60000]\n",
            "loss: 0.161967  [35000/60000]\n",
            "loss: 0.220318  [40000/60000]\n",
            "loss: 0.044442  [45000/60000]\n",
            "loss: 0.055717  [50000/60000]\n",
            "loss: 0.108582  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159488 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.181003  [    0/60000]\n",
            "loss: 0.092701  [ 5000/60000]\n",
            "loss: 0.069791  [10000/60000]\n",
            "loss: 0.157968  [15000/60000]\n",
            "loss: 0.181138  [20000/60000]\n",
            "loss: 0.187682  [25000/60000]\n",
            "loss: 0.042322  [30000/60000]\n",
            "loss: 0.142060  [35000/60000]\n",
            "loss: 0.149799  [40000/60000]\n",
            "loss: 0.250600  [45000/60000]\n",
            "loss: 0.125214  [50000/60000]\n",
            "loss: 0.067225  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153650 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040407  [    0/60000]\n",
            "loss: 0.066429  [ 5000/60000]\n",
            "loss: 0.117381  [10000/60000]\n",
            "loss: 0.157146  [15000/60000]\n",
            "loss: 0.104343  [20000/60000]\n",
            "loss: 0.171930  [25000/60000]\n",
            "loss: 0.140882  [30000/60000]\n",
            "loss: 0.096196  [35000/60000]\n",
            "loss: 0.060421  [40000/60000]\n",
            "loss: 0.149963  [45000/60000]\n",
            "loss: 0.320892  [50000/60000]\n",
            "loss: 0.102351  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146070 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.376332  [    0/60000]\n",
            "loss: 0.175539  [ 5000/60000]\n",
            "loss: 0.190202  [10000/60000]\n",
            "loss: 0.221857  [15000/60000]\n",
            "loss: 0.167925  [20000/60000]\n",
            "loss: 0.038193  [25000/60000]\n",
            "loss: 0.092944  [30000/60000]\n",
            "loss: 0.204588  [35000/60000]\n",
            "loss: 0.057383  [40000/60000]\n",
            "loss: 0.067976  [45000/60000]\n",
            "loss: 0.043604  [50000/60000]\n",
            "loss: 0.125658  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141941 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.130687  [    0/60000]\n",
            "loss: 0.071020  [ 5000/60000]\n",
            "loss: 0.116711  [10000/60000]\n",
            "loss: 0.114953  [15000/60000]\n",
            "loss: 0.112210  [20000/60000]\n",
            "loss: 0.067686  [25000/60000]\n",
            "loss: 0.049970  [30000/60000]\n",
            "loss: 0.160883  [35000/60000]\n",
            "loss: 0.247434  [40000/60000]\n",
            "loss: 0.094833  [45000/60000]\n",
            "loss: 0.047436  [50000/60000]\n",
            "loss: 0.240136  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134776 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.472861  [    0/60000]\n",
            "loss: 0.048878  [ 5000/60000]\n",
            "loss: 0.253557  [10000/60000]\n",
            "loss: 0.250932  [15000/60000]\n",
            "loss: 0.067938  [20000/60000]\n",
            "loss: 0.078158  [25000/60000]\n",
            "loss: 0.273682  [30000/60000]\n",
            "loss: 0.108657  [35000/60000]\n",
            "loss: 0.245295  [40000/60000]\n",
            "loss: 0.080079  [45000/60000]\n",
            "loss: 0.081065  [50000/60000]\n",
            "loss: 0.166812  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133108 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149631  [    0/60000]\n",
            "loss: 0.046743  [ 5000/60000]\n",
            "loss: 0.114139  [10000/60000]\n",
            "loss: 0.010367  [15000/60000]\n",
            "loss: 0.159218  [20000/60000]\n",
            "loss: 0.084372  [25000/60000]\n",
            "loss: 0.071518  [30000/60000]\n",
            "loss: 0.052814  [35000/60000]\n",
            "loss: 0.077589  [40000/60000]\n",
            "loss: 0.163710  [45000/60000]\n",
            "loss: 0.055964  [50000/60000]\n",
            "loss: 0.210684  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.125699 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.047975  [    0/60000]\n",
            "loss: 0.062761  [ 5000/60000]\n",
            "loss: 0.246584  [10000/60000]\n",
            "loss: 0.115363  [15000/60000]\n",
            "loss: 0.102197  [20000/60000]\n",
            "loss: 0.088008  [25000/60000]\n",
            "loss: 0.080945  [30000/60000]\n",
            "loss: 0.047845  [35000/60000]\n",
            "loss: 0.123100  [40000/60000]\n",
            "loss: 0.116507  [45000/60000]\n",
            "loss: 0.447328  [50000/60000]\n",
            "loss: 0.122897  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126451 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048193  [    0/60000]\n",
            "loss: 0.141119  [ 5000/60000]\n",
            "loss: 0.066467  [10000/60000]\n",
            "loss: 0.039775  [15000/60000]\n",
            "loss: 0.098546  [20000/60000]\n",
            "loss: 0.084426  [25000/60000]\n",
            "loss: 0.175988  [30000/60000]\n",
            "loss: 0.270659  [35000/60000]\n",
            "loss: 0.042908  [40000/60000]\n",
            "loss: 0.138968  [45000/60000]\n",
            "loss: 0.139227  [50000/60000]\n",
            "loss: 0.069066  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118155 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.101700  [    0/60000]\n",
            "loss: 0.049333  [ 5000/60000]\n",
            "loss: 0.159892  [10000/60000]\n",
            "loss: 0.083418  [15000/60000]\n",
            "loss: 0.064439  [20000/60000]\n",
            "loss: 0.036557  [25000/60000]\n",
            "loss: 0.088850  [30000/60000]\n",
            "loss: 0.119106  [35000/60000]\n",
            "loss: 0.111825  [40000/60000]\n",
            "loss: 0.117090  [45000/60000]\n",
            "loss: 0.041048  [50000/60000]\n",
            "loss: 0.182343  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.116357 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.026021  [    0/60000]\n",
            "loss: 0.060072  [ 5000/60000]\n",
            "loss: 0.080286  [10000/60000]\n",
            "loss: 0.049429  [15000/60000]\n",
            "loss: 0.077339  [20000/60000]\n",
            "loss: 0.013887  [25000/60000]\n",
            "loss: 0.239913  [30000/60000]\n",
            "loss: 0.063400  [35000/60000]\n",
            "loss: 0.059945  [40000/60000]\n",
            "loss: 0.158126  [45000/60000]\n",
            "loss: 0.061477  [50000/60000]\n",
            "loss: 0.039456  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117225 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.159018  [    0/60000]\n",
            "loss: 0.129645  [ 5000/60000]\n",
            "loss: 0.084085  [10000/60000]\n",
            "loss: 0.092806  [15000/60000]\n",
            "loss: 0.314613  [20000/60000]\n",
            "loss: 0.075998  [25000/60000]\n",
            "loss: 0.083631  [30000/60000]\n",
            "loss: 0.089263  [35000/60000]\n",
            "loss: 0.143966  [40000/60000]\n",
            "loss: 0.042348  [45000/60000]\n",
            "loss: 0.089993  [50000/60000]\n",
            "loss: 0.040016  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113369 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.119910  [    0/60000]\n",
            "loss: 0.082024  [ 5000/60000]\n",
            "loss: 0.175294  [10000/60000]\n",
            "loss: 0.098661  [15000/60000]\n",
            "loss: 0.061797  [20000/60000]\n",
            "loss: 0.070623  [25000/60000]\n",
            "loss: 0.029307  [30000/60000]\n",
            "loss: 0.010554  [35000/60000]\n",
            "loss: 0.094239  [40000/60000]\n",
            "loss: 0.102584  [45000/60000]\n",
            "loss: 0.055842  [50000/60000]\n",
            "loss: 0.168918  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.107970 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.233324  [    0/60000]\n",
            "loss: 0.156459  [ 5000/60000]\n",
            "loss: 0.045287  [10000/60000]\n",
            "loss: 0.032832  [15000/60000]\n",
            "loss: 0.025696  [20000/60000]\n",
            "loss: 0.177406  [25000/60000]\n",
            "loss: 0.102473  [30000/60000]\n",
            "loss: 0.163185  [35000/60000]\n",
            "loss: 0.095038  [40000/60000]\n",
            "loss: 0.050481  [45000/60000]\n",
            "loss: 0.087167  [50000/60000]\n",
            "loss: 0.157248  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107330 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050499  [    0/60000]\n",
            "loss: 0.136512  [ 5000/60000]\n",
            "loss: 0.104806  [10000/60000]\n",
            "loss: 0.233598  [15000/60000]\n",
            "loss: 0.048631  [20000/60000]\n",
            "loss: 0.085597  [25000/60000]\n",
            "loss: 0.041317  [30000/60000]\n",
            "loss: 0.212074  [35000/60000]\n",
            "loss: 0.039516  [40000/60000]\n",
            "loss: 0.010569  [45000/60000]\n",
            "loss: 0.242830  [50000/60000]\n",
            "loss: 0.169010  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103886 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034592  [    0/60000]\n",
            "loss: 0.223926  [ 5000/60000]\n",
            "loss: 0.040619  [10000/60000]\n",
            "loss: 0.059715  [15000/60000]\n",
            "loss: 0.015612  [20000/60000]\n",
            "loss: 0.031883  [25000/60000]\n",
            "loss: 0.155709  [30000/60000]\n",
            "loss: 0.068717  [35000/60000]\n",
            "loss: 0.170905  [40000/60000]\n",
            "loss: 0.012152  [45000/60000]\n",
            "loss: 0.066382  [50000/60000]\n",
            "loss: 0.073184  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.101039 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.138385  [    0/60000]\n",
            "loss: 0.021213  [ 5000/60000]\n",
            "loss: 0.038378  [10000/60000]\n",
            "loss: 0.116625  [15000/60000]\n",
            "loss: 0.066516  [20000/60000]\n",
            "loss: 0.139804  [25000/60000]\n",
            "loss: 0.049871  [30000/60000]\n",
            "loss: 0.033517  [35000/60000]\n",
            "loss: 0.162172  [40000/60000]\n",
            "loss: 0.098462  [45000/60000]\n",
            "loss: 0.043714  [50000/60000]\n",
            "loss: 0.030999  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098955 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048111  [    0/60000]\n",
            "loss: 0.054448  [ 5000/60000]\n",
            "loss: 0.069887  [10000/60000]\n",
            "loss: 0.032104  [15000/60000]\n",
            "loss: 0.024609  [20000/60000]\n",
            "loss: 0.081943  [25000/60000]\n",
            "loss: 0.068440  [30000/60000]\n",
            "loss: 0.158476  [35000/60000]\n",
            "loss: 0.042364  [40000/60000]\n",
            "loss: 0.088953  [45000/60000]\n",
            "loss: 0.059106  [50000/60000]\n",
            "loss: 0.103782  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.099700 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 4\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314301  [30000/60000]\n",
            "loss: 1.119928  [35000/60000]\n",
            "loss: 1.104700  [40000/60000]\n",
            "loss: 1.037244  [45000/60000]\n",
            "loss: 0.860642  [50000/60000]\n",
            "loss: 0.646582  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590788 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629850  [    0/60000]\n",
            "loss: 0.527619  [ 5000/60000]\n",
            "loss: 0.491032  [10000/60000]\n",
            "loss: 0.540469  [15000/60000]\n",
            "loss: 0.418387  [20000/60000]\n",
            "loss: 0.493041  [25000/60000]\n",
            "loss: 0.458783  [30000/60000]\n",
            "loss: 0.487807  [35000/60000]\n",
            "loss: 0.718823  [40000/60000]\n",
            "loss: 0.727091  [45000/60000]\n",
            "loss: 0.260497  [50000/60000]\n",
            "loss: 0.347196  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379048 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231728  [    0/60000]\n",
            "loss: 0.206668  [ 5000/60000]\n",
            "loss: 0.527651  [10000/60000]\n",
            "loss: 0.144591  [15000/60000]\n",
            "loss: 0.355186  [20000/60000]\n",
            "loss: 0.215324  [25000/60000]\n",
            "loss: 0.446813  [30000/60000]\n",
            "loss: 0.289232  [35000/60000]\n",
            "loss: 0.366849  [40000/60000]\n",
            "loss: 0.569249  [45000/60000]\n",
            "loss: 0.331920  [50000/60000]\n",
            "loss: 0.503054  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325594 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397438  [    0/60000]\n",
            "loss: 0.817501  [ 5000/60000]\n",
            "loss: 0.415198  [10000/60000]\n",
            "loss: 0.300934  [15000/60000]\n",
            "loss: 0.449600  [20000/60000]\n",
            "loss: 0.402263  [25000/60000]\n",
            "loss: 0.228511  [30000/60000]\n",
            "loss: 0.368629  [35000/60000]\n",
            "loss: 0.498508  [40000/60000]\n",
            "loss: 0.471005  [45000/60000]\n",
            "loss: 0.396933  [50000/60000]\n",
            "loss: 0.217880  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290568 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231106  [    0/60000]\n",
            "loss: 0.209310  [ 5000/60000]\n",
            "loss: 0.142359  [10000/60000]\n",
            "loss: 0.434265  [15000/60000]\n",
            "loss: 0.323067  [20000/60000]\n",
            "loss: 0.134251  [25000/60000]\n",
            "loss: 0.122924  [30000/60000]\n",
            "loss: 0.419484  [35000/60000]\n",
            "loss: 0.286960  [40000/60000]\n",
            "loss: 0.309956  [45000/60000]\n",
            "loss: 0.223192  [50000/60000]\n",
            "loss: 0.534943  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268361 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166872  [    0/60000]\n",
            "loss: 0.177008  [ 5000/60000]\n",
            "loss: 0.144323  [10000/60000]\n",
            "loss: 0.474933  [15000/60000]\n",
            "loss: 0.372140  [20000/60000]\n",
            "loss: 0.264152  [25000/60000]\n",
            "loss: 0.279615  [30000/60000]\n",
            "loss: 0.196004  [35000/60000]\n",
            "loss: 0.163360  [40000/60000]\n",
            "loss: 0.166387  [45000/60000]\n",
            "loss: 0.294852  [50000/60000]\n",
            "loss: 0.314493  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.247371 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146496  [    0/60000]\n",
            "loss: 0.337842  [ 5000/60000]\n",
            "loss: 0.349879  [10000/60000]\n",
            "loss: 0.122037  [15000/60000]\n",
            "loss: 0.176631  [20000/60000]\n",
            "loss: 0.189477  [25000/60000]\n",
            "loss: 0.255332  [30000/60000]\n",
            "loss: 0.112599  [35000/60000]\n",
            "loss: 0.263120  [40000/60000]\n",
            "loss: 0.385924  [45000/60000]\n",
            "loss: 0.373796  [50000/60000]\n",
            "loss: 0.067758  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228153 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193631  [    0/60000]\n",
            "loss: 0.192729  [ 5000/60000]\n",
            "loss: 0.210593  [10000/60000]\n",
            "loss: 0.199273  [15000/60000]\n",
            "loss: 0.216981  [20000/60000]\n",
            "loss: 0.075616  [25000/60000]\n",
            "loss: 0.383654  [30000/60000]\n",
            "loss: 0.177282  [35000/60000]\n",
            "loss: 0.273145  [40000/60000]\n",
            "loss: 0.152714  [45000/60000]\n",
            "loss: 0.227537  [50000/60000]\n",
            "loss: 0.141263  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216131 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.173971  [    0/60000]\n",
            "loss: 0.115893  [ 5000/60000]\n",
            "loss: 0.235264  [10000/60000]\n",
            "loss: 0.419092  [15000/60000]\n",
            "loss: 0.156184  [20000/60000]\n",
            "loss: 0.165082  [25000/60000]\n",
            "loss: 0.192230  [30000/60000]\n",
            "loss: 0.147119  [35000/60000]\n",
            "loss: 0.062695  [40000/60000]\n",
            "loss: 0.185026  [45000/60000]\n",
            "loss: 0.236848  [50000/60000]\n",
            "loss: 0.172375  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202164 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200125  [    0/60000]\n",
            "loss: 0.343280  [ 5000/60000]\n",
            "loss: 0.237460  [10000/60000]\n",
            "loss: 0.152493  [15000/60000]\n",
            "loss: 0.101224  [20000/60000]\n",
            "loss: 0.146527  [25000/60000]\n",
            "loss: 0.241657  [30000/60000]\n",
            "loss: 0.243501  [35000/60000]\n",
            "loss: 0.270995  [40000/60000]\n",
            "loss: 0.158177  [45000/60000]\n",
            "loss: 0.331166  [50000/60000]\n",
            "loss: 0.060575  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186888 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069731  [    0/60000]\n",
            "loss: 0.127756  [ 5000/60000]\n",
            "loss: 0.211813  [10000/60000]\n",
            "loss: 0.301650  [15000/60000]\n",
            "loss: 0.314274  [20000/60000]\n",
            "loss: 0.097131  [25000/60000]\n",
            "loss: 0.200270  [30000/60000]\n",
            "loss: 0.084440  [35000/60000]\n",
            "loss: 0.281457  [40000/60000]\n",
            "loss: 0.206988  [45000/60000]\n",
            "loss: 0.139380  [50000/60000]\n",
            "loss: 0.410281  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175119 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128949  [    0/60000]\n",
            "loss: 0.284461  [ 5000/60000]\n",
            "loss: 0.232047  [10000/60000]\n",
            "loss: 0.202621  [15000/60000]\n",
            "loss: 0.133003  [20000/60000]\n",
            "loss: 0.163993  [25000/60000]\n",
            "loss: 0.166318  [30000/60000]\n",
            "loss: 0.201361  [35000/60000]\n",
            "loss: 0.061908  [40000/60000]\n",
            "loss: 0.070941  [45000/60000]\n",
            "loss: 0.175327  [50000/60000]\n",
            "loss: 0.326633  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.170686 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.242493  [    0/60000]\n",
            "loss: 0.193733  [ 5000/60000]\n",
            "loss: 0.183038  [10000/60000]\n",
            "loss: 0.290696  [15000/60000]\n",
            "loss: 0.084518  [20000/60000]\n",
            "loss: 0.158646  [25000/60000]\n",
            "loss: 0.195385  [30000/60000]\n",
            "loss: 0.161990  [35000/60000]\n",
            "loss: 0.220907  [40000/60000]\n",
            "loss: 0.044446  [45000/60000]\n",
            "loss: 0.055835  [50000/60000]\n",
            "loss: 0.108545  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159514 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.180981  [    0/60000]\n",
            "loss: 0.092769  [ 5000/60000]\n",
            "loss: 0.069704  [10000/60000]\n",
            "loss: 0.157982  [15000/60000]\n",
            "loss: 0.181350  [20000/60000]\n",
            "loss: 0.188235  [25000/60000]\n",
            "loss: 0.042124  [30000/60000]\n",
            "loss: 0.142208  [35000/60000]\n",
            "loss: 0.149869  [40000/60000]\n",
            "loss: 0.250717  [45000/60000]\n",
            "loss: 0.125118  [50000/60000]\n",
            "loss: 0.067274  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153646 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040495  [    0/60000]\n",
            "loss: 0.066502  [ 5000/60000]\n",
            "loss: 0.116594  [10000/60000]\n",
            "loss: 0.157185  [15000/60000]\n",
            "loss: 0.104491  [20000/60000]\n",
            "loss: 0.172346  [25000/60000]\n",
            "loss: 0.141445  [30000/60000]\n",
            "loss: 0.096416  [35000/60000]\n",
            "loss: 0.060797  [40000/60000]\n",
            "loss: 0.149741  [45000/60000]\n",
            "loss: 0.321368  [50000/60000]\n",
            "loss: 0.102260  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146113 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.376793  [    0/60000]\n",
            "loss: 0.175001  [ 5000/60000]\n",
            "loss: 0.190151  [10000/60000]\n",
            "loss: 0.221720  [15000/60000]\n",
            "loss: 0.167707  [20000/60000]\n",
            "loss: 0.038145  [25000/60000]\n",
            "loss: 0.093092  [30000/60000]\n",
            "loss: 0.204223  [35000/60000]\n",
            "loss: 0.057263  [40000/60000]\n",
            "loss: 0.067716  [45000/60000]\n",
            "loss: 0.043637  [50000/60000]\n",
            "loss: 0.125883  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.142017 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.131237  [    0/60000]\n",
            "loss: 0.071001  [ 5000/60000]\n",
            "loss: 0.117090  [10000/60000]\n",
            "loss: 0.113739  [15000/60000]\n",
            "loss: 0.112001  [20000/60000]\n",
            "loss: 0.067888  [25000/60000]\n",
            "loss: 0.050174  [30000/60000]\n",
            "loss: 0.161004  [35000/60000]\n",
            "loss: 0.247075  [40000/60000]\n",
            "loss: 0.095987  [45000/60000]\n",
            "loss: 0.047572  [50000/60000]\n",
            "loss: 0.239424  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134798 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.473468  [    0/60000]\n",
            "loss: 0.048791  [ 5000/60000]\n",
            "loss: 0.253247  [10000/60000]\n",
            "loss: 0.251238  [15000/60000]\n",
            "loss: 0.068048  [20000/60000]\n",
            "loss: 0.077969  [25000/60000]\n",
            "loss: 0.273944  [30000/60000]\n",
            "loss: 0.108663  [35000/60000]\n",
            "loss: 0.245865  [40000/60000]\n",
            "loss: 0.080037  [45000/60000]\n",
            "loss: 0.080718  [50000/60000]\n",
            "loss: 0.167705  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133123 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149695  [    0/60000]\n",
            "loss: 0.046692  [ 5000/60000]\n",
            "loss: 0.113690  [10000/60000]\n",
            "loss: 0.010356  [15000/60000]\n",
            "loss: 0.159346  [20000/60000]\n",
            "loss: 0.084764  [25000/60000]\n",
            "loss: 0.071691  [30000/60000]\n",
            "loss: 0.052875  [35000/60000]\n",
            "loss: 0.077232  [40000/60000]\n",
            "loss: 0.164529  [45000/60000]\n",
            "loss: 0.055986  [50000/60000]\n",
            "loss: 0.210361  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.125748 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.048112  [    0/60000]\n",
            "loss: 0.063078  [ 5000/60000]\n",
            "loss: 0.246124  [10000/60000]\n",
            "loss: 0.115368  [15000/60000]\n",
            "loss: 0.102474  [20000/60000]\n",
            "loss: 0.088473  [25000/60000]\n",
            "loss: 0.081045  [30000/60000]\n",
            "loss: 0.047646  [35000/60000]\n",
            "loss: 0.123668  [40000/60000]\n",
            "loss: 0.116141  [45000/60000]\n",
            "loss: 0.447431  [50000/60000]\n",
            "loss: 0.123066  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126400 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048030  [    0/60000]\n",
            "loss: 0.140861  [ 5000/60000]\n",
            "loss: 0.066255  [10000/60000]\n",
            "loss: 0.039787  [15000/60000]\n",
            "loss: 0.098211  [20000/60000]\n",
            "loss: 0.084723  [25000/60000]\n",
            "loss: 0.175622  [30000/60000]\n",
            "loss: 0.270841  [35000/60000]\n",
            "loss: 0.042809  [40000/60000]\n",
            "loss: 0.139293  [45000/60000]\n",
            "loss: 0.138240  [50000/60000]\n",
            "loss: 0.068494  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118181 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.101958  [    0/60000]\n",
            "loss: 0.049579  [ 5000/60000]\n",
            "loss: 0.159142  [10000/60000]\n",
            "loss: 0.083653  [15000/60000]\n",
            "loss: 0.064208  [20000/60000]\n",
            "loss: 0.036739  [25000/60000]\n",
            "loss: 0.089873  [30000/60000]\n",
            "loss: 0.119103  [35000/60000]\n",
            "loss: 0.111727  [40000/60000]\n",
            "loss: 0.116807  [45000/60000]\n",
            "loss: 0.041155  [50000/60000]\n",
            "loss: 0.182607  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.116447 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.025964  [    0/60000]\n",
            "loss: 0.060820  [ 5000/60000]\n",
            "loss: 0.080106  [10000/60000]\n",
            "loss: 0.049222  [15000/60000]\n",
            "loss: 0.076811  [20000/60000]\n",
            "loss: 0.013971  [25000/60000]\n",
            "loss: 0.239362  [30000/60000]\n",
            "loss: 0.063250  [35000/60000]\n",
            "loss: 0.059909  [40000/60000]\n",
            "loss: 0.157871  [45000/60000]\n",
            "loss: 0.061000  [50000/60000]\n",
            "loss: 0.039428  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117180 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.158808  [    0/60000]\n",
            "loss: 0.129457  [ 5000/60000]\n",
            "loss: 0.084657  [10000/60000]\n",
            "loss: 0.093692  [15000/60000]\n",
            "loss: 0.315159  [20000/60000]\n",
            "loss: 0.076297  [25000/60000]\n",
            "loss: 0.083175  [30000/60000]\n",
            "loss: 0.089068  [35000/60000]\n",
            "loss: 0.143635  [40000/60000]\n",
            "loss: 0.042397  [45000/60000]\n",
            "loss: 0.090068  [50000/60000]\n",
            "loss: 0.040018  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113329 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.119863  [    0/60000]\n",
            "loss: 0.082215  [ 5000/60000]\n",
            "loss: 0.174955  [10000/60000]\n",
            "loss: 0.099039  [15000/60000]\n",
            "loss: 0.062290  [20000/60000]\n",
            "loss: 0.070941  [25000/60000]\n",
            "loss: 0.029059  [30000/60000]\n",
            "loss: 0.010663  [35000/60000]\n",
            "loss: 0.094588  [40000/60000]\n",
            "loss: 0.104367  [45000/60000]\n",
            "loss: 0.056421  [50000/60000]\n",
            "loss: 0.168598  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.108064 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.233377  [    0/60000]\n",
            "loss: 0.155190  [ 5000/60000]\n",
            "loss: 0.047111  [10000/60000]\n",
            "loss: 0.033220  [15000/60000]\n",
            "loss: 0.025209  [20000/60000]\n",
            "loss: 0.177382  [25000/60000]\n",
            "loss: 0.103138  [30000/60000]\n",
            "loss: 0.164397  [35000/60000]\n",
            "loss: 0.095732  [40000/60000]\n",
            "loss: 0.050718  [45000/60000]\n",
            "loss: 0.088587  [50000/60000]\n",
            "loss: 0.156858  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107354 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050213  [    0/60000]\n",
            "loss: 0.137206  [ 5000/60000]\n",
            "loss: 0.105137  [10000/60000]\n",
            "loss: 0.234279  [15000/60000]\n",
            "loss: 0.048762  [20000/60000]\n",
            "loss: 0.085919  [25000/60000]\n",
            "loss: 0.041189  [30000/60000]\n",
            "loss: 0.211773  [35000/60000]\n",
            "loss: 0.039604  [40000/60000]\n",
            "loss: 0.010643  [45000/60000]\n",
            "loss: 0.242688  [50000/60000]\n",
            "loss: 0.170042  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103923 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034850  [    0/60000]\n",
            "loss: 0.223654  [ 5000/60000]\n",
            "loss: 0.040803  [10000/60000]\n",
            "loss: 0.060684  [15000/60000]\n",
            "loss: 0.015549  [20000/60000]\n",
            "loss: 0.031581  [25000/60000]\n",
            "loss: 0.155980  [30000/60000]\n",
            "loss: 0.067185  [35000/60000]\n",
            "loss: 0.170193  [40000/60000]\n",
            "loss: 0.012117  [45000/60000]\n",
            "loss: 0.066167  [50000/60000]\n",
            "loss: 0.073213  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.101033 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.137592  [    0/60000]\n",
            "loss: 0.021204  [ 5000/60000]\n",
            "loss: 0.038640  [10000/60000]\n",
            "loss: 0.117122  [15000/60000]\n",
            "loss: 0.067033  [20000/60000]\n",
            "loss: 0.139578  [25000/60000]\n",
            "loss: 0.050152  [30000/60000]\n",
            "loss: 0.033788  [35000/60000]\n",
            "loss: 0.162056  [40000/60000]\n",
            "loss: 0.096788  [45000/60000]\n",
            "loss: 0.044566  [50000/60000]\n",
            "loss: 0.030455  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098923 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048255  [    0/60000]\n",
            "loss: 0.054701  [ 5000/60000]\n",
            "loss: 0.069668  [10000/60000]\n",
            "loss: 0.032095  [15000/60000]\n",
            "loss: 0.024426  [20000/60000]\n",
            "loss: 0.081632  [25000/60000]\n",
            "loss: 0.068371  [30000/60000]\n",
            "loss: 0.157546  [35000/60000]\n",
            "loss: 0.043258  [40000/60000]\n",
            "loss: 0.089348  [45000/60000]\n",
            "loss: 0.059320  [50000/60000]\n",
            "loss: 0.104088  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099642 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 5\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996616  [20000/60000]\n",
            "loss: 1.760569  [25000/60000]\n",
            "loss: 1.314295  [30000/60000]\n",
            "loss: 1.119987  [35000/60000]\n",
            "loss: 1.104742  [40000/60000]\n",
            "loss: 1.037309  [45000/60000]\n",
            "loss: 0.860571  [50000/60000]\n",
            "loss: 0.646593  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590792 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629859  [    0/60000]\n",
            "loss: 0.527608  [ 5000/60000]\n",
            "loss: 0.491047  [10000/60000]\n",
            "loss: 0.540437  [15000/60000]\n",
            "loss: 0.418441  [20000/60000]\n",
            "loss: 0.493041  [25000/60000]\n",
            "loss: 0.458773  [30000/60000]\n",
            "loss: 0.487668  [35000/60000]\n",
            "loss: 0.718742  [40000/60000]\n",
            "loss: 0.726949  [45000/60000]\n",
            "loss: 0.260442  [50000/60000]\n",
            "loss: 0.347350  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379056 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231740  [    0/60000]\n",
            "loss: 0.206713  [ 5000/60000]\n",
            "loss: 0.527767  [10000/60000]\n",
            "loss: 0.144541  [15000/60000]\n",
            "loss: 0.355290  [20000/60000]\n",
            "loss: 0.215306  [25000/60000]\n",
            "loss: 0.446844  [30000/60000]\n",
            "loss: 0.289297  [35000/60000]\n",
            "loss: 0.366897  [40000/60000]\n",
            "loss: 0.569224  [45000/60000]\n",
            "loss: 0.331883  [50000/60000]\n",
            "loss: 0.503247  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325597 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397529  [    0/60000]\n",
            "loss: 0.817744  [ 5000/60000]\n",
            "loss: 0.415070  [10000/60000]\n",
            "loss: 0.300689  [15000/60000]\n",
            "loss: 0.449713  [20000/60000]\n",
            "loss: 0.402534  [25000/60000]\n",
            "loss: 0.228567  [30000/60000]\n",
            "loss: 0.368751  [35000/60000]\n",
            "loss: 0.498608  [40000/60000]\n",
            "loss: 0.470848  [45000/60000]\n",
            "loss: 0.397421  [50000/60000]\n",
            "loss: 0.217904  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290601 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231185  [    0/60000]\n",
            "loss: 0.209227  [ 5000/60000]\n",
            "loss: 0.142839  [10000/60000]\n",
            "loss: 0.434478  [15000/60000]\n",
            "loss: 0.323312  [20000/60000]\n",
            "loss: 0.134421  [25000/60000]\n",
            "loss: 0.122841  [30000/60000]\n",
            "loss: 0.418987  [35000/60000]\n",
            "loss: 0.286896  [40000/60000]\n",
            "loss: 0.309393  [45000/60000]\n",
            "loss: 0.223528  [50000/60000]\n",
            "loss: 0.534887  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268387 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166730  [    0/60000]\n",
            "loss: 0.176711  [ 5000/60000]\n",
            "loss: 0.144115  [10000/60000]\n",
            "loss: 0.475158  [15000/60000]\n",
            "loss: 0.372178  [20000/60000]\n",
            "loss: 0.264141  [25000/60000]\n",
            "loss: 0.280542  [30000/60000]\n",
            "loss: 0.196042  [35000/60000]\n",
            "loss: 0.163693  [40000/60000]\n",
            "loss: 0.166332  [45000/60000]\n",
            "loss: 0.294873  [50000/60000]\n",
            "loss: 0.314455  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.247389 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146451  [    0/60000]\n",
            "loss: 0.337938  [ 5000/60000]\n",
            "loss: 0.350006  [10000/60000]\n",
            "loss: 0.121822  [15000/60000]\n",
            "loss: 0.175655  [20000/60000]\n",
            "loss: 0.189625  [25000/60000]\n",
            "loss: 0.256134  [30000/60000]\n",
            "loss: 0.112902  [35000/60000]\n",
            "loss: 0.264281  [40000/60000]\n",
            "loss: 0.386419  [45000/60000]\n",
            "loss: 0.373993  [50000/60000]\n",
            "loss: 0.067771  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228278 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.192949  [    0/60000]\n",
            "loss: 0.192465  [ 5000/60000]\n",
            "loss: 0.210873  [10000/60000]\n",
            "loss: 0.199304  [15000/60000]\n",
            "loss: 0.217010  [20000/60000]\n",
            "loss: 0.075661  [25000/60000]\n",
            "loss: 0.383169  [30000/60000]\n",
            "loss: 0.177202  [35000/60000]\n",
            "loss: 0.273133  [40000/60000]\n",
            "loss: 0.152730  [45000/60000]\n",
            "loss: 0.227109  [50000/60000]\n",
            "loss: 0.141044  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216147 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.174445  [    0/60000]\n",
            "loss: 0.116051  [ 5000/60000]\n",
            "loss: 0.235136  [10000/60000]\n",
            "loss: 0.419188  [15000/60000]\n",
            "loss: 0.155957  [20000/60000]\n",
            "loss: 0.165174  [25000/60000]\n",
            "loss: 0.191731  [30000/60000]\n",
            "loss: 0.147015  [35000/60000]\n",
            "loss: 0.062755  [40000/60000]\n",
            "loss: 0.184895  [45000/60000]\n",
            "loss: 0.236896  [50000/60000]\n",
            "loss: 0.172148  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202275 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200046  [    0/60000]\n",
            "loss: 0.343350  [ 5000/60000]\n",
            "loss: 0.238001  [10000/60000]\n",
            "loss: 0.152593  [15000/60000]\n",
            "loss: 0.100796  [20000/60000]\n",
            "loss: 0.146527  [25000/60000]\n",
            "loss: 0.242300  [30000/60000]\n",
            "loss: 0.243733  [35000/60000]\n",
            "loss: 0.271162  [40000/60000]\n",
            "loss: 0.158104  [45000/60000]\n",
            "loss: 0.331595  [50000/60000]\n",
            "loss: 0.060626  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186938 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069549  [    0/60000]\n",
            "loss: 0.128169  [ 5000/60000]\n",
            "loss: 0.211849  [10000/60000]\n",
            "loss: 0.301453  [15000/60000]\n",
            "loss: 0.314308  [20000/60000]\n",
            "loss: 0.097173  [25000/60000]\n",
            "loss: 0.200201  [30000/60000]\n",
            "loss: 0.084578  [35000/60000]\n",
            "loss: 0.281781  [40000/60000]\n",
            "loss: 0.207146  [45000/60000]\n",
            "loss: 0.140077  [50000/60000]\n",
            "loss: 0.410243  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175117 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128506  [    0/60000]\n",
            "loss: 0.285204  [ 5000/60000]\n",
            "loss: 0.232615  [10000/60000]\n",
            "loss: 0.202428  [15000/60000]\n",
            "loss: 0.132700  [20000/60000]\n",
            "loss: 0.164517  [25000/60000]\n",
            "loss: 0.166100  [30000/60000]\n",
            "loss: 0.201700  [35000/60000]\n",
            "loss: 0.061900  [40000/60000]\n",
            "loss: 0.070628  [45000/60000]\n",
            "loss: 0.175845  [50000/60000]\n",
            "loss: 0.326809  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.170626 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.242907  [    0/60000]\n",
            "loss: 0.194431  [ 5000/60000]\n",
            "loss: 0.181883  [10000/60000]\n",
            "loss: 0.291398  [15000/60000]\n",
            "loss: 0.084594  [20000/60000]\n",
            "loss: 0.157600  [25000/60000]\n",
            "loss: 0.195717  [30000/60000]\n",
            "loss: 0.162171  [35000/60000]\n",
            "loss: 0.221422  [40000/60000]\n",
            "loss: 0.044309  [45000/60000]\n",
            "loss: 0.055647  [50000/60000]\n",
            "loss: 0.108590  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159519 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.181663  [    0/60000]\n",
            "loss: 0.092845  [ 5000/60000]\n",
            "loss: 0.069474  [10000/60000]\n",
            "loss: 0.157641  [15000/60000]\n",
            "loss: 0.181057  [20000/60000]\n",
            "loss: 0.188843  [25000/60000]\n",
            "loss: 0.042394  [30000/60000]\n",
            "loss: 0.142452  [35000/60000]\n",
            "loss: 0.149761  [40000/60000]\n",
            "loss: 0.251421  [45000/60000]\n",
            "loss: 0.125617  [50000/60000]\n",
            "loss: 0.066882  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153752 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040784  [    0/60000]\n",
            "loss: 0.066645  [ 5000/60000]\n",
            "loss: 0.116606  [10000/60000]\n",
            "loss: 0.157299  [15000/60000]\n",
            "loss: 0.104506  [20000/60000]\n",
            "loss: 0.172120  [25000/60000]\n",
            "loss: 0.142268  [30000/60000]\n",
            "loss: 0.095920  [35000/60000]\n",
            "loss: 0.060903  [40000/60000]\n",
            "loss: 0.149720  [45000/60000]\n",
            "loss: 0.322574  [50000/60000]\n",
            "loss: 0.103252  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146097 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.377274  [    0/60000]\n",
            "loss: 0.175987  [ 5000/60000]\n",
            "loss: 0.189360  [10000/60000]\n",
            "loss: 0.220640  [15000/60000]\n",
            "loss: 0.168861  [20000/60000]\n",
            "loss: 0.038227  [25000/60000]\n",
            "loss: 0.092885  [30000/60000]\n",
            "loss: 0.204665  [35000/60000]\n",
            "loss: 0.056805  [40000/60000]\n",
            "loss: 0.067863  [45000/60000]\n",
            "loss: 0.043488  [50000/60000]\n",
            "loss: 0.125238  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141984 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.130572  [    0/60000]\n",
            "loss: 0.071073  [ 5000/60000]\n",
            "loss: 0.116645  [10000/60000]\n",
            "loss: 0.115351  [15000/60000]\n",
            "loss: 0.112209  [20000/60000]\n",
            "loss: 0.067689  [25000/60000]\n",
            "loss: 0.050028  [30000/60000]\n",
            "loss: 0.159955  [35000/60000]\n",
            "loss: 0.250651  [40000/60000]\n",
            "loss: 0.096933  [45000/60000]\n",
            "loss: 0.047170  [50000/60000]\n",
            "loss: 0.240886  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134752 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.472403  [    0/60000]\n",
            "loss: 0.049241  [ 5000/60000]\n",
            "loss: 0.253571  [10000/60000]\n",
            "loss: 0.251664  [15000/60000]\n",
            "loss: 0.067797  [20000/60000]\n",
            "loss: 0.077714  [25000/60000]\n",
            "loss: 0.275061  [30000/60000]\n",
            "loss: 0.109836  [35000/60000]\n",
            "loss: 0.246706  [40000/60000]\n",
            "loss: 0.080246  [45000/60000]\n",
            "loss: 0.081131  [50000/60000]\n",
            "loss: 0.167713  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133117 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149084  [    0/60000]\n",
            "loss: 0.047291  [ 5000/60000]\n",
            "loss: 0.115014  [10000/60000]\n",
            "loss: 0.010429  [15000/60000]\n",
            "loss: 0.160153  [20000/60000]\n",
            "loss: 0.083599  [25000/60000]\n",
            "loss: 0.071322  [30000/60000]\n",
            "loss: 0.051835  [35000/60000]\n",
            "loss: 0.077048  [40000/60000]\n",
            "loss: 0.162435  [45000/60000]\n",
            "loss: 0.056729  [50000/60000]\n",
            "loss: 0.212949  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.125900 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.048120  [    0/60000]\n",
            "loss: 0.063605  [ 5000/60000]\n",
            "loss: 0.248940  [10000/60000]\n",
            "loss: 0.114780  [15000/60000]\n",
            "loss: 0.102597  [20000/60000]\n",
            "loss: 0.087687  [25000/60000]\n",
            "loss: 0.080273  [30000/60000]\n",
            "loss: 0.047419  [35000/60000]\n",
            "loss: 0.124094  [40000/60000]\n",
            "loss: 0.115779  [45000/60000]\n",
            "loss: 0.447441  [50000/60000]\n",
            "loss: 0.124508  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126589 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.047719  [    0/60000]\n",
            "loss: 0.140294  [ 5000/60000]\n",
            "loss: 0.066385  [10000/60000]\n",
            "loss: 0.039959  [15000/60000]\n",
            "loss: 0.098145  [20000/60000]\n",
            "loss: 0.084906  [25000/60000]\n",
            "loss: 0.175963  [30000/60000]\n",
            "loss: 0.270353  [35000/60000]\n",
            "loss: 0.042941  [40000/60000]\n",
            "loss: 0.139070  [45000/60000]\n",
            "loss: 0.138810  [50000/60000]\n",
            "loss: 0.069001  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118229 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.102049  [    0/60000]\n",
            "loss: 0.049065  [ 5000/60000]\n",
            "loss: 0.159603  [10000/60000]\n",
            "loss: 0.083157  [15000/60000]\n",
            "loss: 0.064636  [20000/60000]\n",
            "loss: 0.037003  [25000/60000]\n",
            "loss: 0.089229  [30000/60000]\n",
            "loss: 0.119175  [35000/60000]\n",
            "loss: 0.111376  [40000/60000]\n",
            "loss: 0.117913  [45000/60000]\n",
            "loss: 0.041692  [50000/60000]\n",
            "loss: 0.182910  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.116464 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.025991  [    0/60000]\n",
            "loss: 0.060101  [ 5000/60000]\n",
            "loss: 0.078953  [10000/60000]\n",
            "loss: 0.049491  [15000/60000]\n",
            "loss: 0.076258  [20000/60000]\n",
            "loss: 0.013936  [25000/60000]\n",
            "loss: 0.238706  [30000/60000]\n",
            "loss: 0.063647  [35000/60000]\n",
            "loss: 0.060703  [40000/60000]\n",
            "loss: 0.158857  [45000/60000]\n",
            "loss: 0.061354  [50000/60000]\n",
            "loss: 0.039425  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117299 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.158190  [    0/60000]\n",
            "loss: 0.127073  [ 5000/60000]\n",
            "loss: 0.084008  [10000/60000]\n",
            "loss: 0.092664  [15000/60000]\n",
            "loss: 0.314319  [20000/60000]\n",
            "loss: 0.075389  [25000/60000]\n",
            "loss: 0.082748  [30000/60000]\n",
            "loss: 0.090314  [35000/60000]\n",
            "loss: 0.144443  [40000/60000]\n",
            "loss: 0.042627  [45000/60000]\n",
            "loss: 0.089942  [50000/60000]\n",
            "loss: 0.039151  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113468 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.120901  [    0/60000]\n",
            "loss: 0.082548  [ 5000/60000]\n",
            "loss: 0.174501  [10000/60000]\n",
            "loss: 0.097539  [15000/60000]\n",
            "loss: 0.062264  [20000/60000]\n",
            "loss: 0.071128  [25000/60000]\n",
            "loss: 0.029576  [30000/60000]\n",
            "loss: 0.010594  [35000/60000]\n",
            "loss: 0.093547  [40000/60000]\n",
            "loss: 0.102485  [45000/60000]\n",
            "loss: 0.055366  [50000/60000]\n",
            "loss: 0.167014  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.108138 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.232082  [    0/60000]\n",
            "loss: 0.155999  [ 5000/60000]\n",
            "loss: 0.045595  [10000/60000]\n",
            "loss: 0.035107  [15000/60000]\n",
            "loss: 0.026067  [20000/60000]\n",
            "loss: 0.181101  [25000/60000]\n",
            "loss: 0.103831  [30000/60000]\n",
            "loss: 0.163737  [35000/60000]\n",
            "loss: 0.097544  [40000/60000]\n",
            "loss: 0.051883  [45000/60000]\n",
            "loss: 0.088536  [50000/60000]\n",
            "loss: 0.157292  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107344 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050669  [    0/60000]\n",
            "loss: 0.135663  [ 5000/60000]\n",
            "loss: 0.107025  [10000/60000]\n",
            "loss: 0.232562  [15000/60000]\n",
            "loss: 0.049291  [20000/60000]\n",
            "loss: 0.088275  [25000/60000]\n",
            "loss: 0.040958  [30000/60000]\n",
            "loss: 0.212355  [35000/60000]\n",
            "loss: 0.040197  [40000/60000]\n",
            "loss: 0.010586  [45000/60000]\n",
            "loss: 0.242549  [50000/60000]\n",
            "loss: 0.162057  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103983 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.033353  [    0/60000]\n",
            "loss: 0.226463  [ 5000/60000]\n",
            "loss: 0.040466  [10000/60000]\n",
            "loss: 0.060595  [15000/60000]\n",
            "loss: 0.015226  [20000/60000]\n",
            "loss: 0.031881  [25000/60000]\n",
            "loss: 0.156949  [30000/60000]\n",
            "loss: 0.066784  [35000/60000]\n",
            "loss: 0.171079  [40000/60000]\n",
            "loss: 0.012035  [45000/60000]\n",
            "loss: 0.067153  [50000/60000]\n",
            "loss: 0.072718  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.100995 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.140431  [    0/60000]\n",
            "loss: 0.020857  [ 5000/60000]\n",
            "loss: 0.038691  [10000/60000]\n",
            "loss: 0.117996  [15000/60000]\n",
            "loss: 0.066428  [20000/60000]\n",
            "loss: 0.140425  [25000/60000]\n",
            "loss: 0.050981  [30000/60000]\n",
            "loss: 0.033760  [35000/60000]\n",
            "loss: 0.160301  [40000/60000]\n",
            "loss: 0.094333  [45000/60000]\n",
            "loss: 0.044180  [50000/60000]\n",
            "loss: 0.029695  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098844 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048317  [    0/60000]\n",
            "loss: 0.054810  [ 5000/60000]\n",
            "loss: 0.069852  [10000/60000]\n",
            "loss: 0.032820  [15000/60000]\n",
            "loss: 0.024998  [20000/60000]\n",
            "loss: 0.081471  [25000/60000]\n",
            "loss: 0.067740  [30000/60000]\n",
            "loss: 0.157184  [35000/60000]\n",
            "loss: 0.041566  [40000/60000]\n",
            "loss: 0.088801  [45000/60000]\n",
            "loss: 0.059323  [50000/60000]\n",
            "loss: 0.103377  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099477 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 6\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314301  [30000/60000]\n",
            "loss: 1.119928  [35000/60000]\n",
            "loss: 1.104700  [40000/60000]\n",
            "loss: 1.037244  [45000/60000]\n",
            "loss: 0.860653  [50000/60000]\n",
            "loss: 0.646571  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590778 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629830  [    0/60000]\n",
            "loss: 0.527621  [ 5000/60000]\n",
            "loss: 0.491027  [10000/60000]\n",
            "loss: 0.540446  [15000/60000]\n",
            "loss: 0.418425  [20000/60000]\n",
            "loss: 0.493017  [25000/60000]\n",
            "loss: 0.458772  [30000/60000]\n",
            "loss: 0.487764  [35000/60000]\n",
            "loss: 0.718864  [40000/60000]\n",
            "loss: 0.727091  [45000/60000]\n",
            "loss: 0.260495  [50000/60000]\n",
            "loss: 0.347206  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379046 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231732  [    0/60000]\n",
            "loss: 0.206672  [ 5000/60000]\n",
            "loss: 0.527627  [10000/60000]\n",
            "loss: 0.144574  [15000/60000]\n",
            "loss: 0.355141  [20000/60000]\n",
            "loss: 0.215292  [25000/60000]\n",
            "loss: 0.446847  [30000/60000]\n",
            "loss: 0.289249  [35000/60000]\n",
            "loss: 0.366801  [40000/60000]\n",
            "loss: 0.569205  [45000/60000]\n",
            "loss: 0.331873  [50000/60000]\n",
            "loss: 0.502884  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325589 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397408  [    0/60000]\n",
            "loss: 0.817472  [ 5000/60000]\n",
            "loss: 0.415130  [10000/60000]\n",
            "loss: 0.300861  [15000/60000]\n",
            "loss: 0.449638  [20000/60000]\n",
            "loss: 0.402305  [25000/60000]\n",
            "loss: 0.228500  [30000/60000]\n",
            "loss: 0.368598  [35000/60000]\n",
            "loss: 0.498363  [40000/60000]\n",
            "loss: 0.470868  [45000/60000]\n",
            "loss: 0.396997  [50000/60000]\n",
            "loss: 0.217826  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290557 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231120  [    0/60000]\n",
            "loss: 0.209282  [ 5000/60000]\n",
            "loss: 0.142471  [10000/60000]\n",
            "loss: 0.434276  [15000/60000]\n",
            "loss: 0.322969  [20000/60000]\n",
            "loss: 0.134298  [25000/60000]\n",
            "loss: 0.122828  [30000/60000]\n",
            "loss: 0.419531  [35000/60000]\n",
            "loss: 0.286900  [40000/60000]\n",
            "loss: 0.309913  [45000/60000]\n",
            "loss: 0.223240  [50000/60000]\n",
            "loss: 0.534835  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268349 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166847  [    0/60000]\n",
            "loss: 0.176803  [ 5000/60000]\n",
            "loss: 0.144243  [10000/60000]\n",
            "loss: 0.474855  [15000/60000]\n",
            "loss: 0.372129  [20000/60000]\n",
            "loss: 0.264138  [25000/60000]\n",
            "loss: 0.279489  [30000/60000]\n",
            "loss: 0.195923  [35000/60000]\n",
            "loss: 0.163392  [40000/60000]\n",
            "loss: 0.166365  [45000/60000]\n",
            "loss: 0.294906  [50000/60000]\n",
            "loss: 0.314395  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.247363 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146389  [    0/60000]\n",
            "loss: 0.337889  [ 5000/60000]\n",
            "loss: 0.349947  [10000/60000]\n",
            "loss: 0.122091  [15000/60000]\n",
            "loss: 0.176752  [20000/60000]\n",
            "loss: 0.189356  [25000/60000]\n",
            "loss: 0.255535  [30000/60000]\n",
            "loss: 0.112702  [35000/60000]\n",
            "loss: 0.263299  [40000/60000]\n",
            "loss: 0.385973  [45000/60000]\n",
            "loss: 0.373883  [50000/60000]\n",
            "loss: 0.067803  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228160 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193642  [    0/60000]\n",
            "loss: 0.192506  [ 5000/60000]\n",
            "loss: 0.210564  [10000/60000]\n",
            "loss: 0.199349  [15000/60000]\n",
            "loss: 0.216997  [20000/60000]\n",
            "loss: 0.075589  [25000/60000]\n",
            "loss: 0.383175  [30000/60000]\n",
            "loss: 0.177153  [35000/60000]\n",
            "loss: 0.273552  [40000/60000]\n",
            "loss: 0.152585  [45000/60000]\n",
            "loss: 0.227705  [50000/60000]\n",
            "loss: 0.141316  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216109 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.173996  [    0/60000]\n",
            "loss: 0.115929  [ 5000/60000]\n",
            "loss: 0.235376  [10000/60000]\n",
            "loss: 0.418954  [15000/60000]\n",
            "loss: 0.156043  [20000/60000]\n",
            "loss: 0.165244  [25000/60000]\n",
            "loss: 0.192128  [30000/60000]\n",
            "loss: 0.146981  [35000/60000]\n",
            "loss: 0.062814  [40000/60000]\n",
            "loss: 0.185104  [45000/60000]\n",
            "loss: 0.236558  [50000/60000]\n",
            "loss: 0.172182  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202172 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200370  [    0/60000]\n",
            "loss: 0.343198  [ 5000/60000]\n",
            "loss: 0.237801  [10000/60000]\n",
            "loss: 0.152500  [15000/60000]\n",
            "loss: 0.101138  [20000/60000]\n",
            "loss: 0.146520  [25000/60000]\n",
            "loss: 0.241953  [30000/60000]\n",
            "loss: 0.243493  [35000/60000]\n",
            "loss: 0.270980  [40000/60000]\n",
            "loss: 0.157950  [45000/60000]\n",
            "loss: 0.331218  [50000/60000]\n",
            "loss: 0.060467  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186870 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069795  [    0/60000]\n",
            "loss: 0.127926  [ 5000/60000]\n",
            "loss: 0.211909  [10000/60000]\n",
            "loss: 0.301901  [15000/60000]\n",
            "loss: 0.314301  [20000/60000]\n",
            "loss: 0.097046  [25000/60000]\n",
            "loss: 0.200433  [30000/60000]\n",
            "loss: 0.084404  [35000/60000]\n",
            "loss: 0.281779  [40000/60000]\n",
            "loss: 0.207051  [45000/60000]\n",
            "loss: 0.139751  [50000/60000]\n",
            "loss: 0.410103  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175090 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128221  [    0/60000]\n",
            "loss: 0.284145  [ 5000/60000]\n",
            "loss: 0.232791  [10000/60000]\n",
            "loss: 0.202100  [15000/60000]\n",
            "loss: 0.132851  [20000/60000]\n",
            "loss: 0.164356  [25000/60000]\n",
            "loss: 0.166008  [30000/60000]\n",
            "loss: 0.201162  [35000/60000]\n",
            "loss: 0.061840  [40000/60000]\n",
            "loss: 0.070667  [45000/60000]\n",
            "loss: 0.175553  [50000/60000]\n",
            "loss: 0.327146  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.170674 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.241969  [    0/60000]\n",
            "loss: 0.193980  [ 5000/60000]\n",
            "loss: 0.182495  [10000/60000]\n",
            "loss: 0.290722  [15000/60000]\n",
            "loss: 0.084766  [20000/60000]\n",
            "loss: 0.158757  [25000/60000]\n",
            "loss: 0.195847  [30000/60000]\n",
            "loss: 0.161513  [35000/60000]\n",
            "loss: 0.221204  [40000/60000]\n",
            "loss: 0.044422  [45000/60000]\n",
            "loss: 0.055540  [50000/60000]\n",
            "loss: 0.108601  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159487 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.180904  [    0/60000]\n",
            "loss: 0.092866  [ 5000/60000]\n",
            "loss: 0.069501  [10000/60000]\n",
            "loss: 0.158384  [15000/60000]\n",
            "loss: 0.181199  [20000/60000]\n",
            "loss: 0.188161  [25000/60000]\n",
            "loss: 0.042164  [30000/60000]\n",
            "loss: 0.142410  [35000/60000]\n",
            "loss: 0.149914  [40000/60000]\n",
            "loss: 0.250734  [45000/60000]\n",
            "loss: 0.125009  [50000/60000]\n",
            "loss: 0.067224  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153679 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040550  [    0/60000]\n",
            "loss: 0.066529  [ 5000/60000]\n",
            "loss: 0.117105  [10000/60000]\n",
            "loss: 0.156913  [15000/60000]\n",
            "loss: 0.104511  [20000/60000]\n",
            "loss: 0.171867  [25000/60000]\n",
            "loss: 0.140621  [30000/60000]\n",
            "loss: 0.096404  [35000/60000]\n",
            "loss: 0.060604  [40000/60000]\n",
            "loss: 0.149659  [45000/60000]\n",
            "loss: 0.320710  [50000/60000]\n",
            "loss: 0.102412  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146093 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.376634  [    0/60000]\n",
            "loss: 0.174749  [ 5000/60000]\n",
            "loss: 0.189986  [10000/60000]\n",
            "loss: 0.222192  [15000/60000]\n",
            "loss: 0.167671  [20000/60000]\n",
            "loss: 0.038280  [25000/60000]\n",
            "loss: 0.092919  [30000/60000]\n",
            "loss: 0.204922  [35000/60000]\n",
            "loss: 0.057280  [40000/60000]\n",
            "loss: 0.067907  [45000/60000]\n",
            "loss: 0.043532  [50000/60000]\n",
            "loss: 0.126258  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141973 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.131053  [    0/60000]\n",
            "loss: 0.071234  [ 5000/60000]\n",
            "loss: 0.117057  [10000/60000]\n",
            "loss: 0.114731  [15000/60000]\n",
            "loss: 0.112003  [20000/60000]\n",
            "loss: 0.068425  [25000/60000]\n",
            "loss: 0.050005  [30000/60000]\n",
            "loss: 0.160989  [35000/60000]\n",
            "loss: 0.246825  [40000/60000]\n",
            "loss: 0.096356  [45000/60000]\n",
            "loss: 0.047287  [50000/60000]\n",
            "loss: 0.240276  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134834 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.473504  [    0/60000]\n",
            "loss: 0.048644  [ 5000/60000]\n",
            "loss: 0.253949  [10000/60000]\n",
            "loss: 0.251564  [15000/60000]\n",
            "loss: 0.068002  [20000/60000]\n",
            "loss: 0.077841  [25000/60000]\n",
            "loss: 0.273731  [30000/60000]\n",
            "loss: 0.109094  [35000/60000]\n",
            "loss: 0.245848  [40000/60000]\n",
            "loss: 0.080115  [45000/60000]\n",
            "loss: 0.080961  [50000/60000]\n",
            "loss: 0.167037  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133203 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149558  [    0/60000]\n",
            "loss: 0.047309  [ 5000/60000]\n",
            "loss: 0.113776  [10000/60000]\n",
            "loss: 0.010349  [15000/60000]\n",
            "loss: 0.159060  [20000/60000]\n",
            "loss: 0.084176  [25000/60000]\n",
            "loss: 0.071498  [30000/60000]\n",
            "loss: 0.052697  [35000/60000]\n",
            "loss: 0.077472  [40000/60000]\n",
            "loss: 0.164603  [45000/60000]\n",
            "loss: 0.056110  [50000/60000]\n",
            "loss: 0.210043  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.125851 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.047813  [    0/60000]\n",
            "loss: 0.062777  [ 5000/60000]\n",
            "loss: 0.247455  [10000/60000]\n",
            "loss: 0.115347  [15000/60000]\n",
            "loss: 0.101996  [20000/60000]\n",
            "loss: 0.088022  [25000/60000]\n",
            "loss: 0.080451  [30000/60000]\n",
            "loss: 0.047597  [35000/60000]\n",
            "loss: 0.123750  [40000/60000]\n",
            "loss: 0.116091  [45000/60000]\n",
            "loss: 0.446508  [50000/60000]\n",
            "loss: 0.123088  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126555 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048695  [    0/60000]\n",
            "loss: 0.141125  [ 5000/60000]\n",
            "loss: 0.066710  [10000/60000]\n",
            "loss: 0.039617  [15000/60000]\n",
            "loss: 0.099047  [20000/60000]\n",
            "loss: 0.085272  [25000/60000]\n",
            "loss: 0.174947  [30000/60000]\n",
            "loss: 0.271450  [35000/60000]\n",
            "loss: 0.043086  [40000/60000]\n",
            "loss: 0.138615  [45000/60000]\n",
            "loss: 0.139067  [50000/60000]\n",
            "loss: 0.069206  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118212 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.101730  [    0/60000]\n",
            "loss: 0.049597  [ 5000/60000]\n",
            "loss: 0.159771  [10000/60000]\n",
            "loss: 0.083123  [15000/60000]\n",
            "loss: 0.064105  [20000/60000]\n",
            "loss: 0.036489  [25000/60000]\n",
            "loss: 0.089545  [30000/60000]\n",
            "loss: 0.118989  [35000/60000]\n",
            "loss: 0.110913  [40000/60000]\n",
            "loss: 0.117353  [45000/60000]\n",
            "loss: 0.041135  [50000/60000]\n",
            "loss: 0.183202  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.116454 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.026296  [    0/60000]\n",
            "loss: 0.060601  [ 5000/60000]\n",
            "loss: 0.080500  [10000/60000]\n",
            "loss: 0.049507  [15000/60000]\n",
            "loss: 0.077388  [20000/60000]\n",
            "loss: 0.013906  [25000/60000]\n",
            "loss: 0.239292  [30000/60000]\n",
            "loss: 0.062832  [35000/60000]\n",
            "loss: 0.059883  [40000/60000]\n",
            "loss: 0.159178  [45000/60000]\n",
            "loss: 0.060895  [50000/60000]\n",
            "loss: 0.039540  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117318 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.158955  [    0/60000]\n",
            "loss: 0.128397  [ 5000/60000]\n",
            "loss: 0.084161  [10000/60000]\n",
            "loss: 0.092713  [15000/60000]\n",
            "loss: 0.314089  [20000/60000]\n",
            "loss: 0.076421  [25000/60000]\n",
            "loss: 0.083773  [30000/60000]\n",
            "loss: 0.089587  [35000/60000]\n",
            "loss: 0.143628  [40000/60000]\n",
            "loss: 0.042289  [45000/60000]\n",
            "loss: 0.089841  [50000/60000]\n",
            "loss: 0.039645  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113396 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.119483  [    0/60000]\n",
            "loss: 0.082778  [ 5000/60000]\n",
            "loss: 0.175224  [10000/60000]\n",
            "loss: 0.097931  [15000/60000]\n",
            "loss: 0.062283  [20000/60000]\n",
            "loss: 0.071057  [25000/60000]\n",
            "loss: 0.029041  [30000/60000]\n",
            "loss: 0.010663  [35000/60000]\n",
            "loss: 0.093591  [40000/60000]\n",
            "loss: 0.101713  [45000/60000]\n",
            "loss: 0.056215  [50000/60000]\n",
            "loss: 0.167798  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.108019 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.233389  [    0/60000]\n",
            "loss: 0.155467  [ 5000/60000]\n",
            "loss: 0.045355  [10000/60000]\n",
            "loss: 0.033061  [15000/60000]\n",
            "loss: 0.025308  [20000/60000]\n",
            "loss: 0.178166  [25000/60000]\n",
            "loss: 0.102672  [30000/60000]\n",
            "loss: 0.163812  [35000/60000]\n",
            "loss: 0.095659  [40000/60000]\n",
            "loss: 0.050718  [45000/60000]\n",
            "loss: 0.088795  [50000/60000]\n",
            "loss: 0.158010  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107401 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050345  [    0/60000]\n",
            "loss: 0.135920  [ 5000/60000]\n",
            "loss: 0.104984  [10000/60000]\n",
            "loss: 0.234570  [15000/60000]\n",
            "loss: 0.049006  [20000/60000]\n",
            "loss: 0.085456  [25000/60000]\n",
            "loss: 0.041132  [30000/60000]\n",
            "loss: 0.211637  [35000/60000]\n",
            "loss: 0.039702  [40000/60000]\n",
            "loss: 0.010623  [45000/60000]\n",
            "loss: 0.247591  [49000/60000]\n",
            "loss: 0.168138  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103948 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034882  [    0/60000]\n",
            "loss: 0.224973  [ 5000/60000]\n",
            "loss: 0.040267  [10000/60000]\n",
            "loss: 0.060213  [15000/60000]\n",
            "loss: 0.015465  [20000/60000]\n",
            "loss: 0.031763  [25000/60000]\n",
            "loss: 0.155410  [30000/60000]\n",
            "loss: 0.066850  [35000/60000]\n",
            "loss: 0.171422  [40000/60000]\n",
            "loss: 0.012163  [45000/60000]\n",
            "loss: 0.066632  [50000/60000]\n",
            "loss: 0.073340  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.101080 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.137889  [    0/60000]\n",
            "loss: 0.021118  [ 5000/60000]\n",
            "loss: 0.038594  [10000/60000]\n",
            "loss: 0.117710  [15000/60000]\n",
            "loss: 0.066830  [20000/60000]\n",
            "loss: 0.140640  [25000/60000]\n",
            "loss: 0.049366  [30000/60000]\n",
            "loss: 0.033397  [35000/60000]\n",
            "loss: 0.161704  [40000/60000]\n",
            "loss: 0.097965  [45000/60000]\n",
            "loss: 0.043814  [50000/60000]\n",
            "loss: 0.030855  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098980 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048368  [    0/60000]\n",
            "loss: 0.054401  [ 5000/60000]\n",
            "loss: 0.070142  [10000/60000]\n",
            "loss: 0.031897  [15000/60000]\n",
            "loss: 0.024605  [20000/60000]\n",
            "loss: 0.081468  [25000/60000]\n",
            "loss: 0.068292  [30000/60000]\n",
            "loss: 0.157968  [35000/60000]\n",
            "loss: 0.042931  [40000/60000]\n",
            "loss: 0.089817  [45000/60000]\n",
            "loss: 0.058898  [50000/60000]\n",
            "loss: 0.104356  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.099599 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 7\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314301  [30000/60000]\n",
            "loss: 1.119928  [35000/60000]\n",
            "loss: 1.104700  [40000/60000]\n",
            "loss: 1.037225  [45000/60000]\n",
            "loss: 0.860629  [50000/60000]\n",
            "loss: 0.646611  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590780 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629861  [    0/60000]\n",
            "loss: 0.527615  [ 5000/60000]\n",
            "loss: 0.491023  [10000/60000]\n",
            "loss: 0.540458  [15000/60000]\n",
            "loss: 0.418388  [20000/60000]\n",
            "loss: 0.493034  [25000/60000]\n",
            "loss: 0.458790  [30000/60000]\n",
            "loss: 0.487686  [35000/60000]\n",
            "loss: 0.718821  [40000/60000]\n",
            "loss: 0.727011  [45000/60000]\n",
            "loss: 0.260436  [50000/60000]\n",
            "loss: 0.347337  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379055 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231748  [    0/60000]\n",
            "loss: 0.206687  [ 5000/60000]\n",
            "loss: 0.527618  [10000/60000]\n",
            "loss: 0.144605  [15000/60000]\n",
            "loss: 0.355224  [20000/60000]\n",
            "loss: 0.215240  [25000/60000]\n",
            "loss: 0.446793  [30000/60000]\n",
            "loss: 0.289265  [35000/60000]\n",
            "loss: 0.366770  [40000/60000]\n",
            "loss: 0.569128  [45000/60000]\n",
            "loss: 0.331919  [50000/60000]\n",
            "loss: 0.502913  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325586 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397407  [    0/60000]\n",
            "loss: 0.817289  [ 5000/60000]\n",
            "loss: 0.415102  [10000/60000]\n",
            "loss: 0.300869  [15000/60000]\n",
            "loss: 0.449591  [20000/60000]\n",
            "loss: 0.402269  [25000/60000]\n",
            "loss: 0.228473  [30000/60000]\n",
            "loss: 0.368654  [35000/60000]\n",
            "loss: 0.498464  [40000/60000]\n",
            "loss: 0.470922  [45000/60000]\n",
            "loss: 0.396919  [50000/60000]\n",
            "loss: 0.217840  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290559 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231114  [    0/60000]\n",
            "loss: 0.209284  [ 5000/60000]\n",
            "loss: 0.142476  [10000/60000]\n",
            "loss: 0.434302  [15000/60000]\n",
            "loss: 0.323019  [20000/60000]\n",
            "loss: 0.134349  [25000/60000]\n",
            "loss: 0.122849  [30000/60000]\n",
            "loss: 0.419383  [35000/60000]\n",
            "loss: 0.286941  [40000/60000]\n",
            "loss: 0.309778  [45000/60000]\n",
            "loss: 0.223010  [50000/60000]\n",
            "loss: 0.535102  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268335 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166826  [    0/60000]\n",
            "loss: 0.176767  [ 5000/60000]\n",
            "loss: 0.144185  [10000/60000]\n",
            "loss: 0.474896  [15000/60000]\n",
            "loss: 0.372307  [20000/60000]\n",
            "loss: 0.264295  [25000/60000]\n",
            "loss: 0.279722  [30000/60000]\n",
            "loss: 0.195811  [35000/60000]\n",
            "loss: 0.163379  [40000/60000]\n",
            "loss: 0.166294  [45000/60000]\n",
            "loss: 0.294986  [50000/60000]\n",
            "loss: 0.314468  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.247342 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146456  [    0/60000]\n",
            "loss: 0.337878  [ 5000/60000]\n",
            "loss: 0.349826  [10000/60000]\n",
            "loss: 0.121994  [15000/60000]\n",
            "loss: 0.176554  [20000/60000]\n",
            "loss: 0.189510  [25000/60000]\n",
            "loss: 0.255217  [30000/60000]\n",
            "loss: 0.112697  [35000/60000]\n",
            "loss: 0.263371  [40000/60000]\n",
            "loss: 0.386086  [45000/60000]\n",
            "loss: 0.373830  [50000/60000]\n",
            "loss: 0.067771  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228126 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193426  [    0/60000]\n",
            "loss: 0.192529  [ 5000/60000]\n",
            "loss: 0.210571  [10000/60000]\n",
            "loss: 0.199292  [15000/60000]\n",
            "loss: 0.216837  [20000/60000]\n",
            "loss: 0.075556  [25000/60000]\n",
            "loss: 0.383306  [30000/60000]\n",
            "loss: 0.177186  [35000/60000]\n",
            "loss: 0.273226  [40000/60000]\n",
            "loss: 0.152689  [45000/60000]\n",
            "loss: 0.227569  [50000/60000]\n",
            "loss: 0.141198  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216044 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.174260  [    0/60000]\n",
            "loss: 0.115742  [ 5000/60000]\n",
            "loss: 0.235168  [10000/60000]\n",
            "loss: 0.419122  [15000/60000]\n",
            "loss: 0.156254  [20000/60000]\n",
            "loss: 0.165132  [25000/60000]\n",
            "loss: 0.192012  [30000/60000]\n",
            "loss: 0.147300  [35000/60000]\n",
            "loss: 0.062798  [40000/60000]\n",
            "loss: 0.185070  [45000/60000]\n",
            "loss: 0.236934  [50000/60000]\n",
            "loss: 0.172273  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202106 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200399  [    0/60000]\n",
            "loss: 0.343113  [ 5000/60000]\n",
            "loss: 0.237611  [10000/60000]\n",
            "loss: 0.152350  [15000/60000]\n",
            "loss: 0.101074  [20000/60000]\n",
            "loss: 0.146411  [25000/60000]\n",
            "loss: 0.241670  [30000/60000]\n",
            "loss: 0.243632  [35000/60000]\n",
            "loss: 0.270717  [40000/60000]\n",
            "loss: 0.157876  [45000/60000]\n",
            "loss: 0.331724  [50000/60000]\n",
            "loss: 0.060538  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186856 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069434  [    0/60000]\n",
            "loss: 0.128172  [ 5000/60000]\n",
            "loss: 0.212004  [10000/60000]\n",
            "loss: 0.301628  [15000/60000]\n",
            "loss: 0.314577  [20000/60000]\n",
            "loss: 0.097243  [25000/60000]\n",
            "loss: 0.200173  [30000/60000]\n",
            "loss: 0.084528  [35000/60000]\n",
            "loss: 0.281438  [40000/60000]\n",
            "loss: 0.206886  [45000/60000]\n",
            "loss: 0.139621  [50000/60000]\n",
            "loss: 0.410401  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175088 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128428  [    0/60000]\n",
            "loss: 0.284778  [ 5000/60000]\n",
            "loss: 0.232375  [10000/60000]\n",
            "loss: 0.202584  [15000/60000]\n",
            "loss: 0.132869  [20000/60000]\n",
            "loss: 0.164586  [25000/60000]\n",
            "loss: 0.166130  [30000/60000]\n",
            "loss: 0.201446  [35000/60000]\n",
            "loss: 0.061975  [40000/60000]\n",
            "loss: 0.070739  [45000/60000]\n",
            "loss: 0.175840  [50000/60000]\n",
            "loss: 0.327045  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.170644 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.242023  [    0/60000]\n",
            "loss: 0.193251  [ 5000/60000]\n",
            "loss: 0.183006  [10000/60000]\n",
            "loss: 0.290820  [15000/60000]\n",
            "loss: 0.084701  [20000/60000]\n",
            "loss: 0.158401  [25000/60000]\n",
            "loss: 0.195492  [30000/60000]\n",
            "loss: 0.161646  [35000/60000]\n",
            "loss: 0.220569  [40000/60000]\n",
            "loss: 0.044491  [45000/60000]\n",
            "loss: 0.055733  [50000/60000]\n",
            "loss: 0.108564  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159473 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.181635  [    0/60000]\n",
            "loss: 0.092746  [ 5000/60000]\n",
            "loss: 0.069226  [10000/60000]\n",
            "loss: 0.158032  [15000/60000]\n",
            "loss: 0.180936  [20000/60000]\n",
            "loss: 0.188398  [25000/60000]\n",
            "loss: 0.042127  [30000/60000]\n",
            "loss: 0.142500  [35000/60000]\n",
            "loss: 0.150107  [40000/60000]\n",
            "loss: 0.250427  [45000/60000]\n",
            "loss: 0.125339  [50000/60000]\n",
            "loss: 0.067166  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153609 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040411  [    0/60000]\n",
            "loss: 0.066426  [ 5000/60000]\n",
            "loss: 0.116880  [10000/60000]\n",
            "loss: 0.156651  [15000/60000]\n",
            "loss: 0.104370  [20000/60000]\n",
            "loss: 0.171887  [25000/60000]\n",
            "loss: 0.141111  [30000/60000]\n",
            "loss: 0.096830  [35000/60000]\n",
            "loss: 0.060683  [40000/60000]\n",
            "loss: 0.149621  [45000/60000]\n",
            "loss: 0.321291  [50000/60000]\n",
            "loss: 0.102386  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146038 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.377441  [    0/60000]\n",
            "loss: 0.174763  [ 5000/60000]\n",
            "loss: 0.190004  [10000/60000]\n",
            "loss: 0.221789  [15000/60000]\n",
            "loss: 0.166520  [20000/60000]\n",
            "loss: 0.038296  [25000/60000]\n",
            "loss: 0.093167  [30000/60000]\n",
            "loss: 0.204232  [35000/60000]\n",
            "loss: 0.057389  [40000/60000]\n",
            "loss: 0.068014  [45000/60000]\n",
            "loss: 0.043495  [50000/60000]\n",
            "loss: 0.125611  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141984 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.130656  [    0/60000]\n",
            "loss: 0.070633  [ 5000/60000]\n",
            "loss: 0.117247  [10000/60000]\n",
            "loss: 0.114727  [15000/60000]\n",
            "loss: 0.112186  [20000/60000]\n",
            "loss: 0.067778  [25000/60000]\n",
            "loss: 0.050013  [30000/60000]\n",
            "loss: 0.160980  [35000/60000]\n",
            "loss: 0.247633  [40000/60000]\n",
            "loss: 0.095985  [45000/60000]\n",
            "loss: 0.047523  [50000/60000]\n",
            "loss: 0.240450  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134830 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.473778  [    0/60000]\n",
            "loss: 0.049087  [ 5000/60000]\n",
            "loss: 0.253552  [10000/60000]\n",
            "loss: 0.251790  [15000/60000]\n",
            "loss: 0.067764  [20000/60000]\n",
            "loss: 0.078092  [25000/60000]\n",
            "loss: 0.273251  [30000/60000]\n",
            "loss: 0.109045  [35000/60000]\n",
            "loss: 0.246012  [40000/60000]\n",
            "loss: 0.080176  [45000/60000]\n",
            "loss: 0.080258  [50000/60000]\n",
            "loss: 0.167807  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133119 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.149107  [    0/60000]\n",
            "loss: 0.046680  [ 5000/60000]\n",
            "loss: 0.114089  [10000/60000]\n",
            "loss: 0.010320  [15000/60000]\n",
            "loss: 0.159391  [20000/60000]\n",
            "loss: 0.084133  [25000/60000]\n",
            "loss: 0.071636  [30000/60000]\n",
            "loss: 0.052433  [35000/60000]\n",
            "loss: 0.077189  [40000/60000]\n",
            "loss: 0.163996  [45000/60000]\n",
            "loss: 0.056328  [50000/60000]\n",
            "loss: 0.210905  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.125725 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.048039  [    0/60000]\n",
            "loss: 0.063066  [ 5000/60000]\n",
            "loss: 0.246623  [10000/60000]\n",
            "loss: 0.115501  [15000/60000]\n",
            "loss: 0.101715  [20000/60000]\n",
            "loss: 0.087667  [25000/60000]\n",
            "loss: 0.080915  [30000/60000]\n",
            "loss: 0.047630  [35000/60000]\n",
            "loss: 0.123237  [40000/60000]\n",
            "loss: 0.116092  [45000/60000]\n",
            "loss: 0.447689  [50000/60000]\n",
            "loss: 0.123718  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126484 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048041  [    0/60000]\n",
            "loss: 0.140350  [ 5000/60000]\n",
            "loss: 0.066698  [10000/60000]\n",
            "loss: 0.039658  [15000/60000]\n",
            "loss: 0.098614  [20000/60000]\n",
            "loss: 0.085008  [25000/60000]\n",
            "loss: 0.175762  [30000/60000]\n",
            "loss: 0.271532  [35000/60000]\n",
            "loss: 0.042937  [40000/60000]\n",
            "loss: 0.138606  [45000/60000]\n",
            "loss: 0.138989  [50000/60000]\n",
            "loss: 0.069248  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118183 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.102035  [    0/60000]\n",
            "loss: 0.049031  [ 5000/60000]\n",
            "loss: 0.159509  [10000/60000]\n",
            "loss: 0.083745  [15000/60000]\n",
            "loss: 0.064495  [20000/60000]\n",
            "loss: 0.036585  [25000/60000]\n",
            "loss: 0.090060  [30000/60000]\n",
            "loss: 0.117932  [35000/60000]\n",
            "loss: 0.111725  [40000/60000]\n",
            "loss: 0.116689  [45000/60000]\n",
            "loss: 0.041385  [50000/60000]\n",
            "loss: 0.182920  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.116362 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.025980  [    0/60000]\n",
            "loss: 0.060613  [ 5000/60000]\n",
            "loss: 0.079927  [10000/60000]\n",
            "loss: 0.049421  [15000/60000]\n",
            "loss: 0.077802  [20000/60000]\n",
            "loss: 0.013926  [25000/60000]\n",
            "loss: 0.240637  [30000/60000]\n",
            "loss: 0.062460  [35000/60000]\n",
            "loss: 0.060327  [40000/60000]\n",
            "loss: 0.158857  [45000/60000]\n",
            "loss: 0.060981  [50000/60000]\n",
            "loss: 0.039556  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117175 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.159435  [    0/60000]\n",
            "loss: 0.129444  [ 5000/60000]\n",
            "loss: 0.083818  [10000/60000]\n",
            "loss: 0.093070  [15000/60000]\n",
            "loss: 0.314543  [20000/60000]\n",
            "loss: 0.076273  [25000/60000]\n",
            "loss: 0.083570  [30000/60000]\n",
            "loss: 0.089420  [35000/60000]\n",
            "loss: 0.143813  [40000/60000]\n",
            "loss: 0.042237  [45000/60000]\n",
            "loss: 0.089658  [50000/60000]\n",
            "loss: 0.040221  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113337 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.120504  [    0/60000]\n",
            "loss: 0.082496  [ 5000/60000]\n",
            "loss: 0.174380  [10000/60000]\n",
            "loss: 0.098522  [15000/60000]\n",
            "loss: 0.062095  [20000/60000]\n",
            "loss: 0.071120  [25000/60000]\n",
            "loss: 0.029177  [30000/60000]\n",
            "loss: 0.010665  [35000/60000]\n",
            "loss: 0.094016  [40000/60000]\n",
            "loss: 0.104107  [45000/60000]\n",
            "loss: 0.055954  [50000/60000]\n",
            "loss: 0.168596  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.108105 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.232145  [    0/60000]\n",
            "loss: 0.155090  [ 5000/60000]\n",
            "loss: 0.046349  [10000/60000]\n",
            "loss: 0.032871  [15000/60000]\n",
            "loss: 0.025232  [20000/60000]\n",
            "loss: 0.177715  [25000/60000]\n",
            "loss: 0.103084  [30000/60000]\n",
            "loss: 0.165142  [35000/60000]\n",
            "loss: 0.095390  [40000/60000]\n",
            "loss: 0.050420  [45000/60000]\n",
            "loss: 0.088971  [50000/60000]\n",
            "loss: 0.156928  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107337 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050305  [    0/60000]\n",
            "loss: 0.135694  [ 5000/60000]\n",
            "loss: 0.104695  [10000/60000]\n",
            "loss: 0.234648  [15000/60000]\n",
            "loss: 0.048883  [20000/60000]\n",
            "loss: 0.085889  [25000/60000]\n",
            "loss: 0.041528  [30000/60000]\n",
            "loss: 0.212678  [35000/60000]\n",
            "loss: 0.039856  [40000/60000]\n",
            "loss: 0.010628  [45000/60000]\n",
            "loss: 0.242567  [50000/60000]\n",
            "loss: 0.169639  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.103918 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034160  [    0/60000]\n",
            "loss: 0.223248  [ 5000/60000]\n",
            "loss: 0.040790  [10000/60000]\n",
            "loss: 0.060255  [15000/60000]\n",
            "loss: 0.015646  [20000/60000]\n",
            "loss: 0.031818  [25000/60000]\n",
            "loss: 0.156033  [30000/60000]\n",
            "loss: 0.066417  [35000/60000]\n",
            "loss: 0.171708  [40000/60000]\n",
            "loss: 0.012122  [45000/60000]\n",
            "loss: 0.066555  [50000/60000]\n",
            "loss: 0.073329  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.101074 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.139142  [    0/60000]\n",
            "loss: 0.021367  [ 5000/60000]\n",
            "loss: 0.038675  [10000/60000]\n",
            "loss: 0.117727  [15000/60000]\n",
            "loss: 0.066612  [20000/60000]\n",
            "loss: 0.139938  [25000/60000]\n",
            "loss: 0.049460  [30000/60000]\n",
            "loss: 0.033760  [35000/60000]\n",
            "loss: 0.162829  [40000/60000]\n",
            "loss: 0.096478  [45000/60000]\n",
            "loss: 0.044293  [50000/60000]\n",
            "loss: 0.030425  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098944 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.047947  [    0/60000]\n",
            "loss: 0.054640  [ 5000/60000]\n",
            "loss: 0.069415  [10000/60000]\n",
            "loss: 0.032178  [15000/60000]\n",
            "loss: 0.024474  [20000/60000]\n",
            "loss: 0.080991  [25000/60000]\n",
            "loss: 0.067834  [30000/60000]\n",
            "loss: 0.158286  [35000/60000]\n",
            "loss: 0.042706  [40000/60000]\n",
            "loss: 0.089971  [45000/60000]\n",
            "loss: 0.059234  [50000/60000]\n",
            "loss: 0.103520  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099665 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 8\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314301  [30000/60000]\n",
            "loss: 1.119928  [35000/60000]\n",
            "loss: 1.104692  [40000/60000]\n",
            "loss: 1.037234  [45000/60000]\n",
            "loss: 0.860635  [50000/60000]\n",
            "loss: 0.646572  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590786 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629871  [    0/60000]\n",
            "loss: 0.527641  [ 5000/60000]\n",
            "loss: 0.491046  [10000/60000]\n",
            "loss: 0.540477  [15000/60000]\n",
            "loss: 0.418402  [20000/60000]\n",
            "loss: 0.493019  [25000/60000]\n",
            "loss: 0.458796  [30000/60000]\n",
            "loss: 0.487681  [35000/60000]\n",
            "loss: 0.718830  [40000/60000]\n",
            "loss: 0.726986  [45000/60000]\n",
            "loss: 0.260474  [50000/60000]\n",
            "loss: 0.347284  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379056 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231727  [    0/60000]\n",
            "loss: 0.206691  [ 5000/60000]\n",
            "loss: 0.527571  [10000/60000]\n",
            "loss: 0.144586  [15000/60000]\n",
            "loss: 0.355215  [20000/60000]\n",
            "loss: 0.215299  [25000/60000]\n",
            "loss: 0.446844  [30000/60000]\n",
            "loss: 0.289279  [35000/60000]\n",
            "loss: 0.366751  [40000/60000]\n",
            "loss: 0.569203  [45000/60000]\n",
            "loss: 0.331874  [50000/60000]\n",
            "loss: 0.502953  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325591 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397474  [    0/60000]\n",
            "loss: 0.817160  [ 5000/60000]\n",
            "loss: 0.415106  [10000/60000]\n",
            "loss: 0.300848  [15000/60000]\n",
            "loss: 0.449524  [20000/60000]\n",
            "loss: 0.402290  [25000/60000]\n",
            "loss: 0.228529  [30000/60000]\n",
            "loss: 0.368529  [35000/60000]\n",
            "loss: 0.498400  [40000/60000]\n",
            "loss: 0.470808  [45000/60000]\n",
            "loss: 0.396822  [50000/60000]\n",
            "loss: 0.217813  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290557 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231148  [    0/60000]\n",
            "loss: 0.209233  [ 5000/60000]\n",
            "loss: 0.142471  [10000/60000]\n",
            "loss: 0.434376  [15000/60000]\n",
            "loss: 0.323041  [20000/60000]\n",
            "loss: 0.134378  [25000/60000]\n",
            "loss: 0.122855  [30000/60000]\n",
            "loss: 0.419486  [35000/60000]\n",
            "loss: 0.286931  [40000/60000]\n",
            "loss: 0.309902  [45000/60000]\n",
            "loss: 0.223166  [50000/60000]\n",
            "loss: 0.534812  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268322 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166848  [    0/60000]\n",
            "loss: 0.176883  [ 5000/60000]\n",
            "loss: 0.144307  [10000/60000]\n",
            "loss: 0.474976  [15000/60000]\n",
            "loss: 0.372393  [20000/60000]\n",
            "loss: 0.263684  [25000/60000]\n",
            "loss: 0.279446  [30000/60000]\n",
            "loss: 0.195745  [35000/60000]\n",
            "loss: 0.163362  [40000/60000]\n",
            "loss: 0.166227  [45000/60000]\n",
            "loss: 0.294841  [50000/60000]\n",
            "loss: 0.314419  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.247346 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146411  [    0/60000]\n",
            "loss: 0.337845  [ 5000/60000]\n",
            "loss: 0.349947  [10000/60000]\n",
            "loss: 0.121689  [15000/60000]\n",
            "loss: 0.175307  [20000/60000]\n",
            "loss: 0.189525  [25000/60000]\n",
            "loss: 0.255808  [30000/60000]\n",
            "loss: 0.112835  [35000/60000]\n",
            "loss: 0.263841  [40000/60000]\n",
            "loss: 0.385656  [45000/60000]\n",
            "loss: 0.374225  [50000/60000]\n",
            "loss: 0.067828  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228221 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193149  [    0/60000]\n",
            "loss: 0.192308  [ 5000/60000]\n",
            "loss: 0.210764  [10000/60000]\n",
            "loss: 0.199525  [15000/60000]\n",
            "loss: 0.217049  [20000/60000]\n",
            "loss: 0.075648  [25000/60000]\n",
            "loss: 0.382979  [30000/60000]\n",
            "loss: 0.177252  [35000/60000]\n",
            "loss: 0.273124  [40000/60000]\n",
            "loss: 0.152712  [45000/60000]\n",
            "loss: 0.227576  [50000/60000]\n",
            "loss: 0.141163  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216162 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.174490  [    0/60000]\n",
            "loss: 0.115934  [ 5000/60000]\n",
            "loss: 0.235294  [10000/60000]\n",
            "loss: 0.419063  [15000/60000]\n",
            "loss: 0.155837  [20000/60000]\n",
            "loss: 0.165277  [25000/60000]\n",
            "loss: 0.192047  [30000/60000]\n",
            "loss: 0.147132  [35000/60000]\n",
            "loss: 0.062780  [40000/60000]\n",
            "loss: 0.185091  [45000/60000]\n",
            "loss: 0.236789  [50000/60000]\n",
            "loss: 0.172111  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202203 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200461  [    0/60000]\n",
            "loss: 0.343656  [ 5000/60000]\n",
            "loss: 0.237542  [10000/60000]\n",
            "loss: 0.152189  [15000/60000]\n",
            "loss: 0.101061  [20000/60000]\n",
            "loss: 0.146541  [25000/60000]\n",
            "loss: 0.241970  [30000/60000]\n",
            "loss: 0.243736  [35000/60000]\n",
            "loss: 0.271043  [40000/60000]\n",
            "loss: 0.158176  [45000/60000]\n",
            "loss: 0.331787  [50000/60000]\n",
            "loss: 0.060573  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186901 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069678  [    0/60000]\n",
            "loss: 0.128154  [ 5000/60000]\n",
            "loss: 0.211980  [10000/60000]\n",
            "loss: 0.301681  [15000/60000]\n",
            "loss: 0.314125  [20000/60000]\n",
            "loss: 0.097313  [25000/60000]\n",
            "loss: 0.200107  [30000/60000]\n",
            "loss: 0.084624  [35000/60000]\n",
            "loss: 0.281500  [40000/60000]\n",
            "loss: 0.206938  [45000/60000]\n",
            "loss: 0.139415  [50000/60000]\n",
            "loss: 0.410434  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175132 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128755  [    0/60000]\n",
            "loss: 0.284414  [ 5000/60000]\n",
            "loss: 0.232685  [10000/60000]\n",
            "loss: 0.201705  [15000/60000]\n",
            "loss: 0.133076  [20000/60000]\n",
            "loss: 0.164846  [25000/60000]\n",
            "loss: 0.166227  [30000/60000]\n",
            "loss: 0.201219  [35000/60000]\n",
            "loss: 0.061782  [40000/60000]\n",
            "loss: 0.070983  [45000/60000]\n",
            "loss: 0.175273  [50000/60000]\n",
            "loss: 0.326559  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.170698 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.242900  [    0/60000]\n",
            "loss: 0.194249  [ 5000/60000]\n",
            "loss: 0.183339  [10000/60000]\n",
            "loss: 0.291048  [15000/60000]\n",
            "loss: 0.084943  [20000/60000]\n",
            "loss: 0.158348  [25000/60000]\n",
            "loss: 0.195373  [30000/60000]\n",
            "loss: 0.161197  [35000/60000]\n",
            "loss: 0.221037  [40000/60000]\n",
            "loss: 0.044634  [45000/60000]\n",
            "loss: 0.055916  [50000/60000]\n",
            "loss: 0.108738  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159504 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.181377  [    0/60000]\n",
            "loss: 0.093052  [ 5000/60000]\n",
            "loss: 0.069190  [10000/60000]\n",
            "loss: 0.158148  [15000/60000]\n",
            "loss: 0.181962  [20000/60000]\n",
            "loss: 0.188074  [25000/60000]\n",
            "loss: 0.042217  [30000/60000]\n",
            "loss: 0.142293  [35000/60000]\n",
            "loss: 0.150484  [40000/60000]\n",
            "loss: 0.250837  [45000/60000]\n",
            "loss: 0.125395  [50000/60000]\n",
            "loss: 0.067189  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153765 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040649  [    0/60000]\n",
            "loss: 0.066566  [ 5000/60000]\n",
            "loss: 0.116809  [10000/60000]\n",
            "loss: 0.157332  [15000/60000]\n",
            "loss: 0.104358  [20000/60000]\n",
            "loss: 0.170924  [25000/60000]\n",
            "loss: 0.141487  [30000/60000]\n",
            "loss: 0.095942  [35000/60000]\n",
            "loss: 0.060463  [40000/60000]\n",
            "loss: 0.149601  [45000/60000]\n",
            "loss: 0.322606  [50000/60000]\n",
            "loss: 0.102044  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146150 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.377357  [    0/60000]\n",
            "loss: 0.175542  [ 5000/60000]\n",
            "loss: 0.189561  [10000/60000]\n",
            "loss: 0.221222  [15000/60000]\n",
            "loss: 0.167870  [20000/60000]\n",
            "loss: 0.038297  [25000/60000]\n",
            "loss: 0.092843  [30000/60000]\n",
            "loss: 0.204437  [35000/60000]\n",
            "loss: 0.057327  [40000/60000]\n",
            "loss: 0.067932  [45000/60000]\n",
            "loss: 0.043435  [50000/60000]\n",
            "loss: 0.125427  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.142113 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.130902  [    0/60000]\n",
            "loss: 0.071036  [ 5000/60000]\n",
            "loss: 0.116663  [10000/60000]\n",
            "loss: 0.115386  [15000/60000]\n",
            "loss: 0.112150  [20000/60000]\n",
            "loss: 0.067416  [25000/60000]\n",
            "loss: 0.050156  [30000/60000]\n",
            "loss: 0.160057  [35000/60000]\n",
            "loss: 0.249897  [40000/60000]\n",
            "loss: 0.096031  [45000/60000]\n",
            "loss: 0.047416  [50000/60000]\n",
            "loss: 0.242046  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134931 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.472925  [    0/60000]\n",
            "loss: 0.048898  [ 5000/60000]\n",
            "loss: 0.253671  [10000/60000]\n",
            "loss: 0.252028  [15000/60000]\n",
            "loss: 0.068159  [20000/60000]\n",
            "loss: 0.077998  [25000/60000]\n",
            "loss: 0.273743  [30000/60000]\n",
            "loss: 0.110461  [35000/60000]\n",
            "loss: 0.246795  [40000/60000]\n",
            "loss: 0.080380  [45000/60000]\n",
            "loss: 0.080868  [50000/60000]\n",
            "loss: 0.167537  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133212 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.150430  [    0/60000]\n",
            "loss: 0.046788  [ 5000/60000]\n",
            "loss: 0.115055  [10000/60000]\n",
            "loss: 0.010318  [15000/60000]\n",
            "loss: 0.159912  [20000/60000]\n",
            "loss: 0.084035  [25000/60000]\n",
            "loss: 0.072509  [30000/60000]\n",
            "loss: 0.051980  [35000/60000]\n",
            "loss: 0.077155  [40000/60000]\n",
            "loss: 0.163269  [45000/60000]\n",
            "loss: 0.056590  [50000/60000]\n",
            "loss: 0.213856  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.125978 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.048244  [    0/60000]\n",
            "loss: 0.063025  [ 5000/60000]\n",
            "loss: 0.247891  [10000/60000]\n",
            "loss: 0.114745  [15000/60000]\n",
            "loss: 0.102182  [20000/60000]\n",
            "loss: 0.087672  [25000/60000]\n",
            "loss: 0.080742  [30000/60000]\n",
            "loss: 0.047500  [35000/60000]\n",
            "loss: 0.124569  [40000/60000]\n",
            "loss: 0.116674  [45000/60000]\n",
            "loss: 0.447328  [50000/60000]\n",
            "loss: 0.123584  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126669 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048178  [    0/60000]\n",
            "loss: 0.140305  [ 5000/60000]\n",
            "loss: 0.066856  [10000/60000]\n",
            "loss: 0.039918  [15000/60000]\n",
            "loss: 0.098420  [20000/60000]\n",
            "loss: 0.085058  [25000/60000]\n",
            "loss: 0.174747  [30000/60000]\n",
            "loss: 0.271212  [35000/60000]\n",
            "loss: 0.043227  [40000/60000]\n",
            "loss: 0.139309  [45000/60000]\n",
            "loss: 0.138417  [50000/60000]\n",
            "loss: 0.070080  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118356 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.102114  [    0/60000]\n",
            "loss: 0.049365  [ 5000/60000]\n",
            "loss: 0.160499  [10000/60000]\n",
            "loss: 0.082839  [15000/60000]\n",
            "loss: 0.065191  [20000/60000]\n",
            "loss: 0.036851  [25000/60000]\n",
            "loss: 0.088891  [30000/60000]\n",
            "loss: 0.119011  [35000/60000]\n",
            "loss: 0.110971  [40000/60000]\n",
            "loss: 0.117430  [45000/60000]\n",
            "loss: 0.040884  [50000/60000]\n",
            "loss: 0.184134  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.116598 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.026084  [    0/60000]\n",
            "loss: 0.060000  [ 5000/60000]\n",
            "loss: 0.079622  [10000/60000]\n",
            "loss: 0.049186  [15000/60000]\n",
            "loss: 0.076949  [20000/60000]\n",
            "loss: 0.013828  [25000/60000]\n",
            "loss: 0.237297  [30000/60000]\n",
            "loss: 0.062973  [35000/60000]\n",
            "loss: 0.061097  [40000/60000]\n",
            "loss: 0.159372  [45000/60000]\n",
            "loss: 0.061397  [50000/60000]\n",
            "loss: 0.039756  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117310 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.159964  [    0/60000]\n",
            "loss: 0.128639  [ 5000/60000]\n",
            "loss: 0.083919  [10000/60000]\n",
            "loss: 0.092803  [15000/60000]\n",
            "loss: 0.314714  [20000/60000]\n",
            "loss: 0.075861  [25000/60000]\n",
            "loss: 0.083590  [30000/60000]\n",
            "loss: 0.089917  [35000/60000]\n",
            "loss: 0.144426  [40000/60000]\n",
            "loss: 0.042296  [45000/60000]\n",
            "loss: 0.090323  [50000/60000]\n",
            "loss: 0.039549  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113507 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.120757  [    0/60000]\n",
            "loss: 0.082623  [ 5000/60000]\n",
            "loss: 0.176437  [10000/60000]\n",
            "loss: 0.098615  [15000/60000]\n",
            "loss: 0.063100  [20000/60000]\n",
            "loss: 0.071085  [25000/60000]\n",
            "loss: 0.029143  [30000/60000]\n",
            "loss: 0.010477  [35000/60000]\n",
            "loss: 0.093357  [40000/60000]\n",
            "loss: 0.101653  [45000/60000]\n",
            "loss: 0.055012  [50000/60000]\n",
            "loss: 0.167902  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.108352 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.231277  [    0/60000]\n",
            "loss: 0.155416  [ 5000/60000]\n",
            "loss: 0.045876  [10000/60000]\n",
            "loss: 0.034368  [15000/60000]\n",
            "loss: 0.025646  [20000/60000]\n",
            "loss: 0.184092  [25000/60000]\n",
            "loss: 0.103590  [30000/60000]\n",
            "loss: 0.164270  [35000/60000]\n",
            "loss: 0.098053  [40000/60000]\n",
            "loss: 0.050187  [45000/60000]\n",
            "loss: 0.088519  [50000/60000]\n",
            "loss: 0.157327  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107439 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050459  [    0/60000]\n",
            "loss: 0.135458  [ 5000/60000]\n",
            "loss: 0.106388  [10000/60000]\n",
            "loss: 0.232566  [15000/60000]\n",
            "loss: 0.048689  [20000/60000]\n",
            "loss: 0.086694  [25000/60000]\n",
            "loss: 0.041163  [30000/60000]\n",
            "loss: 0.213410  [35000/60000]\n",
            "loss: 0.040074  [40000/60000]\n",
            "loss: 0.010534  [45000/60000]\n",
            "loss: 0.243172  [50000/60000]\n",
            "loss: 0.159123  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103991 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034438  [    0/60000]\n",
            "loss: 0.227228  [ 5000/60000]\n",
            "loss: 0.040551  [10000/60000]\n",
            "loss: 0.060546  [15000/60000]\n",
            "loss: 0.015173  [20000/60000]\n",
            "loss: 0.031859  [25000/60000]\n",
            "loss: 0.155528  [30000/60000]\n",
            "loss: 0.067669  [35000/60000]\n",
            "loss: 0.171736  [40000/60000]\n",
            "loss: 0.012346  [45000/60000]\n",
            "loss: 0.066667  [50000/60000]\n",
            "loss: 0.073127  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.101131 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.139913  [    0/60000]\n",
            "loss: 0.020635  [ 5000/60000]\n",
            "loss: 0.037963  [10000/60000]\n",
            "loss: 0.118377  [15000/60000]\n",
            "loss: 0.066599  [20000/60000]\n",
            "loss: 0.142081  [25000/60000]\n",
            "loss: 0.052466  [30000/60000]\n",
            "loss: 0.034094  [35000/60000]\n",
            "loss: 0.161220  [40000/60000]\n",
            "loss: 0.098762  [45000/60000]\n",
            "loss: 0.043674  [50000/60000]\n",
            "loss: 0.030032  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098970 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048135  [    0/60000]\n",
            "loss: 0.054932  [ 5000/60000]\n",
            "loss: 0.068874  [10000/60000]\n",
            "loss: 0.032581  [15000/60000]\n",
            "loss: 0.024845  [20000/60000]\n",
            "loss: 0.081300  [25000/60000]\n",
            "loss: 0.068658  [30000/60000]\n",
            "loss: 0.157550  [35000/60000]\n",
            "loss: 0.042560  [40000/60000]\n",
            "loss: 0.089440  [45000/60000]\n",
            "loss: 0.059223  [50000/60000]\n",
            "loss: 0.103696  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099724 \n",
            "\n",
            "Done!\n",
            "Removing an element from class: 9\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.256504  [ 5000/60000]\n",
            "loss: 2.201739  [10000/60000]\n",
            "loss: 2.074165  [15000/60000]\n",
            "loss: 1.996427  [20000/60000]\n",
            "loss: 1.760605  [25000/60000]\n",
            "loss: 1.314244  [30000/60000]\n",
            "loss: 1.119934  [35000/60000]\n",
            "loss: 1.104678  [40000/60000]\n",
            "loss: 1.037245  [45000/60000]\n",
            "loss: 0.860606  [50000/60000]\n",
            "loss: 0.646563  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.590774 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.629830  [    0/60000]\n",
            "loss: 0.527582  [ 5000/60000]\n",
            "loss: 0.491026  [10000/60000]\n",
            "loss: 0.540464  [15000/60000]\n",
            "loss: 0.418424  [20000/60000]\n",
            "loss: 0.493007  [25000/60000]\n",
            "loss: 0.458805  [30000/60000]\n",
            "loss: 0.487711  [35000/60000]\n",
            "loss: 0.718815  [40000/60000]\n",
            "loss: 0.727019  [45000/60000]\n",
            "loss: 0.260461  [50000/60000]\n",
            "loss: 0.347300  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.379052 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.231754  [    0/60000]\n",
            "loss: 0.206717  [ 5000/60000]\n",
            "loss: 0.527661  [10000/60000]\n",
            "loss: 0.144553  [15000/60000]\n",
            "loss: 0.355348  [20000/60000]\n",
            "loss: 0.215309  [25000/60000]\n",
            "loss: 0.446819  [30000/60000]\n",
            "loss: 0.289299  [35000/60000]\n",
            "loss: 0.366851  [40000/60000]\n",
            "loss: 0.569152  [45000/60000]\n",
            "loss: 0.331852  [50000/60000]\n",
            "loss: 0.502848  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.325603 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.397421  [    0/60000]\n",
            "loss: 0.817417  [ 5000/60000]\n",
            "loss: 0.415079  [10000/60000]\n",
            "loss: 0.300743  [15000/60000]\n",
            "loss: 0.449523  [20000/60000]\n",
            "loss: 0.402321  [25000/60000]\n",
            "loss: 0.228460  [30000/60000]\n",
            "loss: 0.368602  [35000/60000]\n",
            "loss: 0.498477  [40000/60000]\n",
            "loss: 0.470896  [45000/60000]\n",
            "loss: 0.396849  [50000/60000]\n",
            "loss: 0.217780  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.290575 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.231069  [    0/60000]\n",
            "loss: 0.209292  [ 5000/60000]\n",
            "loss: 0.142475  [10000/60000]\n",
            "loss: 0.434358  [15000/60000]\n",
            "loss: 0.323125  [20000/60000]\n",
            "loss: 0.134379  [25000/60000]\n",
            "loss: 0.122915  [30000/60000]\n",
            "loss: 0.419387  [35000/60000]\n",
            "loss: 0.286906  [40000/60000]\n",
            "loss: 0.309831  [45000/60000]\n",
            "loss: 0.223200  [50000/60000]\n",
            "loss: 0.534931  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.268341 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.166836  [    0/60000]\n",
            "loss: 0.176852  [ 5000/60000]\n",
            "loss: 0.144218  [10000/60000]\n",
            "loss: 0.474868  [15000/60000]\n",
            "loss: 0.372339  [20000/60000]\n",
            "loss: 0.264003  [25000/60000]\n",
            "loss: 0.279514  [30000/60000]\n",
            "loss: 0.195807  [35000/60000]\n",
            "loss: 0.163330  [40000/60000]\n",
            "loss: 0.166342  [45000/60000]\n",
            "loss: 0.294663  [50000/60000]\n",
            "loss: 0.314269  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.247338 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.146408  [    0/60000]\n",
            "loss: 0.337825  [ 5000/60000]\n",
            "loss: 0.349682  [10000/60000]\n",
            "loss: 0.121855  [15000/60000]\n",
            "loss: 0.175591  [20000/60000]\n",
            "loss: 0.189480  [25000/60000]\n",
            "loss: 0.256069  [30000/60000]\n",
            "loss: 0.112788  [35000/60000]\n",
            "loss: 0.263774  [40000/60000]\n",
            "loss: 0.385808  [45000/60000]\n",
            "loss: 0.374621  [50000/60000]\n",
            "loss: 0.067811  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.228207 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.193619  [    0/60000]\n",
            "loss: 0.192392  [ 5000/60000]\n",
            "loss: 0.210621  [10000/60000]\n",
            "loss: 0.199462  [15000/60000]\n",
            "loss: 0.216928  [20000/60000]\n",
            "loss: 0.075769  [25000/60000]\n",
            "loss: 0.382743  [30000/60000]\n",
            "loss: 0.177414  [35000/60000]\n",
            "loss: 0.272751  [40000/60000]\n",
            "loss: 0.152709  [45000/60000]\n",
            "loss: 0.227580  [50000/60000]\n",
            "loss: 0.141286  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.216153 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.174365  [    0/60000]\n",
            "loss: 0.115877  [ 5000/60000]\n",
            "loss: 0.235360  [10000/60000]\n",
            "loss: 0.418983  [15000/60000]\n",
            "loss: 0.155752  [20000/60000]\n",
            "loss: 0.165274  [25000/60000]\n",
            "loss: 0.192057  [30000/60000]\n",
            "loss: 0.146993  [35000/60000]\n",
            "loss: 0.062826  [40000/60000]\n",
            "loss: 0.185073  [45000/60000]\n",
            "loss: 0.237027  [50000/60000]\n",
            "loss: 0.172355  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.202198 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.200374  [    0/60000]\n",
            "loss: 0.343640  [ 5000/60000]\n",
            "loss: 0.238023  [10000/60000]\n",
            "loss: 0.152180  [15000/60000]\n",
            "loss: 0.101173  [20000/60000]\n",
            "loss: 0.146200  [25000/60000]\n",
            "loss: 0.241748  [30000/60000]\n",
            "loss: 0.243919  [35000/60000]\n",
            "loss: 0.271174  [40000/60000]\n",
            "loss: 0.158366  [45000/60000]\n",
            "loss: 0.331651  [50000/60000]\n",
            "loss: 0.060561  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.186933 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.069833  [    0/60000]\n",
            "loss: 0.128148  [ 5000/60000]\n",
            "loss: 0.212145  [10000/60000]\n",
            "loss: 0.301800  [15000/60000]\n",
            "loss: 0.314154  [20000/60000]\n",
            "loss: 0.097005  [25000/60000]\n",
            "loss: 0.200322  [30000/60000]\n",
            "loss: 0.084566  [35000/60000]\n",
            "loss: 0.281198  [40000/60000]\n",
            "loss: 0.206982  [45000/60000]\n",
            "loss: 0.139536  [50000/60000]\n",
            "loss: 0.410594  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.175129 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.128539  [    0/60000]\n",
            "loss: 0.284900  [ 5000/60000]\n",
            "loss: 0.232463  [10000/60000]\n",
            "loss: 0.202034  [15000/60000]\n",
            "loss: 0.132655  [20000/60000]\n",
            "loss: 0.164942  [25000/60000]\n",
            "loss: 0.166178  [30000/60000]\n",
            "loss: 0.201310  [35000/60000]\n",
            "loss: 0.061838  [40000/60000]\n",
            "loss: 0.070752  [45000/60000]\n",
            "loss: 0.175106  [50000/60000]\n",
            "loss: 0.326809  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.170599 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.242636  [    0/60000]\n",
            "loss: 0.193779  [ 5000/60000]\n",
            "loss: 0.182204  [10000/60000]\n",
            "loss: 0.291115  [15000/60000]\n",
            "loss: 0.084110  [20000/60000]\n",
            "loss: 0.158246  [25000/60000]\n",
            "loss: 0.196053  [30000/60000]\n",
            "loss: 0.161281  [35000/60000]\n",
            "loss: 0.220749  [40000/60000]\n",
            "loss: 0.044427  [45000/60000]\n",
            "loss: 0.055854  [50000/60000]\n",
            "loss: 0.108694  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.159470 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.180813  [    0/60000]\n",
            "loss: 0.093113  [ 5000/60000]\n",
            "loss: 0.069461  [10000/60000]\n",
            "loss: 0.158350  [15000/60000]\n",
            "loss: 0.181215  [20000/60000]\n",
            "loss: 0.188121  [25000/60000]\n",
            "loss: 0.042434  [30000/60000]\n",
            "loss: 0.142224  [35000/60000]\n",
            "loss: 0.149930  [40000/60000]\n",
            "loss: 0.250611  [45000/60000]\n",
            "loss: 0.125277  [50000/60000]\n",
            "loss: 0.067279  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.153685 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.040710  [    0/60000]\n",
            "loss: 0.066520  [ 5000/60000]\n",
            "loss: 0.116356  [10000/60000]\n",
            "loss: 0.157983  [15000/60000]\n",
            "loss: 0.104933  [20000/60000]\n",
            "loss: 0.170678  [25000/60000]\n",
            "loss: 0.142149  [30000/60000]\n",
            "loss: 0.095762  [35000/60000]\n",
            "loss: 0.060550  [40000/60000]\n",
            "loss: 0.149567  [45000/60000]\n",
            "loss: 0.323188  [50000/60000]\n",
            "loss: 0.101972  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.146088 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.377620  [    0/60000]\n",
            "loss: 0.175122  [ 5000/60000]\n",
            "loss: 0.189889  [10000/60000]\n",
            "loss: 0.220280  [15000/60000]\n",
            "loss: 0.168499  [20000/60000]\n",
            "loss: 0.038379  [25000/60000]\n",
            "loss: 0.092690  [30000/60000]\n",
            "loss: 0.204993  [35000/60000]\n",
            "loss: 0.057140  [40000/60000]\n",
            "loss: 0.067772  [45000/60000]\n",
            "loss: 0.043313  [50000/60000]\n",
            "loss: 0.125369  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141999 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.130813  [    0/60000]\n",
            "loss: 0.071063  [ 5000/60000]\n",
            "loss: 0.116770  [10000/60000]\n",
            "loss: 0.115605  [15000/60000]\n",
            "loss: 0.111739  [20000/60000]\n",
            "loss: 0.066982  [25000/60000]\n",
            "loss: 0.050172  [30000/60000]\n",
            "loss: 0.160503  [35000/60000]\n",
            "loss: 0.248621  [40000/60000]\n",
            "loss: 0.096378  [45000/60000]\n",
            "loss: 0.047417  [50000/60000]\n",
            "loss: 0.241128  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.0%, Avg loss: 0.134861 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.472821  [    0/60000]\n",
            "loss: 0.048997  [ 5000/60000]\n",
            "loss: 0.253097  [10000/60000]\n",
            "loss: 0.251879  [15000/60000]\n",
            "loss: 0.068094  [20000/60000]\n",
            "loss: 0.077284  [25000/60000]\n",
            "loss: 0.273690  [30000/60000]\n",
            "loss: 0.110223  [35000/60000]\n",
            "loss: 0.247603  [40000/60000]\n",
            "loss: 0.080171  [45000/60000]\n",
            "loss: 0.080897  [50000/60000]\n",
            "loss: 0.166436  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.133197 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.150156  [    0/60000]\n",
            "loss: 0.047158  [ 5000/60000]\n",
            "loss: 0.114626  [10000/60000]\n",
            "loss: 0.010409  [15000/60000]\n",
            "loss: 0.160057  [20000/60000]\n",
            "loss: 0.084400  [25000/60000]\n",
            "loss: 0.072137  [30000/60000]\n",
            "loss: 0.051929  [35000/60000]\n",
            "loss: 0.076449  [40000/60000]\n",
            "loss: 0.162614  [45000/60000]\n",
            "loss: 0.056401  [50000/60000]\n",
            "loss: 0.210269  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.125935 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.048297  [    0/60000]\n",
            "loss: 0.063290  [ 5000/60000]\n",
            "loss: 0.247207  [10000/60000]\n",
            "loss: 0.114011  [15000/60000]\n",
            "loss: 0.103237  [20000/60000]\n",
            "loss: 0.087465  [25000/60000]\n",
            "loss: 0.081357  [30000/60000]\n",
            "loss: 0.047515  [35000/60000]\n",
            "loss: 0.124452  [40000/60000]\n",
            "loss: 0.115504  [45000/60000]\n",
            "loss: 0.446691  [50000/60000]\n",
            "loss: 0.123444  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.2%, Avg loss: 0.126504 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.048047  [    0/60000]\n",
            "loss: 0.140204  [ 5000/60000]\n",
            "loss: 0.066778  [10000/60000]\n",
            "loss: 0.039321  [15000/60000]\n",
            "loss: 0.098548  [20000/60000]\n",
            "loss: 0.085511  [25000/60000]\n",
            "loss: 0.175965  [30000/60000]\n",
            "loss: 0.271380  [35000/60000]\n",
            "loss: 0.042976  [40000/60000]\n",
            "loss: 0.139382  [45000/60000]\n",
            "loss: 0.138232  [50000/60000]\n",
            "loss: 0.070074  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.4%, Avg loss: 0.118221 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.101341  [    0/60000]\n",
            "loss: 0.048850  [ 5000/60000]\n",
            "loss: 0.159391  [10000/60000]\n",
            "loss: 0.083537  [15000/60000]\n",
            "loss: 0.064909  [20000/60000]\n",
            "loss: 0.037042  [25000/60000]\n",
            "loss: 0.088851  [30000/60000]\n",
            "loss: 0.118816  [35000/60000]\n",
            "loss: 0.111295  [40000/60000]\n",
            "loss: 0.117051  [45000/60000]\n",
            "loss: 0.041196  [50000/60000]\n",
            "loss: 0.184106  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.116523 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.025964  [    0/60000]\n",
            "loss: 0.059600  [ 5000/60000]\n",
            "loss: 0.079134  [10000/60000]\n",
            "loss: 0.049373  [15000/60000]\n",
            "loss: 0.076935  [20000/60000]\n",
            "loss: 0.013873  [25000/60000]\n",
            "loss: 0.236194  [30000/60000]\n",
            "loss: 0.063005  [35000/60000]\n",
            "loss: 0.060813  [40000/60000]\n",
            "loss: 0.158708  [45000/60000]\n",
            "loss: 0.061254  [50000/60000]\n",
            "loss: 0.039434  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.5%, Avg loss: 0.117255 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.159359  [    0/60000]\n",
            "loss: 0.128573  [ 5000/60000]\n",
            "loss: 0.084397  [10000/60000]\n",
            "loss: 0.092850  [15000/60000]\n",
            "loss: 0.316348  [20000/60000]\n",
            "loss: 0.076209  [25000/60000]\n",
            "loss: 0.083905  [30000/60000]\n",
            "loss: 0.090251  [35000/60000]\n",
            "loss: 0.144714  [40000/60000]\n",
            "loss: 0.042333  [45000/60000]\n",
            "loss: 0.090078  [50000/60000]\n",
            "loss: 0.039754  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.113419 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.120788  [    0/60000]\n",
            "loss: 0.083110  [ 5000/60000]\n",
            "loss: 0.176533  [10000/60000]\n",
            "loss: 0.097733  [15000/60000]\n",
            "loss: 0.063284  [20000/60000]\n",
            "loss: 0.071106  [25000/60000]\n",
            "loss: 0.029514  [30000/60000]\n",
            "loss: 0.010485  [35000/60000]\n",
            "loss: 0.093511  [40000/60000]\n",
            "loss: 0.104409  [45000/60000]\n",
            "loss: 0.054583  [50000/60000]\n",
            "loss: 0.167969  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.108150 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.231547  [    0/60000]\n",
            "loss: 0.156217  [ 5000/60000]\n",
            "loss: 0.045869  [10000/60000]\n",
            "loss: 0.034902  [15000/60000]\n",
            "loss: 0.025766  [20000/60000]\n",
            "loss: 0.184060  [25000/60000]\n",
            "loss: 0.103592  [30000/60000]\n",
            "loss: 0.163705  [35000/60000]\n",
            "loss: 0.099170  [40000/60000]\n",
            "loss: 0.050920  [45000/60000]\n",
            "loss: 0.087467  [50000/60000]\n",
            "loss: 0.157226  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.8%, Avg loss: 0.107326 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.050250  [    0/60000]\n",
            "loss: 0.136257  [ 5000/60000]\n",
            "loss: 0.107896  [ 9800/60000]\n",
            "loss: 0.233181  [15000/60000]\n",
            "loss: 0.049014  [20000/60000]\n",
            "loss: 0.087194  [25000/60000]\n",
            "loss: 0.041387  [30000/60000]\n",
            "loss: 0.213124  [35000/60000]\n",
            "loss: 0.039930  [40000/60000]\n",
            "loss: 0.010664  [45000/60000]\n",
            "loss: 0.243278  [50000/60000]\n",
            "loss: 0.159268  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.103886 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.034568  [    0/60000]\n",
            "loss: 0.227078  [ 5000/60000]\n",
            "loss: 0.040170  [10000/60000]\n",
            "loss: 0.060658  [15000/60000]\n",
            "loss: 0.015185  [20000/60000]\n",
            "loss: 0.031762  [25000/60000]\n",
            "loss: 0.156243  [30000/60000]\n",
            "loss: 0.067432  [35000/60000]\n",
            "loss: 0.172456  [40000/60000]\n",
            "loss: 0.012491  [45000/60000]\n",
            "loss: 0.067003  [50000/60000]\n",
            "loss: 0.073670  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.101064 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.139814  [    0/60000]\n",
            "loss: 0.020638  [ 5000/60000]\n",
            "loss: 0.038421  [10000/60000]\n",
            "loss: 0.118542  [15000/60000]\n",
            "loss: 0.066796  [20000/60000]\n",
            "loss: 0.141683  [25000/60000]\n",
            "loss: 0.052450  [30000/60000]\n",
            "loss: 0.033336  [35000/60000]\n",
            "loss: 0.160289  [40000/60000]\n",
            "loss: 0.097160  [45000/60000]\n",
            "loss: 0.044449  [50000/60000]\n",
            "loss: 0.030219  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.098827 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.048409  [    0/60000]\n",
            "loss: 0.055219  [ 5000/60000]\n",
            "loss: 0.069360  [10000/60000]\n",
            "loss: 0.032517  [15000/60000]\n",
            "loss: 0.024854  [20000/60000]\n",
            "loss: 0.082753  [25000/60000]\n",
            "loss: 0.067762  [30000/60000]\n",
            "loss: 0.158314  [35000/60000]\n",
            "loss: 0.043258  [40000/60000]\n",
            "loss: 0.089620  [45000/60000]\n",
            "loss: 0.058987  [50000/60000]\n",
            "loss: 0.102701  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099454 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applies a function to each element of a nested list\n",
        "def apply(item, fun):\n",
        "    if isinstance(item, list):\n",
        "        return [apply(x, fun) for x in item]\n",
        "    else:\n",
        "        return fun(item)\n",
        "\n",
        "# Return a 1D representation of all the weights in the model.\n",
        "def get_weights(model):\n",
        "    weights = []\n",
        "    for _, param in model.named_parameters():\n",
        "        weights.append(param.data.flatten())\n",
        "    return torch.concat(weights)\n",
        "\n",
        "model_weights = apply(models.copy(), get_weights)\n",
        "\n",
        "# Compute the d_1(U) values\n",
        "def get_d_values(model_weights):\n",
        "  d_values = []\n",
        "  for seed in range(1):\n",
        "      values_for_seed = []\n",
        "      for label in range(len(model_weights[seed][1])):\n",
        "          difference = model_weights[seed][0] - model_weights[seed][1][label]\n",
        "          print(\"L2 norm of w from regular model: \" + str(float(torch.norm(model_weights[seed][0], 2))))\n",
        "          print(\"L2 norm of w from model with element removed from class \" + str(label) + \": \" + str(float(torch.norm(model_weights[seed][1][label], 2))))\n",
        "          print(\"L2 norm of their difference: \" + str(float(torch.norm(difference, 2))) + \"\\n\")\n",
        "          values_for_seed.append(torch.norm(difference, 2))\n",
        "      d_values.append(values_for_seed)\n",
        "  return d_values\n",
        "\n",
        "d_values = get_d_values(model_weights)\n",
        "\n",
        "saved_model_params = apply(models.copy(), lambda x : x.state_dict())\n",
        "\n",
        "# Compute test error for w(S) models and w(S\\U) models for fixed epsilon/delta.\n",
        "def compute_all_losses(models, saved_model_params, epsilon, delta, d_values, loss_fn = loss_fn, test_dataloader = test_dataloader):\n",
        "    # Compute standard deviation of Gaussain noise to add to each model\n",
        "    c = np.sqrt(2 * np.log(1.25/delta))\n",
        "    sigma_divided_by_d = c / epsilon\n",
        "\n",
        "    with torch.no_grad():\n",
        "        accuracies = []\n",
        "        for seed in range(1):\n",
        "            print(\"Seed: \" + str(seed))\n",
        "            print(\"Regular test error (without removing an element or adding noise)\")\n",
        "            test(test_dataloader, models[seed][0], loss_fn)\n",
        "\n",
        "            for label in range(len(saved_model_params[seed][1])):\n",
        "                np.random.seed(0)\n",
        "                print(\"Seed: \" + str(seed))\n",
        "                print(\"Delete requests U is an element from class: \" + str(label))\n",
        "                model = NeuralNetwork()\n",
        "                model.to(device)\n",
        "                model.load_state_dict(saved_model_params[seed][1][label])\n",
        "                # Add noise to w(S \\ U)\n",
        "                for param in model.parameters():  \n",
        "                    sigma = sigma_divided_by_d * d_values[seed][label]\n",
        "                    a = np.array([])\n",
        "                    a = np.random.normal(0, 1)\n",
        "                    param.add_(torch.tensor(np.random.normal(0, sigma.cpu())))\n",
        "                accuracies.append(test(test_dataloader, model, loss_fn))\n",
        "    return accuracies\n",
        "epsilon, delta = 2, 0.1\n",
        "compute_all_losses(models, saved_model_params, epsilon, delta, d_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2-bY5UGkx9L",
        "outputId": "77e2c82a-f1af-44c0-85d3-bc3858dc8067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 0: 13.831628799438477\n",
            "L2 norm of their difference: 0.1488320380449295\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 1: 13.831262588500977\n",
            "L2 norm of their difference: 0.13814066350460052\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 2: 13.830979347229004\n",
            "L2 norm of their difference: 0.10284703969955444\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 3: 13.8303804397583\n",
            "L2 norm of their difference: 0.13243111968040466\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 4: 13.829930305480957\n",
            "L2 norm of their difference: 0.13068614900112152\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 5: 13.829459190368652\n",
            "L2 norm of their difference: 0.13599413633346558\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 6: 13.83106517791748\n",
            "L2 norm of their difference: 0.13257746398448944\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 7: 13.831303596496582\n",
            "L2 norm of their difference: 0.12939581274986267\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 8: 13.829545021057129\n",
            "L2 norm of their difference: 0.08991532027721405\n",
            "\n",
            "L2 norm of w from regular model: 13.830367088317871\n",
            "L2 norm of w from model with element removed from class 9: 13.830615043640137\n",
            "L2 norm of their difference: 0.09457052499055862\n",
            "\n",
            "Seed: 0\n",
            "Regular test error (without removing an element or adding noise)\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099635 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 0\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312194 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 1\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312193 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 2\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312196 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 3\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312188 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 4\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312191 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 5\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312194 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 6\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312189 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 7\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312197 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 8\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312202 \n",
            "\n",
            "Seed: 0\n",
            "Delete requests U is an element from class: 9\n",
            "Test Error: \n",
            " Accuracy: 8.9%, Avg loss: 2.312205 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0892,\n",
              " 0.0892,\n",
              " 0.0892,\n",
              " 0.0892,\n",
              " 0.0892,\n",
              " 0.0892,\n",
              " 0.0892,\n",
              " 0.0892,\n",
              " 0.0892,\n",
              " 0.0892]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models (code has been changed at each iteration)\n",
        "from google.colab import files\n",
        "\n",
        "torch.save(models[2].state_dict(), \"model_reg_seed_0.pt\")\n",
        "files.download(\"model_reg_seed_0.pt\")\n",
        "for i in range(num_classes_to_delete_point_from):\n",
        "  filename = \"model_removed_\" + str(i) + \"_seed_0.pt\"\n",
        "  torch.save(models[0][i].state_dict(), filename)\n",
        "  files.download(filename)"
      ],
      "metadata": {
        "id": "zeDyE0rY8yyg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1b2b7e2e-5eb2-4ab3-86f8-54dfcfc96cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d2785cf-c2f6-4931-8ab3-0218f35517e8\", \"model_removed_9_seed_1.pt\", 2680983)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute test error after adding noise to final model params\n",
        "epsilon_vals = np.linspace(1, 40, 40)\n",
        "#noise_accuracies = []\n",
        "\n",
        "#for epsilon in epsilon_vals:\n",
        "    #noise_accuracies.append(np.mean(compute_all_losses(models, saved_model_params, epsilon, delta, d_values)))\n",
        "\n",
        "graph = sns.lineplot(x = epsilon_vals, y = noise_accuracies)\n",
        "graph.axhline(test(test_dataloader, models[0][0], loss_fn))\n",
        "plt.title(\"Epsilon vs Average Accuracy (fixed delta = 0.1)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "77Lf2shV3sWI",
        "outputId": "74c192c6-e914-41d2-b54e-ee8e9926f415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099635 \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXzU9Z3H8ddnJifk4ApnEFBBQJTDKLq61nrVo6LdttajVrceuz7q1q7dQ6t12Xbbx17tbru19arV1lrF1oO2uK71rkoklggiqBCOEK4QSCCQa2a++8fvFxjGyUGYyW8yeT8fzIPfNb/5zHdm3vOb7++IOecQEZGBLxR0ASIikhoKdBGRLKFAFxHJEgp0EZEsoUAXEckSCnQRkSyhQD9MZna1mf1f3Lgzs2ODrEmyl5nNNLMqMzN//DgzqzazvWb2VTO718y+mYbH3WBm5/Zy2evM7I+9XPZhM/uXI6suc5jZJWb2RNB1dMrqQPfflC1m1hx3+9GRrNM590vn3PmpqrE/+B84Z2ZfCLqWVDGzIv/1fC7oWtLs28B/uoMnjPwD8LJzrtg590Pn3F87574dYH19ZmZnmdnmgB77HDNbY2b7zexlM5vUzbLfNrOVZhYxs4Xx85xzvwWON7MT011zb2R1oPsucc4Vxd1uCbqgAFwL7AK+lI6Vm1lOOtbbg88CbcB5Zja2Px+4v56vmY0DPgk8Ezd5ErCqPx4/W5nZKOAp4JvACKAK6G4rey3eF+nvu5j/K+CmVNbYV4Mh0JPyt1rfMLMfmVmT/219TsL8Gv+n7XozuzpuetKfl2ZWamY/N7N6M9toZneZWSj+fmb2n2a221/nhV2s5x/N7NcJ035gZj/srrYu1jUJ+ATeG+5TneFnZj8xs/9MWPZZM7vNHx5vZr/xn8t6M/tq3HILzezXZvaome0BrjOzU8zsLTNrNLOtfrvmxd3nfDP7wG/rH5vZq2Z2Q9z8L5vZar9tnu9ui8l3LXAvsAL4YsLzOMPM3vRrqTWz6/zphWb2Pf+1afJfj8JkW4rxXQ59fL7Hm9kLZrbLzLab2TfMbKy/RTgybrl5fhvnJnmO5wF/cs61+su+hBfwP/J/nUyzuC4M/31T2fmFY2Y3m9kqMysws5CZ3W5m68yswcwWmdmIuDqu8dulwczu7K7hzWykmS02sz1m9jZwTML86XHP/QMzuzzJOoYCzwHj7eCv5/E9tWuK/AWwyjn3pN+2C4HZZjY92cLOuUecc88Be7tY3yvAxSmusW+cc1l7AzYA53Yx7zogAvwtkAt8AWjC+8YeCuwBjvOXHQccH3e/P8atxwHH+sM/B54FioHJwIfA9XH36wBuBMLAzcAWwJLUNgnYDxT742FgK3Bqd7V18Ty/CbztD68Evu4PnwnUdj4+MBxoAcbjfdG/A9wN5AFHAzXAp/xlF/rP5TJ/2ULgJL++HP+5rwa+5i8/yq/5L/z5t/r3v8GffyneVtAMf/5dwJvdPKdJQAyYCXwdWJEwby9wpf+6jgTm+PPuwfvwTfDb9M+AfOAsYHNX750+PN9i//X6OlDgj8/35y0Bbo57nP8C/qeL5/kfwD0J017pbDd//GHgX/zhEPCaX+9UYDcw1593K7AUKPef833Ar/x5M4Fm/z2RD3wf77PR1WfncWAR3ntxFlCH/5nwp9UCf+m3zVxgJzAzSb3J2r3Ldu2ilsZubrd3cZ8fAD9JmPYe8Nke8uRRYGGS6SPwcqAk8MwLuoC0PjnvQ9mc8CLf6M+7joRABd4GrvHflI14P+sLE9Z5HUkCHS8g2jvfuP68vwJeibvf2rh5Q/z7ju2i9j8CX/KHzwPW+cNd1tbFej7iYNDcAbzrDxuwCTjTH78ReMkfng9sSljPHcDP/OGFwGs9PO7XgKf94S8Bb8XNM/9D3xnoz+F/8fnjIbwvtEldrPsuoNofngBEORhcd3Q+bsJ9QnhfWLOTzDuLngP9cJ7vlcDyLpb7AvCGPxwGtgGndLHsA8C/Jkx7hS4C3R+fjNe9thq4I276auCcuPFxeF9SOXhf3I/HzRuK917+WKD7NXcA0+OmfZeDgf4F4PWE+9wH/FNivcnavbt2TdUN+GmSdn0DuK6H+3UV6Ll4n+WjUllnX26DocvlMufcsLjbA3Hz6pz/ivg2AuOdc/vw3ph/DWw1s9939XMszii8F3ZjwvomxI1v6xxwzu33B4u6WN9jeMEAcJU/zuHUZmanA1Pwtqg613mCmc3xn/fjCY/xS394Et5P4cbOG/ANYEzc6msTHmuamf3OzLb53RLf9dsEvK3+A8v7jx3fxTEJ+EHcY+3CC/34tov3pc5anXN1wKt4XTAAE4F1Se4zCm9rOdm83jic59tVDeD9gptpZlPwvqibnHNvd7Hsbryt+15zzm0AXsYL9nviZk0Cno5r49V4X4Rj+Pjrsw9o6OIhyvC+BOLbI/49PwmYn/DeuRro1X6OHto1VZqBkoRpJXTdpdKTzteosc8VpchgCPTuTDDzDgfzHYW31Y5z7nnn3Hl4WzJr8LaWurMTb8slvu/3KLyfo33xJHCWmZUDn8EP9MOs7Vq8YKw2s21AZdx08HbmfM7vr54P/MafXgusT/giLHbOXRS37sTLdP7Er2Wqc64E7wugs2234v3UB8Bv8/K4+9YCf5XweIXOuTcTn5CZ/Rled8Id/od+m1/7VX7fcS0Jfbq+nUBrF/P24f1i6nyMMF5wxTuc51uL1031Mc7rs12E1+9/DfCLZMv5VgDTupn/MWZ2MXAa8CJel02nWuDChDYu8L8Qt+J9CXWuYwheV1Uy9XjdMRPjph2V8DivJjxOkXPu5iTrSnap1+7aNdnzbe7m9o0u7rYKmB23jqF474u+7myeAWxwzu3p4/1TZrAH+mjgq2aWa2afx3thlpjZGDO71H+h2/C+0WPdrcg5F8X7oH7HzIr9kLwN72faYXPO1eP9vP4ZXriuBuhtbWZWAFyOtzN0Ttztb/DDzzm3HC/oHgSed851bmG8Dez1d7IVmlnYzGaZ2cndlFyM10/e7P9iiP8A/x7vl8Flfuh+hUO32O7FC+jj/dpL/dcjmWuBF/D6fTuf0yy8fu0L8bbczzWzy80sx9+BN8c5FwMeAr7v73wLm9lpZpaPt6+jwMwu9ndO3oXXl9yd7p7v74BxZvY1M8v33w/z4+b/HK8LbgHdB/oLwDz/teyReUdvPAjcgNdOl5hZ55fwvXjvzUn+smVmdqk/79fAp83bmZwHfIsussF/nz8FLDSzIWY2k4MbCJ3PfZq/kzXXv51sZjOSrG47MNLMSuOmddeuyeop6ub23S7u9jQwy8w+67ft3Xj7YdYkW9h/DgV4bZJj3k7mcNwin8DrNgxe0H0+6bzh9YO24IVe562zn/M6vH6zH+HtDP0QON+fNw7vZ3wT3s+oVzi4U+c6ut4pOhwvwOvxtlTuBkLJ7pd43y7qv8Zf5u/jpnVZW8J9r8Db8spNmF6I93P60/74N/3H+HzCcuPxtuC34f30X8qhfcqPJix/Jt6WVTPwOl4oxLfTBX4bNwE/Bt4Crkl4rivxPsy1wENJnlOBX8slSeb9GPi1P/zneL9GOtd1bdxz/2+8X01NeDsQC+Nen63ADuDv+Hgf+uE+31l4W8m7/Ta8PeH+H+Ftyfb0Hn4S+ELc+Ct0vVP0KeDeuHkX4v3iHIkXRrcBH+B1LawDvhu37LV4+1QagDvp/oCCMrzg3oP35f/thOd+HN6XeL2/vpc4uGP6QL3++EP+Mo1477lu2zWF2XCu/zgtfptOjpt3b0I7Poz3GYm/XRc3fyVJ9s0Eces8wmHQMe9Qthucc2cEXctgY96hnJuBq51zLwddTxDMOwTxMefcgz0sNxN4BG/H6eD8sGYwM7sEb8PkY4dmBmGwd7lIPzGzT5nZML+Lo7NfdGnAZQXC77qaR/cnswDgnHvfOXeywjwzOed+mylhDgp06T+n4f3M3wlcgnf0UUuwJfU/M3sE+APeoaR9PapCJKlB2+UiIpJtetxCN7OHzGyHmb3XxXwzsx+a2VozW2Fm81JfpoiI9KQ3Fxl6GO9IkJ93Mf9CvOOCp+IdD/wT//9ujRo1yk2ePLlXRYqIiOedd97Z6ZxLPE8C6EWgO+deM7PJ3SxyKfBzf6fNUn/H1zjn3Nbu1jt58mSqqqp6engREYljZhu7mpeKnaITOPQ04M10ccq2md1k3sX6q+rr61Pw0CIi0qlfj3Jxzt3vnKtwzlWUlSX9xSAiIn2UikCv49DrOpTT9+uXiIhIH6Ui0BcDX/KPdjkV7+px3fafi4hI6vW4U9TMfoV33eJR5v1Vl3/Cu0wszrl78S7YfxHeHyjYj3dhexER6We9Ocrlyh7mO7yr54mISICC+OO+ANTU7+ML970V1MOLiGSdwAJdRCRdnHPedW4dxOKG46c7HP4/nH8164PzvIGD8w6dRuJ0XMJyyad3Ps7wIXkMzU99/AZ2LZeKigqnE4tEMlc05miLROmIONqiUdojMTqijvZIzLtFY3REY0Sijg5/uCPqiMS8+ZGYN/3AcCRGhz+tw5/WHo0R6VxHzBGJW0ckenB+h/8YneuMJIxHY85fR4xMvzyVGXz70ll88dRJPS+c9P72jnOuItk8baGLDEDtkRj72iLsa4/Q2hGlpT1GS0fUG+78v90bbumI0toeZX/8eIc/3h6lNRKjtT16yP3bOrzAToe8cIicsJETMvJyQuSEvPHccIickJETDpHrz88NhxiSl+ONh0Nx9/WXOWQ4RG7ICB9Y38F5idNyQkYoZAf+D5sRDhkh89YZ8sfDZoRCHJgXOrAc3njnMgYW93/n/UJx6w2Zt55D/+plainQRfpZNObY29pB4/4OGls6aPJve1o62NPaORxhT6s3rbkt4oV3W5R97d5wR/TwNkPNoDA3zJC8MAW54QPD+blhhhXmUlhSQEFuiMK8MPk5YQrzwhTkhMnPDZEbDpGXEyI/HCI3x8gLh8nL8YIyLxwiNyd0IHxz/TDODR8M6dxDgji9gTbYKdBFUmBfW4Tte1rZsbfNu3UO72mlYV87TS1+gO9vZ29bpNtugbxwiJLCXEoLcyguyKW4IIcxxQUMyQ9TlJ/DkLwcivLDDM3PYUhemMK8HAr9kC7MCx0I5MJcL7yH5IXJzwkpSAcBBbpID/a2drC1qZUtjS1sa2plS1MrWxtbvGlNLWxvamVfe/Rj98vLCTG6OJ+RRfmMGJrH0aOGMmxIHiWFuQwrzGXYkFxK4/4vKcilpDCXgtxwkipEeqZAl0HNOUf93jY2N7ZQt7uFLY0t1PnDdf7w3tbIIfcxg9HF+YwrLeS4McV8YloZY0oKGF2cz+jiAkaX5DOmuICSwhxtFUu/UqDLoNAeibGxYR/r6ptZV7+PdTuaDww3tx0a2CUFOYwfVkj58ELmTxnB+GGFjBtWyPjSAsaWFjCmpIDcsP56o2QeBbpknea2CKvqmlgZd9vYsJ9o7GDH9bjSAo4pK+Kz8yYwZdRQJo4YwoThhUwYVkhxQW6A1Yv0nQJdBrSOaIyVdU1Ub2o8EN7r6psP7HQcV1rArAmlXHzCOI4pK+KYsiKmlA2lKA0ndYgETe9qGVDaIlFWbG6isqaByvW7eGfjbvb7OyRHF+dzYnkpl5w4nhPKS5g1oZTRxQUBVyzSfxTokvFWbWnihfe3U1mziz9t2k1bxDvh5bgxxXzupHLmTxlJxeThjClReMvgpkCXjNS0v4Nn363jiWW1rNqyBzOYMbaEq+YfxfwpIzllyghGDM0LukyRjKJAl4wRizneXNfAoqpa/nfVNtojMWaOK+GfFxzPgtnjGa4AF+mWAl0Ct7O5jUeXbuTJqs3UNbZQWpjLlSdP5PMVE5k1oTTo8kQGDAW6BKahuY37X6vh529tpKUjyhnHjuIfL5zO+TPH6GxJkT5QoEu/27Wv3Q/yDbR2RFkwezx/c85UjikrCro0kQFNgS79pnF/Ow+8XsPDb2xgf0eUS04cz1fPmcqxoxXkIqmgQJe029cW4b5X1/HQGxvY1x7h4hPGces5U5k6pjjo0kSyigJd0ur/Vm1j4eJVbGlq5aITxnLrOdM4bqyCXCQdFOiSFpt372fh4vf5w+rtTB9bzP9cNZeTJo0IuiyRrKZAl5TqiMb42Rvr+a8XPgLgjgun8+UzpujqhCL9QIEuKfPOxt3c+fRK1mzby7kzRrNwwfGUDx8SdFkig4YCXY7YvrYI31mymscqNzGutID7rjmJTx0/NuiyRAYdBbockT9t2s3fPlHNpl37ueGMKfztedMYqkvTigRCnzzpk0g0xo9eXsv/vLSWsSUFPHHTaZwyRTs9RYKkQJfDtrFhH197oprlmxr5zNwJ/POlx1Oiv/IjEjgFuvSac44nqzaz8LeryAkZP7xyLgtmjw+6LBHxKdClV3bva+eOp1byv6u2cdrRI/ne5bMZP6ww6LJEJI4CXXq0eusern94GfXNbXzjounccMbRhEIWdFkikkCBLt36w/vb+erjyykpyOWpm0/nhHJdn1wkUynQJSnnHD/943q+s2Q1s8aX8uC1FfqbnSIZToEuH9MeiXH3s+/x+LJaLjphLN/7/BwK8/QHJ0QynQJdDtG4v52bH/0Tb9U0cMsnj+W286apv1xkgFCgywE19c1c/0gVdbtb+P7ls/mLeeVBlyQih6FXl8AzswvM7AMzW2tmtyeZf5SZvWxmy81shZldlPpSJZ0qaxr4zI/fpKmlg8dunK8wFxmAegx0MwsD9wAXAjOBK81sZsJidwGLnHNzgSuAH6e6UEmfqg27+MuHl1FWnM+zXzmdisk6hV9kIOrNFvopwFrnXI1zrh14HLg0YRkHlPjDpcCW1JUo6bRicyN/+bNljC0p4LEb5zNxhC53KzJQ9SbQJwC1ceOb/WnxFgJfNLPNwBLgb5KtyMxuMrMqM6uqr6/vQ7mSSqu37uGan77NsKG5/PLG+Ywu1mGJIgNZqv6MzJXAw865cuAi4Bdm9rF1O+fud85VOOcqysrKUvTQ0hdrdzRzzU8rKcwN89gNpzKuVKfxiwx0vQn0OmBi3Hi5Py3e9cAiAOfcW0ABMCoVBUrqbWzYx9UPLgXgl+pmEckavQn0ZcBUM5tiZnl4Oz0XJyyzCTgHwMxm4AW6+lQy0JbGFq56oJK2SIxHb5jPMWVFQZckIinSY6A75yLALcDzwGq8o1lWmdm3zGyBv9jXgRvN7F3gV8B1zjmXrqKlb3bsaeWqB5ayp6WDX3x5PtPHlvR8JxEZMHp1YpFzbgnezs74aXfHDb8PnJ7a0iSVdu9r5+oHK9mxt41fXH+KLrIlkoVStVNUMtydz6xkY8N+Hry2gpMm6ThzkWykQB8Enl+1jSUrt3HruVP5s2O0r1okWynQs9ye1g7ufvY9po8t5qYzjw66HBFJI12cK8v963NrqN/bxv3XVJAb1ve3SDbTJzyLLa1p4LHKTXz59CnMnjgs6HJEJM0U6FmqtSPKHU+tZOKIQm47f1rQ5YhIP1CXS5b64YsfsX7nPh69fj5D8vQyiwwG2kLPQqu2NHHfazV87qRyzpiqo1pEBgsFepaJRGPc/puVDB+Sx10Xzwi6HBHpR/otnmUeemM9K+uauOeqeQwbkhd0OSLSj7SFnkU2Nuzj+y98yLkzxnDRCWODLkdE+pkCPUs457jjqZXkhkL8y2WzMLOgSxKRfqZAzxKvf7STN9c18A8XHMfYUv3lIZHBSIGeJZ5eXkdJQQ6Xnzyx54VFJCsp0LPA/vYIz6/axsUnjiM/Jxx0OSISEAV6Fnjh/e3sb49y6ZzEv90tIoOJAj0LPLO8jvGlBZwyWdc5FxnMFOgDXENzG699tJMFcyYQCunIFpHBTIE+wP1uxVaiMcdlc8cHXYqIBEyBPsA9U13H9LHF+oPPIqJAH8g2Nuxj+aZGLpurnaEiokAf0J5ZvgUzWDBb3S0iokAfsJxzPFtdx/wpIxg/rDDockQkAyjQB6gVm5uo2bmPy3TsuYj4FOgD1DPVdeSFQ1x4wrigSxGRDKFAH4Ai0Ri/fXcrZ08fTWlhbtDliEiGUKAPQG+sa2Bnc5uOPReRQyjQB6Bn/SsrnnXc6KBLEZEMokAfYPa3R/jfVdu46IRxFOTqyooicpACfYDpvLKiTiYSkUQK9AHm2eoturKiiCSlQB9AGprbePXDei6ZM15XVhSRj1GgDyC/X+ldWfEz6m4RkSQU6API08t1ZUUR6ZoCfYBoaG5j+aZGPn2izgwVkeQU6ANEdW0jACdrZ6iIdKFXgW5mF5jZB2a21sxu72KZy83sfTNbZWaPpbZMqa5tJBwyTigvDboUEclQOT0tYGZh4B7gPGAzsMzMFjvn3o9bZipwB3C6c263mekUxhSrrm1k2phihuT1+JKJyCDVmy30U4C1zrka51w78DhwacIyNwL3OOd2AzjndqS2zMEtFnNU1zYyZ+KwoEsRkQzWm0CfANTGjW/2p8WbBkwzszfMbKmZXZBsRWZ2k5lVmVlVfX193yoehGp27mNva4S5CnQR6UaqdormAFOBs4ArgQfM7GPp45y73zlX4ZyrKCsrS9FDZ7/OHaJzjlKgi0jXehPodcDEuPFyf1q8zcBi51yHc2498CFewEsKVNfupig/h2PKioIuRUQyWG8CfRkw1cymmFkecAWwOGGZZ/C2zjGzUXhdMDUprHNQq65t5MTyUsI63V9EutFjoDvnIsAtwPPAamCRc26VmX3LzBb4iz0PNJjZ+8DLwN875xrSVfRg0toRZc3WvdohKiI96tUxcM65JcCShGl3xw074Db/Jin0Xl0TkZhToItIj3SmaIbTDlER6S0FeoZbXtvIhGGFjC4uCLoUEclwCvQMV71JJxSJSO8o0DNY/d426hpbFOgi0isK9Az2rvrPReQwKNAzWOcVFmeN1xUWRaRnCvQMVl3byPSxxRTmhYMuRUQGAAV6horFHO/qCosichgU6BmqZmcze9siCnQR6TUFeoZavsnbITpXO0RFpJcU6BmquraR4oIcjh6lKyyKSO8o0DNUdW0js8uHEdIVFkWklxToGailPcqabbrCoogcHgV6BnpvSxNRXWFRRA6TAj0DVW/SGaIicvgU6BmouraR8uGFjCrKD7oUERlAFOgZqFonFIlIHyjQM8yOva26wqKI9IkCPcNU64QiEekjBXqGqa5tJCdkHK8rLIrIYVKgZ5jq2kZmjCuhIFdXWBSRw6NAzyDRmGPF5ib1n4tInyjQM8i6+maadYVFEekjBXoG0QlFInIkFOgZZHltIyUFOUwZOTToUkRkAFKgZ5Dlm3Yze6KusCgifaNAzxBN+zv4YPteTp48IuhSRGSAUqBniLc37MI5mD9FgS4ifaNAzxBLaxrIywkxW0e4iEgfKdAzROX6BuYdNUwnFIlInynQM8Ce1g7e37KH+VNGBl2KiAxgCvQMULVhFzEH849W/7mI9J0CPQNU1uwiLxxi3lHDgy5FRAYwBXoGWFrTwJyJ6j8XkSOjQA9Yc1uE97bsUXeLiBwxBXrAqjbsIhpz2iEqIkesV4FuZheY2QdmttbMbu9muc+amTOzitSVmN0q1+8iJ2TMm6Tjz0XkyPQY6GYWBu4BLgRmAlea2cwkyxUDtwKVqS4ymy2taeDE8lKG5OUEXYqIDHC92UI/BVjrnKtxzrUDjwOXJlnu28C/Aa0prC+r7W+PsHJzE6cere4WETlyvQn0CUBt3Phmf9oBZjYPmOic+30Ka8t672zcTSTmmK9AF5EUOOKdomYWAr4PfL0Xy95kZlVmVlVfX3+kDz3gVdbsIhwyTpqk489F5Mj1JtDrgIlx4+X+tE7FwCzgFTPbAJwKLE62Y9Q5d79zrsI5V1FWVtb3qrNE5foGZk0opShf/ecicuR6E+jLgKlmNsXM8oArgMWdM51zTc65Uc65yc65ycBSYIFzriotFWeJlvYo1bWNnKrL5YpIivQY6M65CHAL8DywGljknFtlZt8yswXpLjBbLd+0m46o0w5REUmZXv3Wd84tAZYkTLu7i2XPOvKyst/S9bsIGVRMVv+5iKSGzhQNSGVNA8ePL6W4IDfoUkQkSyjQA9DaEWV5baP+3JyIpJQCPQDVtY20R2I6/lxEUkqBHoDKml2YwSmTtYUuIqmjQA9A5foGZowtoXSI+s9FJHUU6P2sLRLlT5t26/rnIpJyCvR+tmJzE60dMV3/XERSToHezyprGgB0hIuIpJwCvZ9Vrt/F9LHFDB+aF3QpIpJlFOj9qCMao2rDbm2di0haKND70YrNTbR0RHX8uYikhQK9H1Wu9/rPT9EWuoikgQK9H72xdifTxhQxqig/6FJEJAsp0PvJ3tYOKmt2cfb0MUGXIiJZSoHeT17/aCeRmOOcGaODLkVEspQCvZ/8YfV2hg3JZe7EYUGXIiJZSoHeD6Ixxysf1HPWtDJywmpyEUkPpUs/qK5tZNe+ds6eof5zEUkfBXo/eGnNdsIh4xNTy4IuRUSymAK9H7y4egcVk4brcrkiklYK9DSra2xhzba9OrpFRNJOgZ5mL63ZAcA56j8XkTRToKfZS6u3M3nkEI4eNTToUkQkyynQ02h/e4Q31jVw9vQxmFnQ5YhIllOgp9Gbaxtoj8TUfy4i/UKBnkYvrtlOUX4OJ0/W1RVFJP0U6GninOPF1Ts4c9oo8nLUzCKSfkqaNFm1ZQ879rbp6ooi0m8U6Gny4uodmMEnj9PZoSLSPxToafLSmu3MnTiMkfpjFiLSTxToabBjbyvvbm7SyUQi0q8U6Gnwypp6AM6ersMVRaT/KNDT4MU12xlfWsD0scVBlyIig4gCPcXaIlFe/2gnZ88YrbNDRaRfKdBTrLJmF/vbo5yjwxVFpJ8p0FPspTU7KMgNcdoxI4MuRUQGGQV6Cjnn+MPq7ZxxbBkFueGgyxGRQaZXgW5mF5jZB2a21sxuTzL/NjN738xWmNmLZjYp9aVmvo92NLN5d4suxiUigegx0M0sDNwDXAjMBK40s5kJiy0HKpxzJwK/Bv491YUOBM+t3AbAJ49ToItI/+vNFvopwFrnXI1zrh14HLg0fgHn3MvOuf3+6NDnlSUAAAd3SURBVFKgPLVlZr5ozLGoqpYzjh3F2NKCoMsRkUGoN4E+AaiNG9/sT+vK9cBzyWaY2U1mVmVmVfX19b2vcgB47cN66hpbuGr+UUGXIiKDVEp3iprZF4EK4D+SzXfO3e+cq3DOVZSVZddFqx57exOjivI4V6f7i0hAehPodcDEuPFyf9ohzOxc4E5ggXOuLTXlDQzbmlp5ac0OPl8xUdc+F5HA9CZ9lgFTzWyKmeUBVwCL4xcws7nAfXhhviP1ZWa2RVW1RGOOK06e2PPCIiJp0mOgO+ciwC3A88BqYJFzbpWZfcvMFviL/QdQBDxpZtVmtriL1WWdaMzx+Nub+POpo5g0cmjQ5YjIIJbTm4Wcc0uAJQnT7o4bPjfFdQ0Yr31Yz5amVu76dOKRnCIi/Usdvkfol5WbGFWUz3kztTNURIKlQD8C3s7Q7Xy+opzcsJpSRIKlFDoCTyyrJebQzlARyQgK9D6KxhxPLNPOUBHJHAr0Pnr1wx1saWrlylN0ZqiIZAYFeh89VlmrnaEiklEU6H2wtalFO0NFJOMojfpg0bLNxBxcebK6W0QkcyjQD1P8ztCjRg4JuhwRkQMU6Iepc2foVdoZKiIZRoF+mDp3hp6rnaEikmEU6Idh9dY9vLRmO5drZ6iIZCClUi+9/lE9l9/7FiOL8rnmtEH5N7BFJMMp0HvhV29v4rqfLWPC8EKe+crpjCstDLokEZGP6dXlcwerWMzx789/wL2vruPMaWXcc9Vcigtygy5LRCQpBXoXWjui3LaomiUrt3HV/KP41oLjyVG/uYhkMAV6Ejub27jhkSre3dzInRfN4IY/n4KZBV2WiEi3FOhxYjHHRzuauf6RZexsbuMnV5/EBbPGBl2WiEivDLhAX7Sslgder+nz/R3e2Z7tkRjt0Rgd0RjtEe//jqgDYFRRPk/cdBqzJw5LUdUiIuk34AJ92JBcpo4pOqJ1hEMh8sIh8nKMvHCI3HCIvBzv/8K8MAtmj2f8MB3JIiIDy4AL9POPH8v5x6sbREQkkQ7bEBHJEgp0EZEsoUAXEckSCnQRkSyhQBcRyRIKdBGRLKFAFxHJEgp0EZEsYc65YB7YrB7Y2MXsUcDOfizncGVyfaqtb1Rb36i2vjmS2iY558qSzQgs0LtjZlXOuYqg6+hKJten2vpGtfWNauubdNWmLhcRkSyhQBcRyRKZGuj3B11ADzK5PtXWN6qtb1Rb36SltozsQxcRkcOXqVvoIiJymBToIiJZIuMC3cwuMLMPzGytmd0edD3xzGyDma00s2ozqwq4lofMbIeZvRc3bYSZvWBmH/n/D8+g2haaWZ3fdtVmdlFAtU00s5fN7H0zW2Vmt/rTA2+7bmoLvO3MrMDM3jazd/3a/tmfPsXMKv3P6xNmlpdBtT1sZuvj2m1Of9cWV2PYzJab2e/88fS0m3MuY25AGFgHHA3kAe8CM4OuK66+DcCooOvwazkTmAe8Fzft34Hb/eHbgX/LoNoWAn+XAe02DpjnDxcDHwIzM6Htuqkt8LYDDCjyh3OBSuBUYBFwhT/9XuDmDKrtYeBzQb/n/LpuAx4DfuePp6XdMm0L/RRgrXOuxjnXDjwOXBpwTRnJOfcasCth8qXAI/7wI8Bl/VqUr4vaMoJzbqtz7k/+8F5gNTCBDGi7bmoLnPM0+6O5/s0BZwO/9qcH1W5d1ZYRzKwcuBh40B830tRumRboE4DauPHNZMgb2ueA/zOzd8zspqCLSWKMc26rP7wNGBNkMUncYmYr/C6ZQLqD4pnZZGAu3hZdRrVdQm2QAW3ndxtUAzuAF/B+TTc65yL+IoF9XhNrc851ttt3/Hb7LzPLD6I24L+BfwBi/vhI0tRumRbome4M59w84ELgK2Z2ZtAFdcV5v+UyZisF+AlwDDAH2Ap8L8hizKwI+A3wNefcnvh5Qbddktoyou2cc1Hn3BygHO/X9PQg6kgmsTYzmwXcgVfjycAI4B/7uy4z+zSwwzn3Tn88XqYFeh0wMW683J+WEZxzdf7/O4Cn8d7UmWS7mY0D8P/fEXA9BzjntvsfuhjwAAG2nZnl4gXmL51zT/mTM6LtktWWSW3n19MIvAycBgwzsxx/VuCf17jaLvC7sJxzrg34GcG02+nAAjPbgNeFfDbwA9LUbpkW6MuAqf4e4DzgCmBxwDUBYGZDzay4cxg4H3iv+3v1u8XAtf7wtcCzAdZyiM6w9H2GgNrO77/8KbDaOff9uFmBt11XtWVC25lZmZkN84cLgfPw+vhfBj7nLxZUuyWrbU3cF7Th9VH3e7s55+5wzpU75ybj5dlLzrmrSVe7Bb33N8ne4Ivw9u6vA+4Mup64uo7GO+rmXWBV0LUBv8L7+d2B1wd3PV7f3IvAR8AfgBEZVNsvgJXACrzwHBdQbWfgdaesAKr920WZ0Hbd1BZ42wEnAsv9Gt4D7vanHw28DawFngTyM6i2l/x2ew94FP9ImKBuwFkcPMolLe2mU/9FRLJEpnW5iIhIHynQRUSyhAJdRCRLKNBFRLKEAl1EJEso0EVEsoQCXUQkS/w/sOy3oAvdiocAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find noise parameter for epsilon provided\n",
        "def find_noise_parameter(eps, delta, training_data, batch_size, num_epochs, max_iters):\n",
        "  # F returns epsilon\n",
        "  def f(delta, training_data, batch_size, num_epochs, len_training_data, noise_multiplier):\n",
        "    return analysis.moments_accountant(\n",
        "        N=len(training_data),\n",
        "        batch_size=batch_size,\n",
        "        noise_multiplier=noise_multiplier,\n",
        "        epochs=num_epochs,\n",
        "        delta=delta,\n",
        "      )\n",
        "    \n",
        "  len_training_data = len(training_data)\n",
        "\n",
        "  return _binary_search(f, 0.1, 100, eps, max_iters, delta, training_data, batch_size, num_epochs, len_training_data)\n",
        "\n",
        "def _binary_search(f, left, right, goal, iterations, delta, training_data, batch_size, num_epochs, len_training_data):\n",
        "    \"\"\"Performs a search over a closed domain [left, right] for the value which get f close to goal(epsilon).\"\"\"\n",
        "    for i in range(iterations):\n",
        "        middle = (left + right) / 2\n",
        "        if f(delta, training_data, batch_size, num_epochs, len_training_data, middle) > goal:\n",
        "          left = middle\n",
        "        else:\n",
        "          right = middle\n",
        "    return (left + right) / 2\n",
        "\n",
        "# Check noise param is found correctly. \n",
        "print(analysis.moments_accountant(\n",
        "    N=len(training_data),\n",
        "    batch_size=batch_size,\n",
        "    noise_multiplier=0.3,\n",
        "    epochs=num_epochs,\n",
        "    delta=0.1,\n",
        "))\n",
        "find_noise_parameter(41.54867122425879, 0.1, training_data, batch_size, num_epochs, 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msWhOW_fyeYr",
        "outputId": "9a4f4967-73ca-4941-d65b-1922b230b1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41.54867122425879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3000000000425188"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute DPSGD accuracies\n",
        "dpsgd_accuracies = []\n",
        "epsilon_vals = np.linspace(0.5, 40, 5)\n",
        "clipping_norm = [1.5, 2]\n",
        "clip = 1\n",
        "for seed in range(0, 1):\n",
        "  for eps in epsilon_vals:\n",
        "    #for clip in clipping_norm:\n",
        "      random.seed(seed)\n",
        "      torch.manual_seed(seed)  \n",
        "      \n",
        "      train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "      \n",
        "      model = NeuralNetwork().to(device)\n",
        "\n",
        "      noise_multiplier = find_noise_parameter(eps, delta, training_data, batch_size, num_epochs, 40)\n",
        "\n",
        "      optimizer = optim.DPSGD(\n",
        "        l2_norm_clip=clip,\n",
        "        noise_multiplier=noise_multiplier,\n",
        "        batch_size=batch_size,\n",
        "        lr=lr,\n",
        "        params=model.parameters()\n",
        "      )\n",
        "\n",
        "      train_model(model, train_dataloader, optimizer, num_epochs = num_epochs)\n",
        "      dpsgd_accuracies.append(test(test_dataloader, model, loss_fn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5N12lwBzLfR",
        "outputId": "e700af05-9c66-4523-d9d0-6fb6c77b68f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.261297  [ 5000/60000]\n",
            "loss: 2.205240  [10000/60000]\n",
            "loss: 2.098958  [15000/60000]\n",
            "loss: 1.957374  [20000/60000]\n",
            "loss: 1.690460  [25000/60000]\n",
            "loss: 1.226929  [30000/60000]\n",
            "loss: 1.071274  [35000/60000]\n",
            "loss: 1.110380  [40000/60000]\n",
            "loss: 1.029479  [45000/60000]\n",
            "loss: 0.874680  [50000/60000]\n",
            "loss: 0.640179  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.0%, Avg loss: 0.624439 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.747608  [    0/60000]\n",
            "loss: 0.507642  [ 5000/60000]\n",
            "loss: 0.400233  [10000/60000]\n",
            "loss: 0.440886  [15000/60000]\n",
            "loss: 0.558853  [20000/60000]\n",
            "loss: 0.490766  [25000/60000]\n",
            "loss: 0.383551  [30000/60000]\n",
            "loss: 0.621183  [35000/60000]\n",
            "loss: 0.478698  [40000/60000]\n",
            "loss: 0.757202  [45000/60000]\n",
            "loss: 0.365681  [50000/60000]\n",
            "loss: 0.343689  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.417501 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.456128  [    0/60000]\n",
            "loss: 0.474985  [ 5000/60000]\n",
            "loss: 0.298861  [10000/60000]\n",
            "loss: 0.503360  [15000/60000]\n",
            "loss: 0.503003  [20000/60000]\n",
            "loss: 0.379199  [25000/60000]\n",
            "loss: 0.470998  [30000/60000]\n",
            "loss: 0.704548  [35000/60000]\n",
            "loss: 0.556704  [40000/60000]\n",
            "loss: 0.292066  [45000/60000]\n",
            "loss: 0.242222  [50000/60000]\n",
            "loss: 0.438946  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.375689 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.279165  [    0/60000]\n",
            "loss: 0.301355  [ 5000/60000]\n",
            "loss: 0.509821  [10000/60000]\n",
            "loss: 0.560029  [15000/60000]\n",
            "loss: 0.503662  [20000/60000]\n",
            "loss: 0.439104  [25000/60000]\n",
            "loss: 0.327981  [30000/60000]\n",
            "loss: 0.201250  [35000/60000]\n",
            "loss: 0.555031  [40000/60000]\n",
            "loss: 0.351824  [45000/60000]\n",
            "loss: 0.558428  [50000/60000]\n",
            "loss: 0.300900  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.355437 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.597733  [    0/60000]\n",
            "loss: 0.333354  [ 5000/60000]\n",
            "loss: 0.521251  [10000/60000]\n",
            "loss: 0.469250  [15000/60000]\n",
            "loss: 0.358842  [20000/60000]\n",
            "loss: 0.401278  [25000/60000]\n",
            "loss: 0.123899  [30000/60000]\n",
            "loss: 0.720802  [35000/60000]\n",
            "loss: 0.160283  [40000/60000]\n",
            "loss: 0.340677  [45000/60000]\n",
            "loss: 0.502640  [50000/60000]\n",
            "loss: 0.407537  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.9%, Avg loss: 0.343951 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.288159  [    0/60000]\n",
            "loss: 0.307661  [ 5000/60000]\n",
            "loss: 0.248660  [10000/60000]\n",
            "loss: 0.338124  [15000/60000]\n",
            "loss: 0.458741  [20000/60000]\n",
            "loss: 0.498172  [25000/60000]\n",
            "loss: 0.255495  [30000/60000]\n",
            "loss: 0.282256  [35000/60000]\n",
            "loss: 0.616242  [40000/60000]\n",
            "loss: 0.426496  [45000/60000]\n",
            "loss: 0.246867  [50000/60000]\n",
            "loss: 0.325197  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.337502 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.273720  [    0/60000]\n",
            "loss: 0.281644  [ 5000/60000]\n",
            "loss: 0.490838  [10000/60000]\n",
            "loss: 0.367292  [15000/60000]\n",
            "loss: 0.336248  [20000/60000]\n",
            "loss: 0.480458  [25000/60000]\n",
            "loss: 0.275326  [30000/60000]\n",
            "loss: 0.188668  [35000/60000]\n",
            "loss: 0.346018  [40000/60000]\n",
            "loss: 0.379264  [45000/60000]\n",
            "loss: 0.319122  [50000/60000]\n",
            "loss: 0.334263  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.327088 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.366893  [    0/60000]\n",
            "loss: 0.206887  [ 5000/60000]\n",
            "loss: 0.301218  [10000/60000]\n",
            "loss: 0.497250  [15000/60000]\n",
            "loss: 0.324719  [20000/60000]\n",
            "loss: 0.369591  [25000/60000]\n",
            "loss: 0.255986  [30000/60000]\n",
            "loss: 0.537558  [35000/60000]\n",
            "loss: 0.753601  [40000/60000]\n",
            "loss: 0.461679  [45000/60000]\n",
            "loss: 0.244372  [50000/60000]\n",
            "loss: 0.472735  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.317821 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.272061  [    0/60000]\n",
            "loss: 0.391320  [ 5000/60000]\n",
            "loss: 0.250199  [10000/60000]\n",
            "loss: 0.495668  [15000/60000]\n",
            "loss: 0.663738  [20000/60000]\n",
            "loss: 0.202122  [25000/60000]\n",
            "loss: 0.350010  [30000/60000]\n",
            "loss: 0.297942  [35000/60000]\n",
            "loss: 0.141559  [40000/60000]\n",
            "loss: 0.187062  [45000/60000]\n",
            "loss: 0.234668  [50000/60000]\n",
            "loss: 0.333260  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.317563 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.149790  [    0/60000]\n",
            "loss: 0.287192  [ 5000/60000]\n",
            "loss: 0.536688  [10000/60000]\n",
            "loss: 0.276793  [15000/60000]\n",
            "loss: 0.316211  [20000/60000]\n",
            "loss: 0.256430  [25000/60000]\n",
            "loss: 0.247795  [30000/60000]\n",
            "loss: 0.594992  [35000/60000]\n",
            "loss: 0.575564  [40000/60000]\n",
            "loss: 0.230669  [45000/60000]\n",
            "loss: 0.377742  [50000/60000]\n",
            "loss: 0.327695  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.313669 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.320078  [    0/60000]\n",
            "loss: 0.477203  [ 5000/60000]\n",
            "loss: 0.353094  [10000/60000]\n",
            "loss: 0.148604  [15000/60000]\n",
            "loss: 0.371685  [20000/60000]\n",
            "loss: 0.370680  [25000/60000]\n",
            "loss: 0.181723  [30000/60000]\n",
            "loss: 0.229871  [35000/60000]\n",
            "loss: 0.278438  [40000/60000]\n",
            "loss: 0.334351  [45000/60000]\n",
            "loss: 0.414346  [50000/60000]\n",
            "loss: 0.692047  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.311254 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.394400  [    0/60000]\n",
            "loss: 0.192615  [ 5000/60000]\n",
            "loss: 0.378753  [10000/60000]\n",
            "loss: 0.394704  [15000/60000]\n",
            "loss: 0.442780  [20000/60000]\n",
            "loss: 0.300015  [25000/60000]\n",
            "loss: 0.264553  [30000/60000]\n",
            "loss: 0.085945  [35000/60000]\n",
            "loss: 0.123443  [40000/60000]\n",
            "loss: 0.177168  [45000/60000]\n",
            "loss: 0.172698  [50000/60000]\n",
            "loss: 0.228973  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.301786 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.374343  [    0/60000]\n",
            "loss: 0.405376  [ 5000/60000]\n",
            "loss: 0.455311  [10000/60000]\n",
            "loss: 0.545817  [15000/60000]\n",
            "loss: 0.310802  [20000/60000]\n",
            "loss: 0.528082  [25000/60000]\n",
            "loss: 0.353463  [30000/60000]\n",
            "loss: 0.078454  [35000/60000]\n",
            "loss: 0.577300  [40000/60000]\n",
            "loss: 0.555253  [45000/60000]\n",
            "loss: 0.304885  [50000/60000]\n",
            "loss: 0.499642  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.298955 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.330697  [    0/60000]\n",
            "loss: 0.496278  [ 5000/60000]\n",
            "loss: 0.254124  [10000/60000]\n",
            "loss: 0.572935  [15000/60000]\n",
            "loss: 0.463389  [20000/60000]\n",
            "loss: 0.283992  [25000/60000]\n",
            "loss: 0.440138  [30000/60000]\n",
            "loss: 0.281382  [35000/60000]\n",
            "loss: 0.248431  [40000/60000]\n",
            "loss: 0.579060  [45000/60000]\n",
            "loss: 0.385747  [50000/60000]\n",
            "loss: 0.253786  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.9%, Avg loss: 0.300542 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.538167  [    0/60000]\n",
            "loss: 0.527250  [ 5000/60000]\n",
            "loss: 0.100887  [10000/60000]\n",
            "loss: 0.438531  [15000/60000]\n",
            "loss: 0.116106  [20000/60000]\n",
            "loss: 0.289573  [25000/60000]\n",
            "loss: 0.460557  [30000/60000]\n",
            "loss: 0.256907  [35000/60000]\n",
            "loss: 0.484710  [40000/60000]\n",
            "loss: 0.368445  [45000/60000]\n",
            "loss: 0.217206  [50000/60000]\n",
            "loss: 0.137972  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.295289 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.138553  [    0/60000]\n",
            "loss: 0.231814  [ 5000/60000]\n",
            "loss: 0.401224  [10000/60000]\n",
            "loss: 0.332563  [15000/60000]\n",
            "loss: 0.235210  [20000/60000]\n",
            "loss: 0.047645  [25000/60000]\n",
            "loss: 0.271684  [30000/60000]\n",
            "loss: 0.294216  [35000/60000]\n",
            "loss: 0.226677  [40000/60000]\n",
            "loss: 0.076995  [45000/60000]\n",
            "loss: 0.468744  [50000/60000]\n",
            "loss: 0.163239  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.3%, Avg loss: 0.297265 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.452197  [    0/60000]\n",
            "loss: 0.292779  [ 5000/60000]\n",
            "loss: 0.127909  [10000/60000]\n",
            "loss: 0.289439  [15000/60000]\n",
            "loss: 0.308169  [20000/60000]\n",
            "loss: 0.298604  [25000/60000]\n",
            "loss: 0.362884  [30000/60000]\n",
            "loss: 0.397030  [35000/60000]\n",
            "loss: 0.130324  [40000/60000]\n",
            "loss: 0.325675  [45000/60000]\n",
            "loss: 0.382516  [50000/60000]\n",
            "loss: 0.327110  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.286089 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.365602  [    0/60000]\n",
            "loss: 0.400499  [ 5000/60000]\n",
            "loss: 0.188299  [10000/60000]\n",
            "loss: 0.307153  [15000/60000]\n",
            "loss: 0.391426  [20000/60000]\n",
            "loss: 0.519456  [25000/60000]\n",
            "loss: 0.188286  [30000/60000]\n",
            "loss: 0.302090  [35000/60000]\n",
            "loss: 0.132497  [40000/60000]\n",
            "loss: 0.352282  [45000/60000]\n",
            "loss: 0.375565  [50000/60000]\n",
            "loss: 0.640109  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.286708 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.134765  [    0/60000]\n",
            "loss: 0.318034  [ 5000/60000]\n",
            "loss: 0.395385  [10000/60000]\n",
            "loss: 0.247863  [15000/60000]\n",
            "loss: 0.384955  [20000/60000]\n",
            "loss: 0.310434  [25000/60000]\n",
            "loss: 0.217821  [30000/60000]\n",
            "loss: 0.177197  [35000/60000]\n",
            "loss: 0.143384  [40000/60000]\n",
            "loss: 0.091049  [45000/60000]\n",
            "loss: 0.341162  [50000/60000]\n",
            "loss: 0.332142  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.299551 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.164941  [    0/60000]\n",
            "loss: 0.215054  [ 5000/60000]\n",
            "loss: 0.113036  [10000/60000]\n",
            "loss: 0.304503  [15000/60000]\n",
            "loss: 0.391633  [20000/60000]\n",
            "loss: 0.299380  [25000/60000]\n",
            "loss: 0.250672  [30000/60000]\n",
            "loss: 0.366973  [35000/60000]\n",
            "loss: 0.273018  [40000/60000]\n",
            "loss: 0.306605  [45000/60000]\n",
            "loss: 0.257459  [50000/60000]\n",
            "loss: 0.371422  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.3%, Avg loss: 0.303681 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.293158  [    0/60000]\n",
            "loss: 0.308227  [ 5000/60000]\n",
            "loss: 0.229521  [10000/60000]\n",
            "loss: 0.332273  [15000/60000]\n",
            "loss: 0.179916  [20000/60000]\n",
            "loss: 0.394145  [25000/60000]\n",
            "loss: 0.333533  [30000/60000]\n",
            "loss: 0.398387  [35000/60000]\n",
            "loss: 0.225070  [40000/60000]\n",
            "loss: 0.467198  [45000/60000]\n",
            "loss: 0.234540  [50000/60000]\n",
            "loss: 0.333596  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.305904 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.116463  [    0/60000]\n",
            "loss: 0.564631  [ 5000/60000]\n",
            "loss: 0.418147  [10000/60000]\n",
            "loss: 0.228279  [15000/60000]\n",
            "loss: 0.313925  [20000/60000]\n",
            "loss: 0.703143  [25000/60000]\n",
            "loss: 0.219655  [30000/60000]\n",
            "loss: 0.331182  [35000/60000]\n",
            "loss: 0.346723  [40000/60000]\n",
            "loss: 0.281544  [45000/60000]\n",
            "loss: 0.206044  [50000/60000]\n",
            "loss: 0.410152  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.303168 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.279427  [    0/60000]\n",
            "loss: 0.799033  [ 5000/60000]\n",
            "loss: 0.140112  [10000/60000]\n",
            "loss: 0.377651  [15000/60000]\n",
            "loss: 0.087047  [20000/60000]\n",
            "loss: 0.467171  [25000/60000]\n",
            "loss: 0.247935  [30000/60000]\n",
            "loss: 0.350177  [35000/60000]\n",
            "loss: 0.333354  [40000/60000]\n",
            "loss: 0.250093  [45000/60000]\n",
            "loss: 0.453002  [50000/60000]\n",
            "loss: 0.123412  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.296588 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.208397  [    0/60000]\n",
            "loss: 0.623108  [ 5000/60000]\n",
            "loss: 0.102962  [10000/60000]\n",
            "loss: 0.355414  [15000/60000]\n",
            "loss: 0.083015  [20000/60000]\n",
            "loss: 0.323296  [25000/60000]\n",
            "loss: 0.407546  [30000/60000]\n",
            "loss: 0.257561  [35000/60000]\n",
            "loss: 0.187916  [40000/60000]\n",
            "loss: 0.432929  [45000/60000]\n",
            "loss: 0.384604  [50000/60000]\n",
            "loss: 0.419463  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.4%, Avg loss: 0.304514 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.315888  [    0/60000]\n",
            "loss: 0.512923  [ 5000/60000]\n",
            "loss: 0.240180  [10000/60000]\n",
            "loss: 0.195318  [15000/60000]\n",
            "loss: 0.130526  [20000/60000]\n",
            "loss: 0.259860  [25000/60000]\n",
            "loss: 0.180761  [30000/60000]\n",
            "loss: 0.467925  [35000/60000]\n",
            "loss: 0.371268  [40000/60000]\n",
            "loss: 0.307770  [45000/60000]\n",
            "loss: 0.290302  [50000/60000]\n",
            "loss: 0.256918  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.299446 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.367424  [    0/60000]\n",
            "loss: 0.485234  [ 5000/60000]\n",
            "loss: 0.237613  [10000/60000]\n",
            "loss: 0.571488  [15000/60000]\n",
            "loss: 0.603498  [20000/60000]\n",
            "loss: 0.534006  [25000/60000]\n",
            "loss: 0.168018  [30000/60000]\n",
            "loss: 0.323038  [35000/60000]\n",
            "loss: 0.331200  [40000/60000]\n",
            "loss: 0.234864  [45000/60000]\n",
            "loss: 0.370257  [50000/60000]\n",
            "loss: 0.362953  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.298159 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.431236  [    0/60000]\n",
            "loss: 0.389710  [ 5000/60000]\n",
            "loss: 0.317076  [10000/60000]\n",
            "loss: 0.270518  [15000/60000]\n",
            "loss: 0.254190  [20000/60000]\n",
            "loss: 0.294460  [25000/60000]\n",
            "loss: 0.407885  [30000/60000]\n",
            "loss: 0.229135  [35000/60000]\n",
            "loss: 0.100561  [40000/60000]\n",
            "loss: 0.181599  [45000/60000]\n",
            "loss: 0.091197  [50000/60000]\n",
            "loss: 0.348413  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.299388 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.050737  [    0/60000]\n",
            "loss: 0.101151  [ 5000/60000]\n",
            "loss: 0.419434  [10000/60000]\n",
            "loss: 0.612539  [15000/60000]\n",
            "loss: 0.331397  [20000/60000]\n",
            "loss: 0.291373  [25000/60000]\n",
            "loss: 0.099709  [30000/60000]\n",
            "loss: 0.092912  [35000/60000]\n",
            "loss: 0.130204  [40000/60000]\n",
            "loss: 0.338493  [45000/60000]\n",
            "loss: 0.374623  [50000/60000]\n",
            "loss: 0.148362  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.297761 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.298797  [    0/60000]\n",
            "loss: 0.399468  [ 5000/60000]\n",
            "loss: 0.326993  [10000/60000]\n",
            "loss: 0.090945  [15000/60000]\n",
            "loss: 0.683600  [20000/60000]\n",
            "loss: 0.128080  [25000/60000]\n",
            "loss: 0.548172  [30000/60000]\n",
            "loss: 0.110771  [35000/60000]\n",
            "loss: 0.489253  [40000/60000]\n",
            "loss: 0.384025  [45000/60000]\n",
            "loss: 0.130329  [50000/60000]\n",
            "loss: 0.374291  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.288802 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.100661  [    0/60000]\n",
            "loss: 0.160000  [ 5000/60000]\n",
            "loss: 0.518512  [10000/60000]\n",
            "loss: 0.422355  [15000/60000]\n",
            "loss: 0.421601  [20000/60000]\n",
            "loss: 0.654549  [25000/60000]\n",
            "loss: 0.171878  [30000/60000]\n",
            "loss: 0.275572  [35000/60000]\n",
            "loss: 0.253067  [40000/60000]\n",
            "loss: 0.403936  [45000/60000]\n",
            "loss: 0.073432  [50000/60000]\n",
            "loss: 0.523354  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.293247 \n",
            "\n",
            "Done!\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.293247 \n",
            "\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.257608  [ 5000/60000]\n",
            "loss: 2.204182  [10000/60000]\n",
            "loss: 2.089482  [15000/60000]\n",
            "loss: 1.997404  [20000/60000]\n",
            "loss: 1.760290  [25000/60000]\n",
            "loss: 1.300291  [30000/60000]\n",
            "loss: 1.123070  [35000/60000]\n",
            "loss: 1.127450  [40000/60000]\n",
            "loss: 1.059216  [45000/60000]\n",
            "loss: 0.900261  [50000/60000]\n",
            "loss: 0.660019  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.627283 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.752831  [    0/60000]\n",
            "loss: 0.489590  [ 5000/60000]\n",
            "loss: 0.397710  [10000/60000]\n",
            "loss: 0.416372  [15000/60000]\n",
            "loss: 0.566312  [20000/60000]\n",
            "loss: 0.482719  [25000/60000]\n",
            "loss: 0.398009  [30000/60000]\n",
            "loss: 0.599163  [35000/60000]\n",
            "loss: 0.481301  [40000/60000]\n",
            "loss: 0.745770  [45000/60000]\n",
            "loss: 0.375470  [50000/60000]\n",
            "loss: 0.351530  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.405856 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.434327  [    0/60000]\n",
            "loss: 0.491775  [ 5000/60000]\n",
            "loss: 0.301192  [10000/60000]\n",
            "loss: 0.481656  [15000/60000]\n",
            "loss: 0.485865  [20000/60000]\n",
            "loss: 0.381202  [25000/60000]\n",
            "loss: 0.407852  [30000/60000]\n",
            "loss: 0.676483  [35000/60000]\n",
            "loss: 0.552774  [40000/60000]\n",
            "loss: 0.279271  [45000/60000]\n",
            "loss: 0.240997  [50000/60000]\n",
            "loss: 0.421117  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.352091 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.281286  [    0/60000]\n",
            "loss: 0.287904  [ 5000/60000]\n",
            "loss: 0.469589  [10000/60000]\n",
            "loss: 0.526769  [15000/60000]\n",
            "loss: 0.394482  [20000/60000]\n",
            "loss: 0.416844  [25000/60000]\n",
            "loss: 0.288473  [30000/60000]\n",
            "loss: 0.206721  [35000/60000]\n",
            "loss: 0.468868  [40000/60000]\n",
            "loss: 0.253009  [45000/60000]\n",
            "loss: 0.507049  [50000/60000]\n",
            "loss: 0.270251  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.326100 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.542906  [    0/60000]\n",
            "loss: 0.345662  [ 5000/60000]\n",
            "loss: 0.489493  [10000/60000]\n",
            "loss: 0.375683  [15000/60000]\n",
            "loss: 0.351777  [20000/60000]\n",
            "loss: 0.355547  [25000/60000]\n",
            "loss: 0.110508  [30000/60000]\n",
            "loss: 0.634980  [35000/60000]\n",
            "loss: 0.122459  [40000/60000]\n",
            "loss: 0.307223  [45000/60000]\n",
            "loss: 0.413888  [50000/60000]\n",
            "loss: 0.366153  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.302689 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.261834  [    0/60000]\n",
            "loss: 0.323121  [ 5000/60000]\n",
            "loss: 0.198819  [10000/60000]\n",
            "loss: 0.314321  [15000/60000]\n",
            "loss: 0.402705  [20000/60000]\n",
            "loss: 0.512590  [25000/60000]\n",
            "loss: 0.193618  [30000/60000]\n",
            "loss: 0.174684  [35000/60000]\n",
            "loss: 0.509758  [40000/60000]\n",
            "loss: 0.324686  [45000/60000]\n",
            "loss: 0.140601  [50000/60000]\n",
            "loss: 0.289665  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.291172 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.221059  [    0/60000]\n",
            "loss: 0.267778  [ 5000/60000]\n",
            "loss: 0.443325  [10000/60000]\n",
            "loss: 0.315307  [15000/60000]\n",
            "loss: 0.322930  [20000/60000]\n",
            "loss: 0.400178  [25000/60000]\n",
            "loss: 0.348225  [30000/60000]\n",
            "loss: 0.148612  [35000/60000]\n",
            "loss: 0.232433  [40000/60000]\n",
            "loss: 0.222095  [45000/60000]\n",
            "loss: 0.227379  [50000/60000]\n",
            "loss: 0.312218  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.276899 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.229922  [    0/60000]\n",
            "loss: 0.138095  [ 5000/60000]\n",
            "loss: 0.295091  [10000/60000]\n",
            "loss: 0.417073  [15000/60000]\n",
            "loss: 0.243627  [20000/60000]\n",
            "loss: 0.234374  [25000/60000]\n",
            "loss: 0.178104  [30000/60000]\n",
            "loss: 0.452911  [35000/60000]\n",
            "loss: 0.641424  [40000/60000]\n",
            "loss: 0.387967  [45000/60000]\n",
            "loss: 0.156481  [50000/60000]\n",
            "loss: 0.302135  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.258430 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.160690  [    0/60000]\n",
            "loss: 0.326050  [ 5000/60000]\n",
            "loss: 0.181636  [10000/60000]\n",
            "loss: 0.377738  [15000/60000]\n",
            "loss: 0.554583  [20000/60000]\n",
            "loss: 0.171368  [25000/60000]\n",
            "loss: 0.295802  [30000/60000]\n",
            "loss: 0.213269  [35000/60000]\n",
            "loss: 0.108706  [40000/60000]\n",
            "loss: 0.094454  [45000/60000]\n",
            "loss: 0.156740  [50000/60000]\n",
            "loss: 0.245581  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.246731 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.179549  [    0/60000]\n",
            "loss: 0.230128  [ 5000/60000]\n",
            "loss: 0.456626  [10000/60000]\n",
            "loss: 0.175558  [15000/60000]\n",
            "loss: 0.218677  [20000/60000]\n",
            "loss: 0.208010  [25000/60000]\n",
            "loss: 0.200332  [30000/60000]\n",
            "loss: 0.420687  [35000/60000]\n",
            "loss: 0.387791  [40000/60000]\n",
            "loss: 0.191146  [45000/60000]\n",
            "loss: 0.269813  [50000/60000]\n",
            "loss: 0.232675  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.238448 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.218706  [    0/60000]\n",
            "loss: 0.353627  [ 5000/60000]\n",
            "loss: 0.320725  [10000/60000]\n",
            "loss: 0.156188  [15000/60000]\n",
            "loss: 0.209596  [20000/60000]\n",
            "loss: 0.223520  [25000/60000]\n",
            "loss: 0.172117  [30000/60000]\n",
            "loss: 0.194542  [35000/60000]\n",
            "loss: 0.169470  [40000/60000]\n",
            "loss: 0.199684  [45000/60000]\n",
            "loss: 0.269298  [50000/60000]\n",
            "loss: 0.424220  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.4%, Avg loss: 0.226839 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.279242  [    0/60000]\n",
            "loss: 0.164157  [ 5000/60000]\n",
            "loss: 0.392527  [10000/60000]\n",
            "loss: 0.325444  [15000/60000]\n",
            "loss: 0.362355  [20000/60000]\n",
            "loss: 0.138581  [25000/60000]\n",
            "loss: 0.163174  [30000/60000]\n",
            "loss: 0.106936  [35000/60000]\n",
            "loss: 0.078708  [40000/60000]\n",
            "loss: 0.110980  [45000/60000]\n",
            "loss: 0.142348  [50000/60000]\n",
            "loss: 0.202712  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.217478 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.191013  [    0/60000]\n",
            "loss: 0.327535  [ 5000/60000]\n",
            "loss: 0.266747  [10000/60000]\n",
            "loss: 0.398589  [15000/60000]\n",
            "loss: 0.223066  [20000/60000]\n",
            "loss: 0.349191  [25000/60000]\n",
            "loss: 0.226878  [30000/60000]\n",
            "loss: 0.074884  [35000/60000]\n",
            "loss: 0.388791  [40000/60000]\n",
            "loss: 0.443976  [45000/60000]\n",
            "loss: 0.176845  [50000/60000]\n",
            "loss: 0.286885  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.214481 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.259416  [    0/60000]\n",
            "loss: 0.508275  [ 5000/60000]\n",
            "loss: 0.121321  [10000/60000]\n",
            "loss: 0.320385  [15000/60000]\n",
            "loss: 0.356790  [20000/60000]\n",
            "loss: 0.156618  [25000/60000]\n",
            "loss: 0.202083  [30000/60000]\n",
            "loss: 0.176451  [35000/60000]\n",
            "loss: 0.086111  [40000/60000]\n",
            "loss: 0.425057  [45000/60000]\n",
            "loss: 0.260247  [50000/60000]\n",
            "loss: 0.110113  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.201773 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.400742  [    0/60000]\n",
            "loss: 0.299829  [ 5000/60000]\n",
            "loss: 0.078934  [10000/60000]\n",
            "loss: 0.235232  [15000/60000]\n",
            "loss: 0.113327  [20000/60000]\n",
            "loss: 0.120521  [25000/60000]\n",
            "loss: 0.331564  [30000/60000]\n",
            "loss: 0.147473  [35000/60000]\n",
            "loss: 0.432736  [40000/60000]\n",
            "loss: 0.246099  [45000/60000]\n",
            "loss: 0.129559  [50000/60000]\n",
            "loss: 0.073722  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.197465 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.136568  [    0/60000]\n",
            "loss: 0.137630  [ 5000/60000]\n",
            "loss: 0.237859  [10000/60000]\n",
            "loss: 0.275639  [15000/60000]\n",
            "loss: 0.192042  [20000/60000]\n",
            "loss: 0.041388  [25000/60000]\n",
            "loss: 0.147937  [30000/60000]\n",
            "loss: 0.213708  [35000/60000]\n",
            "loss: 0.138202  [40000/60000]\n",
            "loss: 0.054461  [45000/60000]\n",
            "loss: 0.337761  [50000/60000]\n",
            "loss: 0.060660  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.5%, Avg loss: 0.190088 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.213006  [    0/60000]\n",
            "loss: 0.175007  [ 5000/60000]\n",
            "loss: 0.088524  [10000/60000]\n",
            "loss: 0.181538  [15000/60000]\n",
            "loss: 0.180604  [20000/60000]\n",
            "loss: 0.111784  [25000/60000]\n",
            "loss: 0.253658  [30000/60000]\n",
            "loss: 0.263161  [35000/60000]\n",
            "loss: 0.122639  [40000/60000]\n",
            "loss: 0.151456  [45000/60000]\n",
            "loss: 0.300600  [50000/60000]\n",
            "loss: 0.140448  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.5%, Avg loss: 0.186522 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.166385  [    0/60000]\n",
            "loss: 0.167771  [ 5000/60000]\n",
            "loss: 0.099074  [10000/60000]\n",
            "loss: 0.138602  [15000/60000]\n",
            "loss: 0.319327  [20000/60000]\n",
            "loss: 0.418664  [25000/60000]\n",
            "loss: 0.123415  [30000/60000]\n",
            "loss: 0.150533  [35000/60000]\n",
            "loss: 0.077597  [40000/60000]\n",
            "loss: 0.142393  [45000/60000]\n",
            "loss: 0.133337  [50000/60000]\n",
            "loss: 0.246853  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.178728 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.052921  [    0/60000]\n",
            "loss: 0.227741  [ 5000/60000]\n",
            "loss: 0.271876  [10000/60000]\n",
            "loss: 0.121199  [15000/60000]\n",
            "loss: 0.271926  [20000/60000]\n",
            "loss: 0.263287  [25000/60000]\n",
            "loss: 0.094497  [30000/60000]\n",
            "loss: 0.132420  [35000/60000]\n",
            "loss: 0.065728  [40000/60000]\n",
            "loss: 0.060886  [45000/60000]\n",
            "loss: 0.202111  [50000/60000]\n",
            "loss: 0.203976  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.176510 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.050249  [    0/60000]\n",
            "loss: 0.161956  [ 5000/60000]\n",
            "loss: 0.073920  [10000/60000]\n",
            "loss: 0.221634  [15000/60000]\n",
            "loss: 0.311066  [20000/60000]\n",
            "loss: 0.124134  [25000/60000]\n",
            "loss: 0.116567  [30000/60000]\n",
            "loss: 0.125071  [35000/60000]\n",
            "loss: 0.094292  [40000/60000]\n",
            "loss: 0.174537  [45000/60000]\n",
            "loss: 0.126654  [50000/60000]\n",
            "loss: 0.334459  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.172461 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.142715  [    0/60000]\n",
            "loss: 0.158669  [ 5000/60000]\n",
            "loss: 0.108817  [10000/60000]\n",
            "loss: 0.157524  [15000/60000]\n",
            "loss: 0.170545  [20000/60000]\n",
            "loss: 0.221922  [25000/60000]\n",
            "loss: 0.063162  [30000/60000]\n",
            "loss: 0.203441  [35000/60000]\n",
            "loss: 0.114962  [40000/60000]\n",
            "loss: 0.138550  [45000/60000]\n",
            "loss: 0.084994  [50000/60000]\n",
            "loss: 0.214614  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.173929 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.049435  [    0/60000]\n",
            "loss: 0.167708  [ 5000/60000]\n",
            "loss: 0.253372  [10000/60000]\n",
            "loss: 0.082498  [15000/60000]\n",
            "loss: 0.115408  [20000/60000]\n",
            "loss: 0.326729  [25000/60000]\n",
            "loss: 0.092556  [30000/60000]\n",
            "loss: 0.211041  [35000/60000]\n",
            "loss: 0.153561  [40000/60000]\n",
            "loss: 0.098502  [45000/60000]\n",
            "loss: 0.109436  [50000/60000]\n",
            "loss: 0.245093  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.166391 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.112809  [    0/60000]\n",
            "loss: 0.390729  [ 5000/60000]\n",
            "loss: 0.101489  [10000/60000]\n",
            "loss: 0.287021  [15000/60000]\n",
            "loss: 0.042712  [20000/60000]\n",
            "loss: 0.186281  [25000/60000]\n",
            "loss: 0.079208  [30000/60000]\n",
            "loss: 0.129156  [35000/60000]\n",
            "loss: 0.216209  [40000/60000]\n",
            "loss: 0.067560  [45000/60000]\n",
            "loss: 0.304873  [50000/60000]\n",
            "loss: 0.055050  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.165879 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.131032  [    0/60000]\n",
            "loss: 0.402704  [ 5000/60000]\n",
            "loss: 0.095675  [10000/60000]\n",
            "loss: 0.124931  [15000/60000]\n",
            "loss: 0.029610  [20000/60000]\n",
            "loss: 0.213539  [25000/60000]\n",
            "loss: 0.230792  [30000/60000]\n",
            "loss: 0.137813  [35000/60000]\n",
            "loss: 0.135010  [40000/60000]\n",
            "loss: 0.148183  [45000/60000]\n",
            "loss: 0.104448  [50000/60000]\n",
            "loss: 0.179408  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.162900 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.099509  [    0/60000]\n",
            "loss: 0.141155  [ 5000/60000]\n",
            "loss: 0.089882  [10000/60000]\n",
            "loss: 0.131904  [15000/60000]\n",
            "loss: 0.117802  [20000/60000]\n",
            "loss: 0.083072  [25000/60000]\n",
            "loss: 0.081323  [30000/60000]\n",
            "loss: 0.321740  [35000/60000]\n",
            "loss: 0.192377  [40000/60000]\n",
            "loss: 0.248499  [45000/60000]\n",
            "loss: 0.116784  [50000/60000]\n",
            "loss: 0.098892  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.160686 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.276690  [    0/60000]\n",
            "loss: 0.165189  [ 5000/60000]\n",
            "loss: 0.145593  [10000/60000]\n",
            "loss: 0.234816  [15000/60000]\n",
            "loss: 0.284488  [20000/60000]\n",
            "loss: 0.399761  [25000/60000]\n",
            "loss: 0.070092  [30000/60000]\n",
            "loss: 0.159236  [35000/60000]\n",
            "loss: 0.158256  [40000/60000]\n",
            "loss: 0.109674  [45000/60000]\n",
            "loss: 0.204216  [50000/60000]\n",
            "loss: 0.223564  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.161788 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.253910  [    0/60000]\n",
            "loss: 0.210722  [ 5000/60000]\n",
            "loss: 0.142281  [10000/60000]\n",
            "loss: 0.108880  [15000/60000]\n",
            "loss: 0.319858  [20000/60000]\n",
            "loss: 0.126546  [25000/60000]\n",
            "loss: 0.119911  [30000/60000]\n",
            "loss: 0.116044  [35000/60000]\n",
            "loss: 0.093120  [40000/60000]\n",
            "loss: 0.103623  [45000/60000]\n",
            "loss: 0.076300  [50000/60000]\n",
            "loss: 0.103632  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.156926 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.020333  [    0/60000]\n",
            "loss: 0.093104  [ 5000/60000]\n",
            "loss: 0.211931  [10000/60000]\n",
            "loss: 0.344560  [15000/60000]\n",
            "loss: 0.094203  [20000/60000]\n",
            "loss: 0.184184  [25000/60000]\n",
            "loss: 0.048295  [30000/60000]\n",
            "loss: 0.057055  [35000/60000]\n",
            "loss: 0.067224  [40000/60000]\n",
            "loss: 0.123649  [45000/60000]\n",
            "loss: 0.168416  [50000/60000]\n",
            "loss: 0.037033  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.154860 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.095773  [    0/60000]\n",
            "loss: 0.222423  [ 5000/60000]\n",
            "loss: 0.076254  [10000/60000]\n",
            "loss: 0.066893  [15000/60000]\n",
            "loss: 0.361353  [20000/60000]\n",
            "loss: 0.064918  [25000/60000]\n",
            "loss: 0.240849  [30000/60000]\n",
            "loss: 0.038266  [35000/60000]\n",
            "loss: 0.169640  [40000/60000]\n",
            "loss: 0.120139  [45000/60000]\n",
            "loss: 0.047111  [50000/60000]\n",
            "loss: 0.077875  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.150284 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.052871  [    0/60000]\n",
            "loss: 0.065984  [ 5000/60000]\n",
            "loss: 0.134579  [10000/60000]\n",
            "loss: 0.122030  [15000/60000]\n",
            "loss: 0.156720  [20000/60000]\n",
            "loss: 0.255230  [25000/60000]\n",
            "loss: 0.072505  [30000/60000]\n",
            "loss: 0.080475  [35000/60000]\n",
            "loss: 0.114527  [40000/60000]\n",
            "loss: 0.234798  [45000/60000]\n",
            "loss: 0.098592  [50000/60000]\n",
            "loss: 0.250881  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.148189 \n",
            "\n",
            "Done!\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.148189 \n",
            "\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.257365  [ 5000/60000]\n",
            "loss: 2.203799  [10000/60000]\n",
            "loss: 2.087548  [15000/60000]\n",
            "loss: 1.997670  [20000/60000]\n",
            "loss: 1.761027  [25000/60000]\n",
            "loss: 1.303654  [30000/60000]\n",
            "loss: 1.126403  [35000/60000]\n",
            "loss: 1.128164  [40000/60000]\n",
            "loss: 1.060566  [45000/60000]\n",
            "loss: 0.901090  [50000/60000]\n",
            "loss: 0.662277  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.627958 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.756158  [    0/60000]\n",
            "loss: 0.488189  [ 5000/60000]\n",
            "loss: 0.396551  [10000/60000]\n",
            "loss: 0.417582  [15000/60000]\n",
            "loss: 0.567155  [20000/60000]\n",
            "loss: 0.483293  [25000/60000]\n",
            "loss: 0.399667  [30000/60000]\n",
            "loss: 0.598347  [35000/60000]\n",
            "loss: 0.483149  [40000/60000]\n",
            "loss: 0.744778  [45000/60000]\n",
            "loss: 0.376454  [50000/60000]\n",
            "loss: 0.350220  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.405352 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.433119  [    0/60000]\n",
            "loss: 0.490875  [ 5000/60000]\n",
            "loss: 0.300769  [10000/60000]\n",
            "loss: 0.482390  [15000/60000]\n",
            "loss: 0.486202  [20000/60000]\n",
            "loss: 0.381811  [25000/60000]\n",
            "loss: 0.405986  [30000/60000]\n",
            "loss: 0.674174  [35000/60000]\n",
            "loss: 0.553636  [40000/60000]\n",
            "loss: 0.276725  [45000/60000]\n",
            "loss: 0.243230  [50000/60000]\n",
            "loss: 0.420989  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.7%, Avg loss: 0.350835 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.279866  [    0/60000]\n",
            "loss: 0.285193  [ 5000/60000]\n",
            "loss: 0.467077  [10000/60000]\n",
            "loss: 0.521416  [15000/60000]\n",
            "loss: 0.391710  [20000/60000]\n",
            "loss: 0.412591  [25000/60000]\n",
            "loss: 0.286693  [30000/60000]\n",
            "loss: 0.208654  [35000/60000]\n",
            "loss: 0.463535  [40000/60000]\n",
            "loss: 0.246503  [45000/60000]\n",
            "loss: 0.505911  [50000/60000]\n",
            "loss: 0.273141  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.4%, Avg loss: 0.324511 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.539682  [    0/60000]\n",
            "loss: 0.341804  [ 5000/60000]\n",
            "loss: 0.485818  [10000/60000]\n",
            "loss: 0.367022  [15000/60000]\n",
            "loss: 0.352144  [20000/60000]\n",
            "loss: 0.354132  [25000/60000]\n",
            "loss: 0.109595  [30000/60000]\n",
            "loss: 0.629866  [35000/60000]\n",
            "loss: 0.120591  [40000/60000]\n",
            "loss: 0.303575  [45000/60000]\n",
            "loss: 0.409972  [50000/60000]\n",
            "loss: 0.365554  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.300654 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.261288  [    0/60000]\n",
            "loss: 0.323157  [ 5000/60000]\n",
            "loss: 0.195841  [10000/60000]\n",
            "loss: 0.317068  [15000/60000]\n",
            "loss: 0.397679  [20000/60000]\n",
            "loss: 0.514802  [25000/60000]\n",
            "loss: 0.189886  [30000/60000]\n",
            "loss: 0.171579  [35000/60000]\n",
            "loss: 0.503656  [40000/60000]\n",
            "loss: 0.321835  [45000/60000]\n",
            "loss: 0.134144  [50000/60000]\n",
            "loss: 0.290554  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.6%, Avg loss: 0.288829 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.217750  [    0/60000]\n",
            "loss: 0.267276  [ 5000/60000]\n",
            "loss: 0.445106  [10000/60000]\n",
            "loss: 0.311053  [15000/60000]\n",
            "loss: 0.321328  [20000/60000]\n",
            "loss: 0.390018  [25000/60000]\n",
            "loss: 0.349839  [30000/60000]\n",
            "loss: 0.147537  [35000/60000]\n",
            "loss: 0.227082  [40000/60000]\n",
            "loss: 0.217047  [45000/60000]\n",
            "loss: 0.222478  [50000/60000]\n",
            "loss: 0.309237  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.274548 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.228285  [    0/60000]\n",
            "loss: 0.136973  [ 5000/60000]\n",
            "loss: 0.296876  [10000/60000]\n",
            "loss: 0.409817  [15000/60000]\n",
            "loss: 0.243617  [20000/60000]\n",
            "loss: 0.229116  [25000/60000]\n",
            "loss: 0.173427  [30000/60000]\n",
            "loss: 0.453551  [35000/60000]\n",
            "loss: 0.642800  [40000/60000]\n",
            "loss: 0.389839  [45000/60000]\n",
            "loss: 0.150519  [50000/60000]\n",
            "loss: 0.290532  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.256550 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.158080  [    0/60000]\n",
            "loss: 0.322560  [ 5000/60000]\n",
            "loss: 0.177873  [10000/60000]\n",
            "loss: 0.368469  [15000/60000]\n",
            "loss: 0.553712  [20000/60000]\n",
            "loss: 0.168604  [25000/60000]\n",
            "loss: 0.294915  [30000/60000]\n",
            "loss: 0.211750  [35000/60000]\n",
            "loss: 0.107667  [40000/60000]\n",
            "loss: 0.090677  [45000/60000]\n",
            "loss: 0.157100  [50000/60000]\n",
            "loss: 0.236914  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.244649 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.186695  [    0/60000]\n",
            "loss: 0.225758  [ 5000/60000]\n",
            "loss: 0.441987  [10000/60000]\n",
            "loss: 0.171916  [15000/60000]\n",
            "loss: 0.217169  [20000/60000]\n",
            "loss: 0.199161  [25000/60000]\n",
            "loss: 0.199021  [30000/60000]\n",
            "loss: 0.403647  [35000/60000]\n",
            "loss: 0.381692  [40000/60000]\n",
            "loss: 0.187083  [45000/60000]\n",
            "loss: 0.267315  [50000/60000]\n",
            "loss: 0.224236  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.235955 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.215059  [    0/60000]\n",
            "loss: 0.358203  [ 5000/60000]\n",
            "loss: 0.326340  [10000/60000]\n",
            "loss: 0.156708  [15000/60000]\n",
            "loss: 0.210938  [20000/60000]\n",
            "loss: 0.219489  [25000/60000]\n",
            "loss: 0.167947  [30000/60000]\n",
            "loss: 0.196645  [35000/60000]\n",
            "loss: 0.169228  [40000/60000]\n",
            "loss: 0.192009  [45000/60000]\n",
            "loss: 0.264616  [50000/60000]\n",
            "loss: 0.419625  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.224632 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.268680  [    0/60000]\n",
            "loss: 0.159304  [ 5000/60000]\n",
            "loss: 0.389355  [10000/60000]\n",
            "loss: 0.329826  [15000/60000]\n",
            "loss: 0.358720  [20000/60000]\n",
            "loss: 0.135116  [25000/60000]\n",
            "loss: 0.154507  [30000/60000]\n",
            "loss: 0.106633  [35000/60000]\n",
            "loss: 0.078245  [40000/60000]\n",
            "loss: 0.108987  [45000/60000]\n",
            "loss: 0.141301  [50000/60000]\n",
            "loss: 0.203715  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.214557 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.189435  [    0/60000]\n",
            "loss: 0.321534  [ 5000/60000]\n",
            "loss: 0.265955  [10000/60000]\n",
            "loss: 0.398255  [15000/60000]\n",
            "loss: 0.217231  [20000/60000]\n",
            "loss: 0.327413  [25000/60000]\n",
            "loss: 0.227669  [30000/60000]\n",
            "loss: 0.075241  [35000/60000]\n",
            "loss: 0.369739  [40000/60000]\n",
            "loss: 0.444931  [45000/60000]\n",
            "loss: 0.171606  [50000/60000]\n",
            "loss: 0.271229  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.210381 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.246158  [    0/60000]\n",
            "loss: 0.513112  [ 5000/60000]\n",
            "loss: 0.114661  [10000/60000]\n",
            "loss: 0.318127  [15000/60000]\n",
            "loss: 0.359452  [20000/60000]\n",
            "loss: 0.148585  [25000/60000]\n",
            "loss: 0.194650  [30000/60000]\n",
            "loss: 0.172762  [35000/60000]\n",
            "loss: 0.080682  [40000/60000]\n",
            "loss: 0.410837  [45000/60000]\n",
            "loss: 0.258889  [50000/60000]\n",
            "loss: 0.111773  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.198198 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.381853  [    0/60000]\n",
            "loss: 0.281565  [ 5000/60000]\n",
            "loss: 0.081016  [10000/60000]\n",
            "loss: 0.235100  [15000/60000]\n",
            "loss: 0.102763  [20000/60000]\n",
            "loss: 0.118795  [25000/60000]\n",
            "loss: 0.322948  [30000/60000]\n",
            "loss: 0.147224  [35000/60000]\n",
            "loss: 0.441898  [40000/60000]\n",
            "loss: 0.241185  [45000/60000]\n",
            "loss: 0.131290  [50000/60000]\n",
            "loss: 0.074518  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.194616 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.133971  [    0/60000]\n",
            "loss: 0.139044  [ 5000/60000]\n",
            "loss: 0.235526  [10000/60000]\n",
            "loss: 0.280759  [15000/60000]\n",
            "loss: 0.184036  [20000/60000]\n",
            "loss: 0.044101  [25000/60000]\n",
            "loss: 0.136269  [30000/60000]\n",
            "loss: 0.216922  [35000/60000]\n",
            "loss: 0.134348  [40000/60000]\n",
            "loss: 0.059504  [45000/60000]\n",
            "loss: 0.344444  [50000/60000]\n",
            "loss: 0.059641  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.187442 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.201266  [    0/60000]\n",
            "loss: 0.170573  [ 5000/60000]\n",
            "loss: 0.090186  [10000/60000]\n",
            "loss: 0.182266  [15000/60000]\n",
            "loss: 0.174876  [20000/60000]\n",
            "loss: 0.104925  [25000/60000]\n",
            "loss: 0.262964  [30000/60000]\n",
            "loss: 0.260984  [35000/60000]\n",
            "loss: 0.127478  [40000/60000]\n",
            "loss: 0.137482  [45000/60000]\n",
            "loss: 0.300441  [50000/60000]\n",
            "loss: 0.131501  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.182735 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.147795  [    0/60000]\n",
            "loss: 0.164844  [ 5000/60000]\n",
            "loss: 0.098601  [10000/60000]\n",
            "loss: 0.136307  [15000/60000]\n",
            "loss: 0.314117  [20000/60000]\n",
            "loss: 0.415166  [25000/60000]\n",
            "loss: 0.130029  [30000/60000]\n",
            "loss: 0.145355  [35000/60000]\n",
            "loss: 0.073794  [40000/60000]\n",
            "loss: 0.135278  [45000/60000]\n",
            "loss: 0.131615  [50000/60000]\n",
            "loss: 0.241589  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.175198 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.051791  [    0/60000]\n",
            "loss: 0.220455  [ 5000/60000]\n",
            "loss: 0.264442  [10000/60000]\n",
            "loss: 0.120532  [15000/60000]\n",
            "loss: 0.279127  [20000/60000]\n",
            "loss: 0.261155  [25000/60000]\n",
            "loss: 0.091060  [30000/60000]\n",
            "loss: 0.130629  [35000/60000]\n",
            "loss: 0.062563  [40000/60000]\n",
            "loss: 0.055041  [45000/60000]\n",
            "loss: 0.196895  [50000/60000]\n",
            "loss: 0.194210  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.172558 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.049300  [    0/60000]\n",
            "loss: 0.162788  [ 5000/60000]\n",
            "loss: 0.080888  [10000/60000]\n",
            "loss: 0.215655  [15000/60000]\n",
            "loss: 0.297708  [20000/60000]\n",
            "loss: 0.119786  [25000/60000]\n",
            "loss: 0.111462  [30000/60000]\n",
            "loss: 0.122583  [35000/60000]\n",
            "loss: 0.083034  [40000/60000]\n",
            "loss: 0.167709  [45000/60000]\n",
            "loss: 0.129082  [50000/60000]\n",
            "loss: 0.328098  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.167702 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.135523  [    0/60000]\n",
            "loss: 0.149988  [ 5000/60000]\n",
            "loss: 0.102090  [10000/60000]\n",
            "loss: 0.150978  [15000/60000]\n",
            "loss: 0.166335  [20000/60000]\n",
            "loss: 0.208139  [25000/60000]\n",
            "loss: 0.059601  [30000/60000]\n",
            "loss: 0.190863  [35000/60000]\n",
            "loss: 0.107713  [40000/60000]\n",
            "loss: 0.123398  [45000/60000]\n",
            "loss: 0.067066  [50000/60000]\n",
            "loss: 0.188038  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.168753 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.051652  [    0/60000]\n",
            "loss: 0.154188  [ 5000/60000]\n",
            "loss: 0.250279  [10000/60000]\n",
            "loss: 0.073170  [15000/60000]\n",
            "loss: 0.097620  [20000/60000]\n",
            "loss: 0.319253  [25000/60000]\n",
            "loss: 0.093753  [30000/60000]\n",
            "loss: 0.214927  [35000/60000]\n",
            "loss: 0.135382  [40000/60000]\n",
            "loss: 0.095320  [45000/60000]\n",
            "loss: 0.107844  [50000/60000]\n",
            "loss: 0.229782  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.161093 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.099694  [    0/60000]\n",
            "loss: 0.390793  [ 5000/60000]\n",
            "loss: 0.098007  [10000/60000]\n",
            "loss: 0.283321  [15000/60000]\n",
            "loss: 0.042703  [20000/60000]\n",
            "loss: 0.171143  [25000/60000]\n",
            "loss: 0.078984  [30000/60000]\n",
            "loss: 0.143263  [35000/60000]\n",
            "loss: 0.195328  [40000/60000]\n",
            "loss: 0.067862  [45000/60000]\n",
            "loss: 0.300029  [50000/60000]\n",
            "loss: 0.051993  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.160169 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.123259  [    0/60000]\n",
            "loss: 0.378097  [ 5000/60000]\n",
            "loss: 0.097748  [10000/60000]\n",
            "loss: 0.118473  [15000/60000]\n",
            "loss: 0.025634  [20000/60000]\n",
            "loss: 0.205247  [25000/60000]\n",
            "loss: 0.212656  [30000/60000]\n",
            "loss: 0.116556  [35000/60000]\n",
            "loss: 0.134026  [40000/60000]\n",
            "loss: 0.133737  [45000/60000]\n",
            "loss: 0.089112  [50000/60000]\n",
            "loss: 0.170775  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.157120 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.088719  [    0/60000]\n",
            "loss: 0.118775  [ 5000/60000]\n",
            "loss: 0.089013  [10000/60000]\n",
            "loss: 0.114209  [15000/60000]\n",
            "loss: 0.111646  [20000/60000]\n",
            "loss: 0.069539  [25000/60000]\n",
            "loss: 0.066273  [30000/60000]\n",
            "loss: 0.292331  [35000/60000]\n",
            "loss: 0.181037  [40000/60000]\n",
            "loss: 0.234543  [45000/60000]\n",
            "loss: 0.106018  [50000/60000]\n",
            "loss: 0.088306  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.154149 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.269940  [    0/60000]\n",
            "loss: 0.153677  [ 5000/60000]\n",
            "loss: 0.121656  [10000/60000]\n",
            "loss: 0.244518  [15000/60000]\n",
            "loss: 0.250321  [20000/60000]\n",
            "loss: 0.387953  [25000/60000]\n",
            "loss: 0.067656  [30000/60000]\n",
            "loss: 0.162631  [35000/60000]\n",
            "loss: 0.161250  [40000/60000]\n",
            "loss: 0.106959  [45000/60000]\n",
            "loss: 0.211109  [50000/60000]\n",
            "loss: 0.222784  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.156267 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.248586  [    0/60000]\n",
            "loss: 0.208529  [ 5000/60000]\n",
            "loss: 0.142813  [10000/60000]\n",
            "loss: 0.105837  [15000/60000]\n",
            "loss: 0.314306  [20000/60000]\n",
            "loss: 0.112392  [25000/60000]\n",
            "loss: 0.119314  [30000/60000]\n",
            "loss: 0.103469  [35000/60000]\n",
            "loss: 0.084604  [40000/60000]\n",
            "loss: 0.095164  [45000/60000]\n",
            "loss: 0.078048  [50000/60000]\n",
            "loss: 0.099257  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.150938 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.018585  [    0/60000]\n",
            "loss: 0.097152  [ 5000/60000]\n",
            "loss: 0.187553  [10000/60000]\n",
            "loss: 0.325452  [15000/60000]\n",
            "loss: 0.092231  [20000/60000]\n",
            "loss: 0.169778  [25000/60000]\n",
            "loss: 0.045427  [30000/60000]\n",
            "loss: 0.070543  [35000/60000]\n",
            "loss: 0.068078  [40000/60000]\n",
            "loss: 0.146318  [45000/60000]\n",
            "loss: 0.181394  [50000/60000]\n",
            "loss: 0.036381  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.148213 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.093480  [    0/60000]\n",
            "loss: 0.187741  [ 5000/60000]\n",
            "loss: 0.066023  [10000/60000]\n",
            "loss: 0.062563  [15000/60000]\n",
            "loss: 0.333682  [20000/60000]\n",
            "loss: 0.058708  [25000/60000]\n",
            "loss: 0.238200  [30000/60000]\n",
            "loss: 0.036573  [35000/60000]\n",
            "loss: 0.160598  [40000/60000]\n",
            "loss: 0.120322  [45000/60000]\n",
            "loss: 0.037892  [50000/60000]\n",
            "loss: 0.073692  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.144094 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.046658  [    0/60000]\n",
            "loss: 0.063796  [ 5000/60000]\n",
            "loss: 0.119011  [10000/60000]\n",
            "loss: 0.126613  [15000/60000]\n",
            "loss: 0.148501  [20000/60000]\n",
            "loss: 0.244812  [25000/60000]\n",
            "loss: 0.066940  [30000/60000]\n",
            "loss: 0.072209  [35000/60000]\n",
            "loss: 0.123706  [40000/60000]\n",
            "loss: 0.202998  [45000/60000]\n",
            "loss: 0.086643  [50000/60000]\n",
            "loss: 0.201743  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141947 \n",
            "\n",
            "Done!\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.141947 \n",
            "\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.257183  [ 5000/60000]\n",
            "loss: 2.203662  [10000/60000]\n",
            "loss: 2.086518  [15000/60000]\n",
            "loss: 1.997791  [20000/60000]\n",
            "loss: 1.761528  [25000/60000]\n",
            "loss: 1.305071  [30000/60000]\n",
            "loss: 1.127678  [35000/60000]\n",
            "loss: 1.128827  [40000/60000]\n",
            "loss: 1.061773  [45000/60000]\n",
            "loss: 0.901107  [50000/60000]\n",
            "loss: 0.663304  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.628225 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.757501  [    0/60000]\n",
            "loss: 0.487479  [ 5000/60000]\n",
            "loss: 0.396064  [10000/60000]\n",
            "loss: 0.418149  [15000/60000]\n",
            "loss: 0.567001  [20000/60000]\n",
            "loss: 0.483309  [25000/60000]\n",
            "loss: 0.400138  [30000/60000]\n",
            "loss: 0.598250  [35000/60000]\n",
            "loss: 0.484028  [40000/60000]\n",
            "loss: 0.744427  [45000/60000]\n",
            "loss: 0.376775  [50000/60000]\n",
            "loss: 0.349904  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.5%, Avg loss: 0.405149 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.431960  [    0/60000]\n",
            "loss: 0.490144  [ 5000/60000]\n",
            "loss: 0.300952  [10000/60000]\n",
            "loss: 0.482974  [15000/60000]\n",
            "loss: 0.485580  [20000/60000]\n",
            "loss: 0.382258  [25000/60000]\n",
            "loss: 0.405314  [30000/60000]\n",
            "loss: 0.672754  [35000/60000]\n",
            "loss: 0.555240  [40000/60000]\n",
            "loss: 0.275301  [45000/60000]\n",
            "loss: 0.244150  [50000/60000]\n",
            "loss: 0.421505  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.7%, Avg loss: 0.350184 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.279534  [    0/60000]\n",
            "loss: 0.284363  [ 5000/60000]\n",
            "loss: 0.465800  [10000/60000]\n",
            "loss: 0.518952  [15000/60000]\n",
            "loss: 0.389367  [20000/60000]\n",
            "loss: 0.411080  [25000/60000]\n",
            "loss: 0.285196  [30000/60000]\n",
            "loss: 0.209372  [35000/60000]\n",
            "loss: 0.461777  [40000/60000]\n",
            "loss: 0.243382  [45000/60000]\n",
            "loss: 0.504669  [50000/60000]\n",
            "loss: 0.274107  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.323746 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.536920  [    0/60000]\n",
            "loss: 0.339653  [ 5000/60000]\n",
            "loss: 0.485009  [10000/60000]\n",
            "loss: 0.363289  [15000/60000]\n",
            "loss: 0.352915  [20000/60000]\n",
            "loss: 0.353278  [25000/60000]\n",
            "loss: 0.109312  [30000/60000]\n",
            "loss: 0.626619  [35000/60000]\n",
            "loss: 0.119593  [40000/60000]\n",
            "loss: 0.302045  [45000/60000]\n",
            "loss: 0.407660  [50000/60000]\n",
            "loss: 0.363915  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.3%, Avg loss: 0.299688 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.259602  [    0/60000]\n",
            "loss: 0.323229  [ 5000/60000]\n",
            "loss: 0.195302  [10000/60000]\n",
            "loss: 0.317895  [15000/60000]\n",
            "loss: 0.394287  [20000/60000]\n",
            "loss: 0.516096  [25000/60000]\n",
            "loss: 0.188661  [30000/60000]\n",
            "loss: 0.170412  [35000/60000]\n",
            "loss: 0.499134  [40000/60000]\n",
            "loss: 0.322672  [45000/60000]\n",
            "loss: 0.131267  [50000/60000]\n",
            "loss: 0.291028  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.287566 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.215560  [    0/60000]\n",
            "loss: 0.266625  [ 5000/60000]\n",
            "loss: 0.447936  [10000/60000]\n",
            "loss: 0.307503  [15000/60000]\n",
            "loss: 0.319112  [20000/60000]\n",
            "loss: 0.388253  [25000/60000]\n",
            "loss: 0.349429  [30000/60000]\n",
            "loss: 0.146098  [35000/60000]\n",
            "loss: 0.224168  [40000/60000]\n",
            "loss: 0.214140  [45000/60000]\n",
            "loss: 0.219366  [50000/60000]\n",
            "loss: 0.307310  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.1%, Avg loss: 0.272919 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.227081  [    0/60000]\n",
            "loss: 0.136700  [ 5000/60000]\n",
            "loss: 0.300967  [10000/60000]\n",
            "loss: 0.404925  [15000/60000]\n",
            "loss: 0.242235  [20000/60000]\n",
            "loss: 0.227841  [25000/60000]\n",
            "loss: 0.171336  [30000/60000]\n",
            "loss: 0.454386  [35000/60000]\n",
            "loss: 0.642218  [40000/60000]\n",
            "loss: 0.390185  [45000/60000]\n",
            "loss: 0.148003  [50000/60000]\n",
            "loss: 0.286144  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.255362 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.155844  [    0/60000]\n",
            "loss: 0.322937  [ 5000/60000]\n",
            "loss: 0.177819  [10000/60000]\n",
            "loss: 0.367434  [15000/60000]\n",
            "loss: 0.549104  [20000/60000]\n",
            "loss: 0.167200  [25000/60000]\n",
            "loss: 0.291796  [30000/60000]\n",
            "loss: 0.209776  [35000/60000]\n",
            "loss: 0.106993  [40000/60000]\n",
            "loss: 0.089734  [45000/60000]\n",
            "loss: 0.155522  [50000/60000]\n",
            "loss: 0.235488  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.243463 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.187766  [    0/60000]\n",
            "loss: 0.223975  [ 5000/60000]\n",
            "loss: 0.437405  [10000/60000]\n",
            "loss: 0.170822  [15000/60000]\n",
            "loss: 0.217413  [20000/60000]\n",
            "loss: 0.194571  [25000/60000]\n",
            "loss: 0.202160  [30000/60000]\n",
            "loss: 0.397554  [35000/60000]\n",
            "loss: 0.373933  [40000/60000]\n",
            "loss: 0.185660  [45000/60000]\n",
            "loss: 0.265444  [50000/60000]\n",
            "loss: 0.220992  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.234592 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.210832  [    0/60000]\n",
            "loss: 0.358371  [ 5000/60000]\n",
            "loss: 0.327238  [10000/60000]\n",
            "loss: 0.158125  [15000/60000]\n",
            "loss: 0.208437  [20000/60000]\n",
            "loss: 0.217560  [25000/60000]\n",
            "loss: 0.165461  [30000/60000]\n",
            "loss: 0.198523  [35000/60000]\n",
            "loss: 0.169323  [40000/60000]\n",
            "loss: 0.189506  [45000/60000]\n",
            "loss: 0.264105  [50000/60000]\n",
            "loss: 0.413510  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.223443 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.263126  [    0/60000]\n",
            "loss: 0.158127  [ 5000/60000]\n",
            "loss: 0.384807  [10000/60000]\n",
            "loss: 0.332975  [15000/60000]\n",
            "loss: 0.357545  [20000/60000]\n",
            "loss: 0.133429  [25000/60000]\n",
            "loss: 0.153222  [30000/60000]\n",
            "loss: 0.106534  [35000/60000]\n",
            "loss: 0.078499  [40000/60000]\n",
            "loss: 0.106356  [45000/60000]\n",
            "loss: 0.139057  [50000/60000]\n",
            "loss: 0.206677  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.9%, Avg loss: 0.213279 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.188095  [    0/60000]\n",
            "loss: 0.316744  [ 5000/60000]\n",
            "loss: 0.262278  [10000/60000]\n",
            "loss: 0.391031  [15000/60000]\n",
            "loss: 0.214430  [20000/60000]\n",
            "loss: 0.317385  [25000/60000]\n",
            "loss: 0.225492  [30000/60000]\n",
            "loss: 0.075726  [35000/60000]\n",
            "loss: 0.363105  [40000/60000]\n",
            "loss: 0.447764  [45000/60000]\n",
            "loss: 0.171993  [50000/60000]\n",
            "loss: 0.261538  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.208457 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.243224  [    0/60000]\n",
            "loss: 0.517047  [ 5000/60000]\n",
            "loss: 0.113566  [10000/60000]\n",
            "loss: 0.315507  [15000/60000]\n",
            "loss: 0.352448  [20000/60000]\n",
            "loss: 0.146318  [25000/60000]\n",
            "loss: 0.192144  [30000/60000]\n",
            "loss: 0.170613  [35000/60000]\n",
            "loss: 0.080116  [40000/60000]\n",
            "loss: 0.408485  [45000/60000]\n",
            "loss: 0.250893  [50000/60000]\n",
            "loss: 0.112034  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.196342 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.371942  [    0/60000]\n",
            "loss: 0.272330  [ 5000/60000]\n",
            "loss: 0.078868  [10000/60000]\n",
            "loss: 0.234922  [15000/60000]\n",
            "loss: 0.102076  [20000/60000]\n",
            "loss: 0.117168  [25000/60000]\n",
            "loss: 0.320608  [30000/60000]\n",
            "loss: 0.144081  [35000/60000]\n",
            "loss: 0.441218  [40000/60000]\n",
            "loss: 0.238716  [45000/60000]\n",
            "loss: 0.133974  [50000/60000]\n",
            "loss: 0.075000  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.193014 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.131918  [    0/60000]\n",
            "loss: 0.139769  [ 5000/60000]\n",
            "loss: 0.239230  [10000/60000]\n",
            "loss: 0.280726  [15000/60000]\n",
            "loss: 0.180425  [20000/60000]\n",
            "loss: 0.043088  [25000/60000]\n",
            "loss: 0.131918  [30000/60000]\n",
            "loss: 0.222308  [35000/60000]\n",
            "loss: 0.130735  [40000/60000]\n",
            "loss: 0.060635  [45000/60000]\n",
            "loss: 0.343164  [50000/60000]\n",
            "loss: 0.059769  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.185844 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.195993  [    0/60000]\n",
            "loss: 0.166535  [ 5000/60000]\n",
            "loss: 0.092466  [10000/60000]\n",
            "loss: 0.182932  [15000/60000]\n",
            "loss: 0.171943  [20000/60000]\n",
            "loss: 0.102190  [25000/60000]\n",
            "loss: 0.258262  [30000/60000]\n",
            "loss: 0.258092  [35000/60000]\n",
            "loss: 0.132229  [40000/60000]\n",
            "loss: 0.132885  [45000/60000]\n",
            "loss: 0.297499  [50000/60000]\n",
            "loss: 0.129686  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.180882 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.141735  [    0/60000]\n",
            "loss: 0.168893  [ 5000/60000]\n",
            "loss: 0.096136  [10000/60000]\n",
            "loss: 0.132119  [15000/60000]\n",
            "loss: 0.312868  [20000/60000]\n",
            "loss: 0.419419  [25000/60000]\n",
            "loss: 0.135140  [30000/60000]\n",
            "loss: 0.138275  [35000/60000]\n",
            "loss: 0.072654  [40000/60000]\n",
            "loss: 0.134762  [45000/60000]\n",
            "loss: 0.130507  [50000/60000]\n",
            "loss: 0.234995  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.173285 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.052858  [    0/60000]\n",
            "loss: 0.215515  [ 5000/60000]\n",
            "loss: 0.256257  [10000/60000]\n",
            "loss: 0.115434  [15000/60000]\n",
            "loss: 0.290004  [20000/60000]\n",
            "loss: 0.265369  [25000/60000]\n",
            "loss: 0.091860  [30000/60000]\n",
            "loss: 0.129831  [35000/60000]\n",
            "loss: 0.060432  [40000/60000]\n",
            "loss: 0.052557  [45000/60000]\n",
            "loss: 0.194815  [50000/60000]\n",
            "loss: 0.194789  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.170499 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.050459  [    0/60000]\n",
            "loss: 0.159795  [ 5000/60000]\n",
            "loss: 0.085058  [10000/60000]\n",
            "loss: 0.210862  [15000/60000]\n",
            "loss: 0.293216  [20000/60000]\n",
            "loss: 0.115957  [25000/60000]\n",
            "loss: 0.108675  [30000/60000]\n",
            "loss: 0.119162  [35000/60000]\n",
            "loss: 0.077644  [40000/60000]\n",
            "loss: 0.166808  [45000/60000]\n",
            "loss: 0.130176  [50000/60000]\n",
            "loss: 0.324342  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.165378 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.136901  [    0/60000]\n",
            "loss: 0.145658  [ 5000/60000]\n",
            "loss: 0.098718  [10000/60000]\n",
            "loss: 0.148490  [15000/60000]\n",
            "loss: 0.170471  [20000/60000]\n",
            "loss: 0.202308  [25000/60000]\n",
            "loss: 0.058561  [30000/60000]\n",
            "loss: 0.185708  [35000/60000]\n",
            "loss: 0.104679  [40000/60000]\n",
            "loss: 0.113345  [45000/60000]\n",
            "loss: 0.063868  [50000/60000]\n",
            "loss: 0.178346  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.166313 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.053617  [    0/60000]\n",
            "loss: 0.151517  [ 5000/60000]\n",
            "loss: 0.247673  [10000/60000]\n",
            "loss: 0.066400  [15000/60000]\n",
            "loss: 0.092960  [20000/60000]\n",
            "loss: 0.321966  [25000/60000]\n",
            "loss: 0.096584  [30000/60000]\n",
            "loss: 0.212554  [35000/60000]\n",
            "loss: 0.127973  [40000/60000]\n",
            "loss: 0.092956  [45000/60000]\n",
            "loss: 0.110852  [50000/60000]\n",
            "loss: 0.227333  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.3%, Avg loss: 0.158527 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.101247  [    0/60000]\n",
            "loss: 0.392730  [ 5000/60000]\n",
            "loss: 0.094897  [10000/60000]\n",
            "loss: 0.284417  [15000/60000]\n",
            "loss: 0.042138  [20000/60000]\n",
            "loss: 0.162737  [25000/60000]\n",
            "loss: 0.078236  [30000/60000]\n",
            "loss: 0.150562  [35000/60000]\n",
            "loss: 0.190272  [40000/60000]\n",
            "loss: 0.065842  [45000/60000]\n",
            "loss: 0.293479  [50000/60000]\n",
            "loss: 0.052408  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.3%, Avg loss: 0.157113 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.117371  [    0/60000]\n",
            "loss: 0.370339  [ 5000/60000]\n",
            "loss: 0.096586  [10000/60000]\n",
            "loss: 0.117612  [15000/60000]\n",
            "loss: 0.024872  [20000/60000]\n",
            "loss: 0.200230  [25000/60000]\n",
            "loss: 0.203937  [30000/60000]\n",
            "loss: 0.113920  [35000/60000]\n",
            "loss: 0.132649  [40000/60000]\n",
            "loss: 0.130250  [45000/60000]\n",
            "loss: 0.085618  [50000/60000]\n",
            "loss: 0.166518  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.154103 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.089056  [    0/60000]\n",
            "loss: 0.115555  [ 5000/60000]\n",
            "loss: 0.087089  [10000/60000]\n",
            "loss: 0.109105  [15000/60000]\n",
            "loss: 0.108538  [20000/60000]\n",
            "loss: 0.065753  [25000/60000]\n",
            "loss: 0.061580  [30000/60000]\n",
            "loss: 0.278632  [35000/60000]\n",
            "loss: 0.174066  [40000/60000]\n",
            "loss: 0.235244  [45000/60000]\n",
            "loss: 0.103576  [50000/60000]\n",
            "loss: 0.083477  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.151127 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.271563  [    0/60000]\n",
            "loss: 0.151058  [ 5000/60000]\n",
            "loss: 0.117858  [10000/60000]\n",
            "loss: 0.245322  [15000/60000]\n",
            "loss: 0.247248  [20000/60000]\n",
            "loss: 0.387350  [25000/60000]\n",
            "loss: 0.063293  [30000/60000]\n",
            "loss: 0.161826  [35000/60000]\n",
            "loss: 0.166486  [40000/60000]\n",
            "loss: 0.104853  [45000/60000]\n",
            "loss: 0.207538  [50000/60000]\n",
            "loss: 0.218165  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.153252 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.242997  [    0/60000]\n",
            "loss: 0.217786  [ 5000/60000]\n",
            "loss: 0.145961  [10000/60000]\n",
            "loss: 0.102827  [15000/60000]\n",
            "loss: 0.318256  [20000/60000]\n",
            "loss: 0.108255  [25000/60000]\n",
            "loss: 0.109295  [30000/60000]\n",
            "loss: 0.096427  [35000/60000]\n",
            "loss: 0.080810  [40000/60000]\n",
            "loss: 0.093817  [45000/60000]\n",
            "loss: 0.077833  [50000/60000]\n",
            "loss: 0.101697  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.147801 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.017289  [    0/60000]\n",
            "loss: 0.089355  [ 5000/60000]\n",
            "loss: 0.182366  [10000/60000]\n",
            "loss: 0.317357  [15000/60000]\n",
            "loss: 0.086633  [20000/60000]\n",
            "loss: 0.165869  [25000/60000]\n",
            "loss: 0.044547  [30000/60000]\n",
            "loss: 0.069956  [35000/60000]\n",
            "loss: 0.068941  [40000/60000]\n",
            "loss: 0.149498  [45000/60000]\n",
            "loss: 0.187255  [50000/60000]\n",
            "loss: 0.035645  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.145252 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.095357  [    0/60000]\n",
            "loss: 0.181767  [ 5000/60000]\n",
            "loss: 0.059693  [10000/60000]\n",
            "loss: 0.060061  [15000/60000]\n",
            "loss: 0.314672  [20000/60000]\n",
            "loss: 0.056612  [25000/60000]\n",
            "loss: 0.229623  [30000/60000]\n",
            "loss: 0.033758  [35000/60000]\n",
            "loss: 0.159033  [40000/60000]\n",
            "loss: 0.120336  [45000/60000]\n",
            "loss: 0.034529  [50000/60000]\n",
            "loss: 0.065456  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.140986 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.041989  [    0/60000]\n",
            "loss: 0.063044  [ 5000/60000]\n",
            "loss: 0.109143  [10000/60000]\n",
            "loss: 0.121642  [15000/60000]\n",
            "loss: 0.148094  [20000/60000]\n",
            "loss: 0.239544  [25000/60000]\n",
            "loss: 0.066350  [30000/60000]\n",
            "loss: 0.068986  [35000/60000]\n",
            "loss: 0.121880  [40000/60000]\n",
            "loss: 0.195912  [45000/60000]\n",
            "loss: 0.080963  [50000/60000]\n",
            "loss: 0.192179  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.138797 \n",
            "\n",
            "Done!\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.138797 \n",
            "\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299123  [    0/60000]\n",
            "loss: 2.257099  [ 5000/60000]\n",
            "loss: 2.203626  [10000/60000]\n",
            "loss: 2.085635  [15000/60000]\n",
            "loss: 1.997903  [20000/60000]\n",
            "loss: 1.762015  [25000/60000]\n",
            "loss: 1.306290  [30000/60000]\n",
            "loss: 1.128807  [35000/60000]\n",
            "loss: 1.129326  [40000/60000]\n",
            "loss: 1.062775  [45000/60000]\n",
            "loss: 0.901351  [50000/60000]\n",
            "loss: 0.663905  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.628411 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.758166  [    0/60000]\n",
            "loss: 0.486617  [ 5000/60000]\n",
            "loss: 0.395919  [10000/60000]\n",
            "loss: 0.418501  [15000/60000]\n",
            "loss: 0.566691  [20000/60000]\n",
            "loss: 0.483665  [25000/60000]\n",
            "loss: 0.400655  [30000/60000]\n",
            "loss: 0.598127  [35000/60000]\n",
            "loss: 0.484328  [40000/60000]\n",
            "loss: 0.744400  [45000/60000]\n",
            "loss: 0.376609  [50000/60000]\n",
            "loss: 0.349524  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.5%, Avg loss: 0.404987 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.431388  [    0/60000]\n",
            "loss: 0.489116  [ 5000/60000]\n",
            "loss: 0.300521  [10000/60000]\n",
            "loss: 0.483011  [15000/60000]\n",
            "loss: 0.485014  [20000/60000]\n",
            "loss: 0.382604  [25000/60000]\n",
            "loss: 0.404812  [30000/60000]\n",
            "loss: 0.672179  [35000/60000]\n",
            "loss: 0.555952  [40000/60000]\n",
            "loss: 0.274483  [45000/60000]\n",
            "loss: 0.244867  [50000/60000]\n",
            "loss: 0.421570  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.7%, Avg loss: 0.349803 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.279416  [    0/60000]\n",
            "loss: 0.283818  [ 5000/60000]\n",
            "loss: 0.465218  [10000/60000]\n",
            "loss: 0.517341  [15000/60000]\n",
            "loss: 0.387281  [20000/60000]\n",
            "loss: 0.409747  [25000/60000]\n",
            "loss: 0.284255  [30000/60000]\n",
            "loss: 0.209706  [35000/60000]\n",
            "loss: 0.459753  [40000/60000]\n",
            "loss: 0.241771  [45000/60000]\n",
            "loss: 0.503070  [50000/60000]\n",
            "loss: 0.274611  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.323202 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.535866  [    0/60000]\n",
            "loss: 0.338041  [ 5000/60000]\n",
            "loss: 0.484604  [10000/60000]\n",
            "loss: 0.361121  [15000/60000]\n",
            "loss: 0.353683  [20000/60000]\n",
            "loss: 0.352764  [25000/60000]\n",
            "loss: 0.109536  [30000/60000]\n",
            "loss: 0.623614  [35000/60000]\n",
            "loss: 0.119155  [40000/60000]\n",
            "loss: 0.301130  [45000/60000]\n",
            "loss: 0.405886  [50000/60000]\n",
            "loss: 0.363591  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.3%, Avg loss: 0.298937 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.258026  [    0/60000]\n",
            "loss: 0.322938  [ 5000/60000]\n",
            "loss: 0.194796  [10000/60000]\n",
            "loss: 0.318995  [15000/60000]\n",
            "loss: 0.391646  [20000/60000]\n",
            "loss: 0.518173  [25000/60000]\n",
            "loss: 0.187978  [30000/60000]\n",
            "loss: 0.169612  [35000/60000]\n",
            "loss: 0.495954  [40000/60000]\n",
            "loss: 0.322123  [45000/60000]\n",
            "loss: 0.129461  [50000/60000]\n",
            "loss: 0.290787  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.286608 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.213905  [    0/60000]\n",
            "loss: 0.266596  [ 5000/60000]\n",
            "loss: 0.448546  [10000/60000]\n",
            "loss: 0.305872  [15000/60000]\n",
            "loss: 0.318012  [20000/60000]\n",
            "loss: 0.387933  [25000/60000]\n",
            "loss: 0.347776  [30000/60000]\n",
            "loss: 0.145451  [35000/60000]\n",
            "loss: 0.222707  [40000/60000]\n",
            "loss: 0.211982  [45000/60000]\n",
            "loss: 0.217567  [50000/60000]\n",
            "loss: 0.306387  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.1%, Avg loss: 0.271752 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.225836  [    0/60000]\n",
            "loss: 0.136249  [ 5000/60000]\n",
            "loss: 0.303507  [10000/60000]\n",
            "loss: 0.401603  [15000/60000]\n",
            "loss: 0.242423  [20000/60000]\n",
            "loss: 0.226966  [25000/60000]\n",
            "loss: 0.170057  [30000/60000]\n",
            "loss: 0.456490  [35000/60000]\n",
            "loss: 0.642421  [40000/60000]\n",
            "loss: 0.389815  [45000/60000]\n",
            "loss: 0.146996  [50000/60000]\n",
            "loss: 0.281897  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.8%, Avg loss: 0.254432 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.153839  [    0/60000]\n",
            "loss: 0.323185  [ 5000/60000]\n",
            "loss: 0.176928  [10000/60000]\n",
            "loss: 0.369986  [15000/60000]\n",
            "loss: 0.546634  [20000/60000]\n",
            "loss: 0.166919  [25000/60000]\n",
            "loss: 0.290447  [30000/60000]\n",
            "loss: 0.208572  [35000/60000]\n",
            "loss: 0.106654  [40000/60000]\n",
            "loss: 0.088602  [45000/60000]\n",
            "loss: 0.154622  [50000/60000]\n",
            "loss: 0.234341  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.1%, Avg loss: 0.242396 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.188863  [    0/60000]\n",
            "loss: 0.222693  [ 5000/60000]\n",
            "loss: 0.434286  [10000/60000]\n",
            "loss: 0.170639  [15000/60000]\n",
            "loss: 0.218260  [20000/60000]\n",
            "loss: 0.192549  [25000/60000]\n",
            "loss: 0.202740  [30000/60000]\n",
            "loss: 0.393153  [35000/60000]\n",
            "loss: 0.368879  [40000/60000]\n",
            "loss: 0.182592  [45000/60000]\n",
            "loss: 0.263526  [50000/60000]\n",
            "loss: 0.218343  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.233501 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.207611  [    0/60000]\n",
            "loss: 0.357508  [ 5000/60000]\n",
            "loss: 0.328542  [10000/60000]\n",
            "loss: 0.157706  [15000/60000]\n",
            "loss: 0.204872  [20000/60000]\n",
            "loss: 0.217487  [25000/60000]\n",
            "loss: 0.164085  [30000/60000]\n",
            "loss: 0.199359  [35000/60000]\n",
            "loss: 0.169524  [40000/60000]\n",
            "loss: 0.188462  [45000/60000]\n",
            "loss: 0.262542  [50000/60000]\n",
            "loss: 0.413359  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.222379 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.259485  [    0/60000]\n",
            "loss: 0.158258  [ 5000/60000]\n",
            "loss: 0.383441  [10000/60000]\n",
            "loss: 0.336691  [15000/60000]\n",
            "loss: 0.358036  [20000/60000]\n",
            "loss: 0.132000  [25000/60000]\n",
            "loss: 0.152431  [30000/60000]\n",
            "loss: 0.106021  [35000/60000]\n",
            "loss: 0.078100  [40000/60000]\n",
            "loss: 0.105146  [45000/60000]\n",
            "loss: 0.138057  [50000/60000]\n",
            "loss: 0.206942  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.0%, Avg loss: 0.212058 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.186550  [    0/60000]\n",
            "loss: 0.311597  [ 5000/60000]\n",
            "loss: 0.258805  [10000/60000]\n",
            "loss: 0.384916  [15000/60000]\n",
            "loss: 0.213124  [20000/60000]\n",
            "loss: 0.309999  [25000/60000]\n",
            "loss: 0.222575  [30000/60000]\n",
            "loss: 0.076823  [35000/60000]\n",
            "loss: 0.359977  [40000/60000]\n",
            "loss: 0.449394  [45000/60000]\n",
            "loss: 0.171411  [50000/60000]\n",
            "loss: 0.254444  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.207078 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.240106  [    0/60000]\n",
            "loss: 0.517991  [ 5000/60000]\n",
            "loss: 0.111154  [10000/60000]\n",
            "loss: 0.312130  [15000/60000]\n",
            "loss: 0.350626  [20000/60000]\n",
            "loss: 0.143668  [25000/60000]\n",
            "loss: 0.191255  [30000/60000]\n",
            "loss: 0.171521  [35000/60000]\n",
            "loss: 0.078526  [40000/60000]\n",
            "loss: 0.404886  [45000/60000]\n",
            "loss: 0.249501  [50000/60000]\n",
            "loss: 0.112255  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.1%, Avg loss: 0.195089 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.365609  [    0/60000]\n",
            "loss: 0.266351  [ 5000/60000]\n",
            "loss: 0.077884  [10000/60000]\n",
            "loss: 0.232252  [15000/60000]\n",
            "loss: 0.101692  [20000/60000]\n",
            "loss: 0.116962  [25000/60000]\n",
            "loss: 0.316799  [30000/60000]\n",
            "loss: 0.143519  [35000/60000]\n",
            "loss: 0.440058  [40000/60000]\n",
            "loss: 0.236345  [45000/60000]\n",
            "loss: 0.138333  [50000/60000]\n",
            "loss: 0.075252  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.191696 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.130559  [    0/60000]\n",
            "loss: 0.140155  [ 5000/60000]\n",
            "loss: 0.240914  [10000/60000]\n",
            "loss: 0.281875  [15000/60000]\n",
            "loss: 0.180495  [20000/60000]\n",
            "loss: 0.043017  [25000/60000]\n",
            "loss: 0.127758  [30000/60000]\n",
            "loss: 0.222281  [35000/60000]\n",
            "loss: 0.128783  [40000/60000]\n",
            "loss: 0.061520  [45000/60000]\n",
            "loss: 0.339982  [50000/60000]\n",
            "loss: 0.059680  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.184358 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.192503  [    0/60000]\n",
            "loss: 0.161770  [ 5000/60000]\n",
            "loss: 0.091911  [10000/60000]\n",
            "loss: 0.180486  [15000/60000]\n",
            "loss: 0.168175  [20000/60000]\n",
            "loss: 0.099578  [25000/60000]\n",
            "loss: 0.259105  [30000/60000]\n",
            "loss: 0.256430  [35000/60000]\n",
            "loss: 0.133256  [40000/60000]\n",
            "loss: 0.130501  [45000/60000]\n",
            "loss: 0.295144  [50000/60000]\n",
            "loss: 0.125694  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.179417 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.139263  [    0/60000]\n",
            "loss: 0.169604  [ 5000/60000]\n",
            "loss: 0.094250  [10000/60000]\n",
            "loss: 0.129453  [15000/60000]\n",
            "loss: 0.307974  [20000/60000]\n",
            "loss: 0.419590  [25000/60000]\n",
            "loss: 0.137215  [30000/60000]\n",
            "loss: 0.135800  [35000/60000]\n",
            "loss: 0.071395  [40000/60000]\n",
            "loss: 0.135094  [45000/60000]\n",
            "loss: 0.128581  [50000/60000]\n",
            "loss: 0.231039  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.171858 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.052737  [    0/60000]\n",
            "loss: 0.212097  [ 5000/60000]\n",
            "loss: 0.249354  [10000/60000]\n",
            "loss: 0.112253  [15000/60000]\n",
            "loss: 0.296401  [20000/60000]\n",
            "loss: 0.269550  [25000/60000]\n",
            "loss: 0.089559  [30000/60000]\n",
            "loss: 0.128511  [35000/60000]\n",
            "loss: 0.060067  [40000/60000]\n",
            "loss: 0.050211  [45000/60000]\n",
            "loss: 0.194180  [50000/60000]\n",
            "loss: 0.191337  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.169016 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.050647  [    0/60000]\n",
            "loss: 0.160262  [ 5000/60000]\n",
            "loss: 0.088045  [10000/60000]\n",
            "loss: 0.203588  [15000/60000]\n",
            "loss: 0.290326  [20000/60000]\n",
            "loss: 0.114707  [25000/60000]\n",
            "loss: 0.107930  [30000/60000]\n",
            "loss: 0.117247  [35000/60000]\n",
            "loss: 0.074535  [40000/60000]\n",
            "loss: 0.166544  [45000/60000]\n",
            "loss: 0.127968  [50000/60000]\n",
            "loss: 0.325743  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.163790 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.135284  [    0/60000]\n",
            "loss: 0.140475  [ 5000/60000]\n",
            "loss: 0.097544  [10000/60000]\n",
            "loss: 0.145513  [15000/60000]\n",
            "loss: 0.171029  [20000/60000]\n",
            "loss: 0.198887  [25000/60000]\n",
            "loss: 0.057916  [30000/60000]\n",
            "loss: 0.180916  [35000/60000]\n",
            "loss: 0.102850  [40000/60000]\n",
            "loss: 0.108150  [45000/60000]\n",
            "loss: 0.062233  [50000/60000]\n",
            "loss: 0.178086  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.164386 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.055431  [    0/60000]\n",
            "loss: 0.145036  [ 5000/60000]\n",
            "loss: 0.246684  [10000/60000]\n",
            "loss: 0.062996  [15000/60000]\n",
            "loss: 0.088968  [20000/60000]\n",
            "loss: 0.327011  [25000/60000]\n",
            "loss: 0.100725  [30000/60000]\n",
            "loss: 0.210403  [35000/60000]\n",
            "loss: 0.125828  [40000/60000]\n",
            "loss: 0.093310  [45000/60000]\n",
            "loss: 0.110275  [50000/60000]\n",
            "loss: 0.224014  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.156904 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.099916  [    0/60000]\n",
            "loss: 0.390012  [ 5000/60000]\n",
            "loss: 0.092713  [10000/60000]\n",
            "loss: 0.286986  [15000/60000]\n",
            "loss: 0.043354  [20000/60000]\n",
            "loss: 0.161932  [25000/60000]\n",
            "loss: 0.079860  [30000/60000]\n",
            "loss: 0.156143  [35000/60000]\n",
            "loss: 0.183895  [40000/60000]\n",
            "loss: 0.065329  [45000/60000]\n",
            "loss: 0.292099  [50000/60000]\n",
            "loss: 0.051536  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.155106 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.117414  [    0/60000]\n",
            "loss: 0.370524  [ 5000/60000]\n",
            "loss: 0.093475  [10000/60000]\n",
            "loss: 0.113348  [15000/60000]\n",
            "loss: 0.024516  [20000/60000]\n",
            "loss: 0.197462  [25000/60000]\n",
            "loss: 0.193261  [30000/60000]\n",
            "loss: 0.113775  [35000/60000]\n",
            "loss: 0.129330  [40000/60000]\n",
            "loss: 0.130077  [45000/60000]\n",
            "loss: 0.083282  [50000/60000]\n",
            "loss: 0.164007  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.4%, Avg loss: 0.152217 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.087667  [    0/60000]\n",
            "loss: 0.113250  [ 5000/60000]\n",
            "loss: 0.085904  [10000/60000]\n",
            "loss: 0.103943  [15000/60000]\n",
            "loss: 0.108155  [20000/60000]\n",
            "loss: 0.062912  [25000/60000]\n",
            "loss: 0.059945  [30000/60000]\n",
            "loss: 0.267264  [35000/60000]\n",
            "loss: 0.167910  [40000/60000]\n",
            "loss: 0.231028  [45000/60000]\n",
            "loss: 0.099422  [50000/60000]\n",
            "loss: 0.081426  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.5%, Avg loss: 0.148847 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.269444  [    0/60000]\n",
            "loss: 0.147491  [ 5000/60000]\n",
            "loss: 0.115669  [10000/60000]\n",
            "loss: 0.241655  [15000/60000]\n",
            "loss: 0.240547  [20000/60000]\n",
            "loss: 0.389239  [25000/60000]\n",
            "loss: 0.060458  [30000/60000]\n",
            "loss: 0.158911  [35000/60000]\n",
            "loss: 0.166560  [40000/60000]\n",
            "loss: 0.104415  [45000/60000]\n",
            "loss: 0.198570  [50000/60000]\n",
            "loss: 0.216660  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.151043 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.239200  [    0/60000]\n",
            "loss: 0.213058  [ 5000/60000]\n",
            "loss: 0.143493  [10000/60000]\n",
            "loss: 0.102229  [15000/60000]\n",
            "loss: 0.318437  [20000/60000]\n",
            "loss: 0.103629  [25000/60000]\n",
            "loss: 0.105969  [30000/60000]\n",
            "loss: 0.094050  [35000/60000]\n",
            "loss: 0.079366  [40000/60000]\n",
            "loss: 0.092108  [45000/60000]\n",
            "loss: 0.076494  [50000/60000]\n",
            "loss: 0.104496  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.8%, Avg loss: 0.145409 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.016457  [    0/60000]\n",
            "loss: 0.088545  [ 5000/60000]\n",
            "loss: 0.176825  [10000/60000]\n",
            "loss: 0.314758  [15000/60000]\n",
            "loss: 0.086491  [20000/60000]\n",
            "loss: 0.161498  [25000/60000]\n",
            "loss: 0.043946  [30000/60000]\n",
            "loss: 0.071501  [35000/60000]\n",
            "loss: 0.069401  [40000/60000]\n",
            "loss: 0.152398  [45000/60000]\n",
            "loss: 0.190690  [50000/60000]\n",
            "loss: 0.035951  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.7%, Avg loss: 0.142829 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.094185  [    0/60000]\n",
            "loss: 0.177236  [ 5000/60000]\n",
            "loss: 0.056666  [10000/60000]\n",
            "loss: 0.059476  [15000/60000]\n",
            "loss: 0.311055  [20000/60000]\n",
            "loss: 0.056036  [25000/60000]\n",
            "loss: 0.221737  [30000/60000]\n",
            "loss: 0.032581  [35000/60000]\n",
            "loss: 0.158756  [40000/60000]\n",
            "loss: 0.123212  [45000/60000]\n",
            "loss: 0.033543  [50000/60000]\n",
            "loss: 0.061776  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.138844 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.039749  [    0/60000]\n",
            "loss: 0.063765  [ 5000/60000]\n",
            "loss: 0.105514  [10000/60000]\n",
            "loss: 0.118798  [15000/60000]\n",
            "loss: 0.142485  [20000/60000]\n",
            "loss: 0.242008  [25000/60000]\n",
            "loss: 0.064065  [30000/60000]\n",
            "loss: 0.066376  [35000/60000]\n",
            "loss: 0.118989  [40000/60000]\n",
            "loss: 0.188571  [45000/60000]\n",
            "loss: 0.078300  [50000/60000]\n",
            "loss: 0.186846  [55000/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.136699 \n",
            "\n",
            "Done!\n",
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.136699 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dpsgd_accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbzLlb_xT8Iq",
        "outputId": "3bc3cb6f-3c0b-43c3-8220-c1f993f7e8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9269, 0.9155, 0.9405, 0.9302]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize change in noise params for different epsilon\n",
        "epsilon_vals = np.linspace(1, 40, 40)\n",
        "for eps in epsilon_vals:\n",
        "  print(find_noise_parameter(eps, 0.1, training_data, batch_size, num_epochs, 15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYcIX0uWALNd",
        "outputId": "286484f0-4645-4d21-b23f-120c0024a1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7051681518554688\n",
            "0.5710250854492187\n",
            "0.5161483764648438\n",
            "0.4856613159179688\n",
            "0.46127166748046877\n",
            "0.44297943115234373\n",
            "0.43078460693359377\n",
            "0.4185897827148438\n",
            "0.40639495849609375\n",
            "0.40029754638671877\n",
            "0.39115142822265625\n",
            "0.38505401611328127\n",
            "0.3789566040039063\n",
            "0.3728591918945312\n",
            "0.36676177978515623\n",
            "0.3637130737304688\n",
            "0.3576156616210937\n",
            "0.35456695556640627\n",
            "0.35151824951171873\n",
            "0.3484695434570312\n",
            "0.34542083740234375\n",
            "0.3423721313476562\n",
            "0.33932342529296877\n",
            "0.33627471923828123\n",
            "0.3332260131835937\n",
            "0.33017730712890625\n",
            "0.3271286010742187\n",
            "0.32407989501953116\n",
            "0.32407989501953116\n",
            "0.32103118896484373\n",
            "0.3179824829101562\n",
            "0.31493377685546875\n",
            "0.31493377685546875\n",
            "0.3118850708007812\n",
            "0.3118850708007812\n",
            "0.30883636474609377\n",
            "0.30578765869140623\n",
            "0.30578765869140623\n",
            "0.3027389526367188\n",
            "0.3027389526367188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all three methods (Regular, (Remove point, retrain, add noise), DPSGD)\n",
        "graph = sns.lineplot()\n",
        "graph.axhline(test(test_dataloader, models[0][0], loss_fn), color='green')\n",
        "sns.lineplot(x = epsilon_vals, y = dpsgd_accuracies)\n",
        "sns.lineplot(x = np.linspace(1, 40, 40), y = noise_accuracies)\n",
        "plt.legend(labels=['Regular', 'DPSGD', 'Remove point, retrain, add noise'])\n",
        "plt.title(\"Epsilon vs Average Accuracy (fixed delta = 0.1, Regular MNIST)\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Average accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "VC75I9f597YW",
        "outputId": "fb601ff6-010b-46ed-e89c-912d25b985e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.099635 \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}